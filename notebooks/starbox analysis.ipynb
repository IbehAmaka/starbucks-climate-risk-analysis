{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dafdacbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… FIXED: CONFIG as single source of truth\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "COMPREHENSIVE CLIMATE RISK ANALYSIS FOR STARBUCKS COFFEE SUPPLY CHAIN\n",
    "TCFD-Aligned Framework with Physical and Transition Risk Assessment\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 1: IMPORTS AND CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats, interpolate\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import folium\n",
    "from folium import plugins\n",
    "import networkx as nx\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39609c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STARBUCKS CLIMATE RISK ANALYSIS - COMPLETE PIPELINE\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ Using corrected climate data with elevation adjustments\n",
      "ğŸ“ Base path: C:/Users/ibeha/OneDrive/Desktop/Climate\n",
      "ğŸŒ¡ï¸  Elevation lapse rate: 6.5Â°C per 1000m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "CONFIG = {\n",
    "    'base_path': r\"C:/Users/ibeha/OneDrive/Desktop/Climate\",\n",
    "    'scenarios': ['historical', 'ssp126', 'ssp245', 'ssp585'],\n",
    "    'variables': ['tas', 'tasmax', 'tasmin', 'pr', 'hurs'],\n",
    "    'time_periods': {\n",
    "        'baseline': (1985, 2014),\n",
    "        'near_term': (2021, 2040),\n",
    "        'mid_term': (2041, 2060)\n",
    "    },\n",
    "    'coffee_optimal': {\n",
    "        'temp_min': 15,\n",
    "        'temp_max': 24,\n",
    "        'temp_optimal': 19.5,\n",
    "        'precip_min': 1200,\n",
    "        'precip_max': 2000,\n",
    "        'precip_optimal': 1600\n",
    "    },\n",
    "    'elevation_lapse_rate': 0.0065,  # Temperature decrease per meter elevation\n",
    "    'financial_params': {\n",
    "        'discount_rate': 0.08,\n",
    "        'coffee_price_baseline_usd_kg': 3.5,\n",
    "        'starbucks_annual_coffee_mt': 172000,\n",
    "        'operating_margin': 0.16,\n",
    "        'gross_margin_pct': 0.28,\n",
    "        'price_elasticity': -0.8,\n",
    "        'total_assets': 35e9,\n",
    "        'total_revenue': 36.2e9,\n",
    "        'coffee_revenue': 36.2e9 * 0.35,\n",
    "        'scope_1_2_emissions': 1.5e6,\n",
    "        'scope_3_emissions': 15e6\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STARBUCKS CLIMATE RISK ANALYSIS - COMPLETE PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nğŸ“ Using corrected climate data with elevation adjustments\")\n",
    "print(f\"ğŸ“ Base path: {CONFIG['base_path']}\")\n",
    "print(f\"ğŸŒ¡ï¸  Elevation lapse rate: {CONFIG['elevation_lapse_rate']*1000:.1f}Â°C per 1000m\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d4d463c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 1: LOADING CLIMATE DATA\n",
      "================================================================================\n",
      "âœ… Loading tas_historical\n",
      "âœ… Loading tas_ssp126\n",
      "âœ… Loading tas_ssp245\n",
      "âœ… Loading tas_ssp585\n",
      "âœ… Loading tasmax_historical\n",
      "âœ… Loading tasmax_ssp126\n",
      "âœ… Loading tasmax_ssp245\n",
      "âœ… Loading tasmax_ssp585\n",
      "âœ… Loading tasmin_historical\n",
      "âœ… Loading tasmin_ssp126\n",
      "âœ… Loading tasmin_ssp245\n",
      "âœ… Loading tasmin_ssp585\n",
      "âœ… Loading pr_historical\n",
      "âœ… Loading pr_ssp126\n",
      "âœ… Loading pr_ssp245\n",
      "âœ… Loading pr_ssp585\n",
      "âœ… Loading hurs_historical\n",
      "âœ… Loading hurs_ssp126\n",
      "âœ… Loading hurs_ssp245\n",
      "âœ… Loading hurs_ssp585\n",
      "\n",
      "================================================================================\n",
      "STEP 1: LOADING CLIMATE DATA\n",
      "================================================================================\n",
      "âœ… Loading tas_historical\n",
      "âœ… Loading tas_ssp126\n",
      "âœ… Loading tas_ssp245\n",
      "âœ… Loading tas_ssp585\n",
      "âœ… Loading tasmax_historical\n",
      "âœ… Loading tasmax_ssp126\n",
      "âœ… Loading tasmax_ssp245\n",
      "âœ… Loading tasmax_ssp585\n",
      "âœ… Loading tasmin_historical\n",
      "âœ… Loading tasmin_ssp126\n",
      "âœ… Loading tasmin_ssp245\n",
      "âœ… Loading tasmin_ssp585\n",
      "âœ… Loading pr_historical\n",
      "âœ… Loading pr_ssp126\n",
      "âœ… Loading pr_ssp245\n",
      "âœ… Loading pr_ssp585\n",
      "âœ… Loading hurs_historical\n",
      "âœ… Loading hurs_ssp126\n",
      "âœ… Loading hurs_ssp245\n",
      "âœ… Loading hurs_ssp585\n",
      "\n",
      "ğŸ“Š Loading Summary:\n",
      "  tas: 4/4 scenarios loaded\n",
      "  tasmax: 4/4 scenarios loaded\n",
      "  tasmin: 4/4 scenarios loaded\n",
      "  pr: 4/4 scenarios loaded\n",
      "  hurs: 4/4 scenarios loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: LOAD CLIMATE DATA\n",
    "# ============================================================================\n",
    "\n",
    "def load_all_climate_data(base_path, variables, scenarios):\n",
    "    \"\"\"Load all CMIP6 NetCDF files\"\"\"\n",
    "    climate_data = {}\n",
    "    all_files = glob.glob(os.path.join(base_path, \"**/*.nc\"), recursive=True)\n",
    "    \n",
    "    for var in variables:\n",
    "        var_data = {}\n",
    "        for scenario in scenarios:\n",
    "            matches = [f for f in all_files if f\"{var}_{scenario}\" in f.lower()]\n",
    "            if matches:\n",
    "                print(f\"âœ… Loading {var}_{scenario}\")\n",
    "                var_data[scenario] = xr.open_dataset(matches[0])\n",
    "            else:\n",
    "                print(f\"âš ï¸ Missing {var}_{scenario}\")\n",
    "        climate_data[var] = var_data\n",
    "    \n",
    "    return climate_data\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: LOADING CLIMATE DATA\")\n",
    "print(\"=\"*80)\n",
    "climate_data = load_all_climate_data(CONFIG['base_path'], CONFIG['variables'], CONFIG['scenarios'])\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: LOADING CLIMATE DATA\")\n",
    "print(\"=\"*80)\n",
    "climate_data = load_all_climate_data(CONFIG['base_path'], CONFIG['variables'], CONFIG['scenarios'])\n",
    "\n",
    "# Add this summary:\n",
    "print(\"\\nğŸ“Š Loading Summary:\")\n",
    "for var in CONFIG['variables']:\n",
    "    loaded = len(climate_data.get(var, {}))\n",
    "    total = len(CONFIG['scenarios'])\n",
    "    print(f\"  {var}: {loaded}/{total} scenarios loaded\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0aaec97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 2: LOADING CONFIGURATION DATA\n",
      "================================================================================\n",
      "âœ… Loaded 29 coffee regions\n",
      "âœ… Loaded carbon price scenarios\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: LOAD CONFIGURATION DATA\n",
    "# ============================================================================\n",
    "\n",
    "def load_excel_data(base_path):\n",
    "    \"\"\"Load Excel configuration files\"\"\"\n",
    "    data = {}\n",
    "    data['carbon'] = pd.read_excel(os.path.join(base_path, 'Data/carbon_prices.xlsx'))\n",
    "    data['regions'] = pd.read_excel(os.path.join(base_path, 'Data/coffee_regions_coordinates.xlsx'))\n",
    "    return data\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: LOADING CONFIGURATION DATA\")\n",
    "print(\"=\"*80)\n",
    "excel_data = load_excel_data(CONFIG['base_path'])\n",
    "regions_df = excel_data['regions']\n",
    "carbon_prices = excel_data['carbon']\n",
    "\n",
    "print(f\"âœ… Loaded {len(regions_df)} coffee regions\")\n",
    "print(f\"âœ… Loaded carbon price scenarios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bdd2eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 3: EXTRACTING REGIONAL CLIMATE DATA (CORRECTED)\n",
      "================================================================================\n",
      "\n",
      "Extracting climate data for regions:\n",
      "Method: Excel baseline + CMIP6 warming delta\n",
      "Temperature extremes adjusted for elevation\n",
      "----------------------------------------------------------------------\n",
      "  Colombia_Huila                           (  2.50Â°,  -75.80Â°) @ 1700m\n",
      "  Colombia_Antioquia                       (  6.20Â°,  -75.60Â°) @ 1500m\n",
      "  Colombia_Tolima                          (  4.50Â°,  -75.20Â°) @ 1600m\n",
      "  Colombia_Cauca                           (  2.80Â°,  -76.50Â°) @ 1800m\n",
      "  Brazil_Minas Gerais Sul                  (-21.50Â°,  -45.50Â°) @ 1100m\n",
      "  Brazil_SÃ£o Paulo                         (-22.80Â°,  -47.20Â°) @ 1000m\n",
      "  Brazil_EspÃ­rito Santo                    (-19.50Â°,  -40.80Â°) @  900m\n",
      "  Guatemala_Huehuetenango                  ( 15.50Â°,  -91.50Â°) @ 1750m\n",
      "  Guatemala_Antigua                        ( 14.60Â°,  -90.70Â°) @ 1600m\n",
      "  Guatemala_AtitlÃ¡n                        ( 14.70Â°,  -91.20Â°) @ 1700m\n",
      "  Ethiopia_Yirgacheffe                     (  6.20Â°,   38.20Â°) @ 1950m\n",
      "  Ethiopia_Sidamo                          (  6.50Â°,   38.50Â°) @ 1850m\n",
      "  Ethiopia_Harrar                          (  9.30Â°,   42.10Â°) @ 1750m\n",
      "  Ethiopia_Kaffa                           (  7.30Â°,   36.20Â°) @ 1650m\n",
      "  Kenya_Central Highlands                  ( -0.50Â°,   37.00Â°) @ 1800m\n",
      "  Kenya_Rift Valley                        ( -0.20Â°,   35.80Â°) @ 1650m\n",
      "  Costa Rica_TarrazÃº                       (  9.60Â°,  -84.00Â°) @ 1500m\n",
      "  Costa Rica_West Valley                   ( 10.00Â°,  -84.40Â°) @ 1400m\n",
      "  Mexico_Chiapas                           ( 15.20Â°,  -92.50Â°) @ 1300m\n",
      "  Mexico_Veracruz                          ( 19.50Â°,  -97.00Â°) @ 1200m\n",
      "  Peru_Cajamarca                           ( -6.50Â°,  -78.80Â°) @ 1500m\n",
      "  Honduras_CopÃ¡n                           ( 14.80Â°,  -88.80Â°) @ 1400m\n",
      "  Rwanda_Northern Province                 ( -1.70Â°,   29.70Â°) @ 1950m\n",
      "  Tanzania_Kilimanjaro                     ( -3.40Â°,   37.30Â°) @ 1600m\n",
      "  Indonesia_Sumatra Aceh                   (  4.50Â°,   96.80Â°) @ 1250m\n",
      "  Indonesia_Java West                      ( -7.00Â°,  107.50Â°) @ 1200m\n",
      "  China_Yunnan Pu er                       ( 22.80Â°,  100.90Â°) @ 1500m\n",
      "  Vietnam_Central Highlands                ( 12.70Â°,  108.00Â°) @  700m\n",
      "  nan_nan                                  (   nanÂ°,     nanÂ°) @  nanm\n",
      "\n",
      "âœ… Extraction complete using warming delta method with elevation-dependent extremes\n",
      "\n",
      "âœ… Regional extraction complete for 29 regions\n",
      "\n",
      "================================================================================\n",
      "TASMAX BASELINE - ELEVATION DEPENDENT CHECK\n",
      "================================================================================\n",
      "Region                                   Elevation    Baseline T   Tasmax       Offset    \n",
      "--------------------------------------------------------------------------------------\n",
      "Colombia_Huila                                 1700m       19.0Â°C       24.5Â°C      5.5Â°C\n",
      "Colombia_Antioquia                             1500m       19.5Â°C       25.0Â°C      5.5Â°C\n",
      "Colombia_Tolima                                1600m       19.2Â°C       24.7Â°C      5.5Â°C\n",
      "Colombia_Cauca                                 1800m       18.5Â°C       23.5Â°C      5.0Â°C\n",
      "Brazil_Minas Gerais Sul                        1100m       20.5Â°C       28.5Â°C      8.0Â°C\n",
      "Brazil_SÃ£o Paulo                               1000m       21.0Â°C       29.0Â°C      8.0Â°C\n",
      "Brazil_EspÃ­rito Santo                           900m       21.5Â°C       29.5Â°C      8.0Â°C\n",
      "Guatemala_Huehuetenango                        1750m       18.0Â°C       23.5Â°C      5.5Â°C\n",
      "Guatemala_Antigua                              1600m       18.8Â°C       24.3Â°C      5.5Â°C\n",
      "Guatemala_AtitlÃ¡n                              1700m       18.5Â°C       24.0Â°C      5.5Â°C\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: EXTRACT REGIONAL CLIMATE DATA (WARMING DELTA METHOD) - CORRECTED WITH ELEVATION-DEPENDENT TASMAX/TASMIN\n",
    "# ============================================================================\n",
    "def extract_regional_climate_data(climate_data, regions_df, scenarios, time_periods):\n",
    "    \"\"\"Extract climate data using WARMING DELTA approach - with elevation-dependent tasmax/tasmin\"\"\"\n",
    "    regional_data = {}\n",
    "    \n",
    "    print(\"\\nExtracting climate data for regions:\")\n",
    "    print(\"Method: Excel baseline + CMIP6 warming delta\")\n",
    "    print(\"Temperature extremes adjusted for elevation\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for idx, region in regions_df.iterrows():\n",
    "        region_name = region['region_name']\n",
    "        country = region['country']\n",
    "        lat, lon = region['latitude'], region['longitude']\n",
    "        \n",
    "        region_id = f\"{country}_{region_name}\"\n",
    "        elevation = (region.get('elevation_m_low', 1000) + region.get('elevation_m_high', 1000)) / 2\n",
    "        \n",
    "        print(f\"  {region_id:40s} ({lat:6.2f}Â°, {lon:7.2f}Â°) @ {elevation:4.0f}m\")\n",
    "        \n",
    "        regional_data[region_id] = {}\n",
    "        \n",
    "        # Get Excel baseline\n",
    "        baseline_temp = region.get('baseline_temp_c', None)\n",
    "        baseline_precip = region.get('baseline_precip_mm', None)\n",
    "        \n",
    "        # ============================================================\n",
    "        # ELEVATION-DEPENDENT TASMAX/TASMIN OFFSETS\n",
    "        # ============================================================\n",
    "        # Low elevation (tropical): larger daily temperature range\n",
    "        # High elevation (mountains): smaller daily temperature range\n",
    "        \n",
    "        if elevation < 900:\n",
    "            # Very low elevation: large daily range (typically 9-11Â°C in tropics)\n",
    "            tasmax_offset = 9.0\n",
    "            tasmin_offset = -4.5\n",
    "        elif elevation < 1200:\n",
    "            # Low elevation: moderate-large range\n",
    "            tasmax_offset = 8.0\n",
    "            tasmin_offset = -4.0\n",
    "        elif elevation < 1500:\n",
    "            # Mid elevation: moderate range\n",
    "            tasmax_offset = 6.5\n",
    "            tasmin_offset = -3.5\n",
    "        elif elevation < 1800:\n",
    "            # High elevation: smaller range\n",
    "            tasmax_offset = 5.5\n",
    "            tasmin_offset = -3.0\n",
    "        else:\n",
    "            # Very high elevation: small range\n",
    "            tasmax_offset = 5.0\n",
    "            tasmin_offset = -2.5\n",
    "        \n",
    "        baseline_data = {}\n",
    "        if pd.notna(baseline_temp):\n",
    "            baseline_data['tas_baseline'] = baseline_temp\n",
    "            baseline_data['tasmax_baseline'] = baseline_temp + tasmax_offset\n",
    "            baseline_data['tasmin_baseline'] = baseline_temp + tasmin_offset\n",
    "        \n",
    "        if pd.notna(baseline_precip):\n",
    "            baseline_data['pr_baseline'] = baseline_precip\n",
    "        \n",
    "        # Extract CMIP6 HISTORICAL\n",
    "        cmip6_hist = {}\n",
    "        \n",
    "        # ============================================================\n",
    "        # HISTORICAL TEMPERATURE (mean)\n",
    "        # ============================================================\n",
    "        if 'historical' in climate_data.get('tas', {}):\n",
    "            ds = climate_data['tas']['historical']\n",
    "            var_key = 'tas' if 'tas' in ds.variables else list(ds.data_vars)[0]\n",
    "            try:\n",
    "                point_data = ds[var_key].sel(lat=lat, lon=lon, method='nearest')\n",
    "                time_slice = point_data.sel(time=slice('1985', '2014'))\n",
    "                cmip6_hist['tas'] = float(time_slice.mean().values) - 273.15\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # ============================================================\n",
    "        # HISTORICAL TEMPERATURE MAX\n",
    "        # ============================================================\n",
    "        if 'historical' in climate_data.get('tasmax', {}):\n",
    "            ds = climate_data['tasmax']['historical']\n",
    "            var_key = 'tasmax' if 'tasmax' in ds.variables else list(ds.data_vars)[0]\n",
    "            try:\n",
    "                point_data = ds[var_key].sel(lat=lat, lon=lon, method='nearest')\n",
    "                time_slice = point_data.sel(time=slice('1985', '2014'))\n",
    "                cmip6_hist['tasmax'] = float(time_slice.mean().values) - 273.15\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # ============================================================\n",
    "        # HISTORICAL TEMPERATURE MIN\n",
    "        # ============================================================\n",
    "        if 'historical' in climate_data.get('tasmin', {}):\n",
    "            ds = climate_data['tasmin']['historical']\n",
    "            var_key = 'tasmin' if 'tasmin' in ds.variables else list(ds.data_vars)[0]\n",
    "            try:\n",
    "                point_data = ds[var_key].sel(lat=lat, lon=lon, method='nearest')\n",
    "                time_slice = point_data.sel(time=slice('1985', '2014'))\n",
    "                cmip6_hist['tasmin'] = float(time_slice.mean().values) - 273.15\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # ============================================================\n",
    "        # HISTORICAL PRECIPITATION\n",
    "        # ============================================================\n",
    "        if 'historical' in climate_data.get('pr', {}):\n",
    "            ds = climate_data['pr']['historical']\n",
    "            var_key = 'pr' if 'pr' in ds.variables else list(ds.data_vars)[0]\n",
    "            try:\n",
    "                point_data = ds[var_key].sel(lat=lat, lon=lon, method='nearest')\n",
    "                time_slice = point_data.sel(time=slice('1985', '2014'))\n",
    "                cmip6_hist['pr'] = float(time_slice.mean().values) * 86400 * 365\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Extract FUTURE and calculate as baseline + warming\n",
    "        for scenario in ['ssp126', 'ssp245', 'ssp585']:\n",
    "            regional_data[region_id][scenario] = baseline_data.copy()\n",
    "            \n",
    "            # ============================================================\n",
    "            # TEMPERATURE (mean)\n",
    "            # ============================================================\n",
    "            if scenario in climate_data.get('tas', {}) and 'tas' in cmip6_hist and pd.notna(baseline_temp):\n",
    "                try:\n",
    "                    ds = climate_data['tas'][scenario]\n",
    "                    var_key = 'tas' if 'tas' in ds.variables else list(ds.data_vars)[0]\n",
    "                    point_data = ds[var_key].sel(lat=lat, lon=lon, method='nearest')\n",
    "                    \n",
    "                    for period_name, (start_year, end_year) in time_periods.items():\n",
    "                        if period_name == 'baseline':\n",
    "                            continue\n",
    "                        \n",
    "                        time_slice = point_data.sel(time=slice(str(start_year), str(end_year)))\n",
    "                        future_cmip6 = float(time_slice.mean().values) - 273.15\n",
    "                        warming = future_cmip6 - cmip6_hist['tas']\n",
    "                        final_temp = baseline_temp + warming\n",
    "                        regional_data[region_id][scenario][f'tas_{period_name}'] = final_temp\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # ============================================================\n",
    "            # TEMPERATURE MAX (with elevation-dependent offset)\n",
    "            # ============================================================\n",
    "            if scenario in climate_data.get('tasmax', {}) and pd.notna(baseline_temp):\n",
    "                try:\n",
    "                    ds = climate_data['tasmax'][scenario]\n",
    "                    var_key = 'tasmax' if 'tasmax' in ds.variables else list(ds.data_vars)[0]\n",
    "                    point_data = ds[var_key].sel(lat=lat, lon=lon, method='nearest')\n",
    "                    \n",
    "                    for period_name, (start_year, end_year) in time_periods.items():\n",
    "                        if period_name == 'baseline':\n",
    "                            continue\n",
    "                        \n",
    "                        time_slice = point_data.sel(time=slice(str(start_year), str(end_year)))\n",
    "                        future_tasmax = float(time_slice.mean().values) - 273.15\n",
    "                        \n",
    "                        # Use tasmax from historical if available, else use tas warming\n",
    "                        if 'tasmax' in cmip6_hist:\n",
    "                            warming = future_tasmax - cmip6_hist['tasmax']\n",
    "                        else:\n",
    "                            warming = future_tasmax - cmip6_hist.get('tas', 0)\n",
    "                        \n",
    "                        final_tasmax = baseline_data['tasmax_baseline'] + warming\n",
    "                        regional_data[region_id][scenario][f'tasmax_{period_name}'] = final_tasmax\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # ============================================================\n",
    "            # TEMPERATURE MIN (with elevation-dependent offset)\n",
    "            # ============================================================\n",
    "            if scenario in climate_data.get('tasmin', {}) and pd.notna(baseline_temp):\n",
    "                try:\n",
    "                    ds = climate_data['tasmin'][scenario]\n",
    "                    var_key = 'tasmin' if 'tasmin' in ds.variables else list(ds.data_vars)[0]\n",
    "                    point_data = ds[var_key].sel(lat=lat, lon=lon, method='nearest')\n",
    "                    \n",
    "                    for period_name, (start_year, end_year) in time_periods.items():\n",
    "                        if period_name == 'baseline':\n",
    "                            continue\n",
    "                        \n",
    "                        time_slice = point_data.sel(time=slice(str(start_year), str(end_year)))\n",
    "                        future_tasmin = float(time_slice.mean().values) - 273.15\n",
    "                        \n",
    "                        # Use tasmin from historical if available, else use tas warming\n",
    "                        if 'tasmin' in cmip6_hist:\n",
    "                            warming = future_tasmin - cmip6_hist['tasmin']\n",
    "                        else:\n",
    "                            warming = future_tasmin - cmip6_hist.get('tas', 0)\n",
    "                        \n",
    "                        final_tasmin = baseline_data['tasmin_baseline'] + warming\n",
    "                        regional_data[region_id][scenario][f'tasmin_{period_name}'] = final_tasmin\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # ============================================================\n",
    "            # PRECIPITATION\n",
    "            # ============================================================\n",
    "            if scenario in climate_data.get('pr', {}) and 'pr' in cmip6_hist and pd.notna(baseline_precip):\n",
    "                try:\n",
    "                    ds = climate_data['pr'][scenario]\n",
    "                    var_key = 'pr' if 'pr' in ds.variables else list(ds.data_vars)[0]\n",
    "                    point_data = ds[var_key].sel(lat=lat, lon=lon, method='nearest')\n",
    "                    \n",
    "                    for period_name, (start_year, end_year) in time_periods.items():\n",
    "                        if period_name == 'baseline':\n",
    "                            continue\n",
    "                        \n",
    "                        time_slice = point_data.sel(time=slice(str(start_year), str(end_year)))\n",
    "                        future_cmip6 = float(time_slice.mean().values) * 86400 * 365\n",
    "                        change = future_cmip6 - cmip6_hist['pr']\n",
    "                        final_precip = baseline_precip + change\n",
    "                        regional_data[region_id][scenario][f'pr_{period_name}'] = final_precip\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    print(\"\\nâœ… Extraction complete using warming delta method with elevation-dependent extremes\")\n",
    "    return regional_data\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: EXTRACTING REGIONAL CLIMATE DATA (CORRECTED)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "regional_climate = extract_regional_climate_data(\n",
    "    climate_data, \n",
    "    regions_df, \n",
    "    CONFIG['scenarios'], \n",
    "    CONFIG['time_periods']\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Regional extraction complete for {len(regional_climate)} regions\")\n",
    "\n",
    "# VALIDATION\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TASMAX BASELINE - ELEVATION DEPENDENT CHECK\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Region':<40s} {'Elevation':<12s} {'Baseline T':<12s} {'Tasmax':<12s} {'Offset':<10s}\")\n",
    "print(\"-\"*86)\n",
    "\n",
    "for idx in range(min(10, len(regions_df))):\n",
    "    region = regions_df.iloc[idx]\n",
    "    region_id = f\"{region['country']}_{region['region_name']}\"\n",
    "    elevation = (region.get('elevation_m_low', 1000) + region.get('elevation_m_high', 1000)) / 2\n",
    "    \n",
    "    if region_id in regional_climate and 'ssp245' in regional_climate[region_id]:\n",
    "        data = regional_climate[region_id]['ssp245']\n",
    "        baseline_temp = data.get('tas_baseline', np.nan)\n",
    "        tasmax_baseline = data.get('tasmax_baseline', np.nan)\n",
    "        \n",
    "        if pd.notna(baseline_temp) and pd.notna(tasmax_baseline):\n",
    "            offset = tasmax_baseline - baseline_temp\n",
    "            print(f\"{region_id:<40s} {elevation:>10.0f}m {baseline_temp:>10.1f}Â°C {tasmax_baseline:>10.1f}Â°C {offset:>8.1f}Â°C\")\n",
    "\n",
    "print(\"=\"*86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a78bff56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TASMAX 2050 - WITH ELEVATION-DEPENDENT BASELINES\n",
      "================================================================================\n",
      "Region                                   Elevation    Tasmax Base  Tasmax 2050  Warming   \n",
      "--------------------------------------------------------------------------------------\n",
      "Colombia_Huila                                 1700m       24.5Â°C       25.6Â°C      1.1Â°C\n",
      "Colombia_Antioquia                             1500m       25.0Â°C       30.0Â°C      5.0Â°C\n",
      "Colombia_Tolima                                1600m       24.7Â°C       26.1Â°C      1.4Â°C\n",
      "Colombia_Cauca                                 1800m       23.5Â°C       24.8Â°C      1.3Â°C\n",
      "Brazil_Minas Gerais Sul                        1100m       28.5Â°C       29.6Â°C      1.1Â°C\n",
      "Brazil_SÃ£o Paulo                               1000m       29.0Â°C       30.6Â°C      1.6Â°C\n",
      "Brazil_EspÃ­rito Santo                           900m       29.5Â°C       29.8Â°C      0.3Â°C\n",
      "Guatemala_Huehuetenango                        1750m       23.5Â°C       25.4Â°C      1.9Â°C\n",
      "Guatemala_Antigua                              1600m       24.3Â°C       26.0Â°C      1.7Â°C\n",
      "Guatemala_AtitlÃ¡n                              1700m       24.0Â°C       25.7Â°C      1.7Â°C\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TASMAX 2050 - WITH ELEVATION-DEPENDENT BASELINES\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Region':<40s} {'Elevation':<12s} {'Tasmax Base':<12s} {'Tasmax 2050':<12s} {'Warming':<10s}\")\n",
    "print(\"-\"*86)\n",
    "\n",
    "for idx in range(min(10, len(regions_df))):\n",
    "    region = regions_df.iloc[idx]\n",
    "    region_id = f\"{region['country']}_{region['region_name']}\"\n",
    "    elevation = (region.get('elevation_m_low', 1000) + region.get('elevation_m_high', 1000)) / 2\n",
    "    \n",
    "    if region_id in regional_climate and 'ssp245' in regional_climate[region_id]:\n",
    "        data = regional_climate[region_id]['ssp245']\n",
    "        tasmax_base = data.get('tasmax_baseline', np.nan)\n",
    "        tasmax_2050 = data.get('tasmax_mid_term', np.nan)\n",
    "        \n",
    "        if pd.notna(tasmax_base) and pd.notna(tasmax_2050):\n",
    "            warming = tasmax_2050 - tasmax_base\n",
    "            print(f\"{region_id:<40s} {elevation:>10.0f}m {tasmax_base:>10.1f}Â°C {tasmax_2050:>10.1f}Â°C {warming:>8.1f}Â°C\")\n",
    "\n",
    "print(\"=\"*86)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2305a34e",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# STEP 3: EXTRACT REGIONAL CLIMATE DATA (WARMING DELTA METHOD)\n",
    "# ============================================================================\n",
    "def extract_regional_climate_data(climate_data, regions_df, scenarios, time_periods):\n",
    "    \"\"\"Extract climate data using WARMING DELTA approach\"\"\"\n",
    "    regional_data = {}\n",
    "    \n",
    "    print(\"\\nExtracting climate data for regions:\")\n",
    "    print(\"Method: Excel baseline + CMIP6 warming delta\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for idx, region in regions_df.iterrows():\n",
    "        region_name = region['region_name']\n",
    "        country = region['country']\n",
    "        lat, lon = region['latitude'], region['longitude']\n",
    "        \n",
    "        region_id = f\"{country}_{region_name}\"\n",
    "        elevation = (region.get('elevation_m_low', 1000) + region.get('elevation_m_high', 1000)) / 2\n",
    "        \n",
    "        print(f\"  {region_id:40s} ({lat:6.2f}Â°, {lon:7.2f}Â°) @ {elevation:4.0f}m\")\n",
    "        \n",
    "        regional_data[region_id] = {}\n",
    "        \n",
    "        # Get Excel baseline\n",
    "        baseline_temp = region.get('baseline_temp_c', None)\n",
    "        baseline_precip = region.get('baseline_precip_mm', None)\n",
    "        \n",
    "        baseline_data = {}\n",
    "        if pd.notna(baseline_temp):\n",
    "            baseline_data['tas_baseline'] = baseline_temp\n",
    "            baseline_data['tasmax_baseline'] = baseline_temp + 5.5\n",
    "            baseline_data['tasmin_baseline'] = baseline_temp - 5.5\n",
    "        \n",
    "        if pd.notna(baseline_precip):\n",
    "            baseline_data['pr_baseline'] = baseline_precip\n",
    "        \n",
    "        # Extract CMIP6 HISTORICAL\n",
    "        cmip6_hist = {}\n",
    "        \n",
    "        if 'historical' in climate_data.get('tas', {}):\n",
    "            ds = climate_data['tas']['historical']\n",
    "            var_key = 'tas' if 'tas' in ds.variables else list(ds.data_vars)[0]\n",
    "            try:\n",
    "                point_data = ds[var_key].sel(lat=lat, lon=lon, method='nearest')\n",
    "                time_slice = point_data.sel(time=slice('1985', '2014'))\n",
    "                cmip6_hist['tas'] = float(time_slice.mean().values) - 273.15\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if 'historical' in climate_data.get('pr', {}):\n",
    "            ds = climate_data['pr']['historical']\n",
    "            var_key = 'pr' if 'pr' in ds.variables else list(ds.data_vars)[0]\n",
    "            try:\n",
    "                point_data = ds[var_key].sel(lat=lat, lon=lon, method='nearest')\n",
    "                time_slice = point_data.sel(time=slice('1985', '2014'))\n",
    "                cmip6_hist['pr'] = float(time_slice.mean().values) * 86400 * 365\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Extract FUTURE and calculate as baseline + warming\n",
    "        for scenario in ['ssp126', 'ssp245', 'ssp585']:\n",
    "            regional_data[region_id][scenario] = baseline_data.copy()\n",
    "            \n",
    "            # Temperature\n",
    "            if scenario in climate_data.get('tas', {}) and 'tas' in cmip6_hist and pd.notna(baseline_temp):\n",
    "                try:\n",
    "                    ds = climate_data['tas'][scenario]\n",
    "                    var_key = 'tas' if 'tas' in ds.variables else list(ds.data_vars)[0]\n",
    "                    point_data = ds[var_key].sel(lat=lat, lon=lon, method='nearest')\n",
    "                    \n",
    "                    for period_name, (start_year, end_year) in time_periods.items():\n",
    "                        if period_name == 'baseline':\n",
    "                            continue\n",
    "                        \n",
    "                        time_slice = point_data.sel(time=slice(str(start_year), str(end_year)))\n",
    "                        future_cmip6 = float(time_slice.mean().values) - 273.15\n",
    "                        warming = future_cmip6 - cmip6_hist['tas']\n",
    "                        final_temp = baseline_temp + warming\n",
    "                        regional_data[region_id][scenario][f'tas_{period_name}'] = final_temp\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # Precipitation\n",
    "            if scenario in climate_data.get('pr', {}) and 'pr' in cmip6_hist and pd.notna(baseline_precip):\n",
    "                try:\n",
    "                    ds = climate_data['pr'][scenario]\n",
    "                    var_key = 'pr' if 'pr' in ds.variables else list(ds.data_vars)[0]\n",
    "                    point_data = ds[var_key].sel(lat=lat, lon=lon, method='nearest')\n",
    "                    \n",
    "                    for period_name, (start_year, end_year) in time_periods.items():\n",
    "                        if period_name == 'baseline':\n",
    "                            continue\n",
    "                        \n",
    "                        time_slice = point_data.sel(time=slice(str(start_year), str(end_year)))\n",
    "                        future_cmip6 = float(time_slice.mean().values) * 86400 * 365\n",
    "                        change = future_cmip6 - cmip6_hist['pr']\n",
    "                        final_precip = baseline_precip + change\n",
    "                        regional_data[region_id][scenario][f'pr_{period_name}'] = final_precip\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    print(\"\\nâœ… Extraction complete using warming delta method\")\n",
    "    return regional_data\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: EXTRACTING REGIONAL CLIMATE DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "regional_climate = extract_regional_climate_data(\n",
    "    climate_data, \n",
    "    regions_df, \n",
    "    CONFIG['scenarios'], \n",
    "    CONFIG['time_periods']\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Regional extraction complete for {len(regional_climate)} regions\")\n",
    "\n",
    "# VALIDATION\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BASELINE & WARMING VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Region':<40s} {'Baseline':<10s} {'2050':<10s} {'Warming':<10s} {'Status':<10s}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for idx in range(min(5, len(regions_df))):\n",
    "    region = regions_df.iloc[idx]\n",
    "    region_id = f\"{region['country']}_{region['region_name']}\"\n",
    "    excel_baseline = region['baseline_temp_c']\n",
    "    \n",
    "    if region_id in regional_climate and 'ssp245' in regional_climate[region_id]:\n",
    "        data = regional_climate[region_id]['ssp245']\n",
    "        extracted_baseline = data.get('tas_baseline', np.nan)\n",
    "        temp_2050 = data.get('tas_mid_term', np.nan)\n",
    "        \n",
    "        if pd.notna(extracted_baseline) and pd.notna(temp_2050):\n",
    "            warming = temp_2050 - extracted_baseline\n",
    "            baseline_match = abs(extracted_baseline - excel_baseline) < 0.5\n",
    "            warming_positive = warming > 0\n",
    "            \n",
    "            if baseline_match and warming_positive:\n",
    "                status = \"âœ“ CORRECT\"\n",
    "            else:\n",
    "                status = \"âœ— ERROR\"\n",
    "            \n",
    "            print(f\"{region_id:<40s} {extracted_baseline:>8.1f}Â°C {temp_2050:>8.1f}Â°C {warming:>8.1f}Â°C {status:<10s}\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Expected: All regions show 'âœ“ CORRECT' with positive warming\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb05deb",
   "metadata": {},
   "source": [
    "After the stress calculation, add a diagnostic to verify the fix worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed00ff82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 4: CALCULATING CLIMATE STRESS INDICES (WITH HEAT & FROST)\n",
      "================================================================================\n",
      "\n",
      "Calculating stress indices for regions:\n",
      "âœ… Stress calculation complete\n",
      "\n",
      "================================================================================\n",
      "UPDATED STRESS COMPARISON\n",
      "================================================================================\n",
      "Region                                   Baseline     2050         Heat Stress  Total     \n",
      "--------------------------------------------------------------------------------------\n",
      "Colombia_Huila                                0.044       0.027       0.000     0.027\n",
      "Colombia_Antioquia                            0.030       0.134       0.333     0.134\n",
      "Colombia_Tolima                               0.037       0.044       0.015     0.044\n",
      "Colombia_Cauca                                0.048       0.063       0.000     0.063\n",
      "Brazil_Minas Gerais Sul                       0.033       0.098       0.269     0.098\n",
      "Brazil_SÃ£o Paulo                              0.067       0.156       0.430     0.156\n",
      "Brazil_EspÃ­rito Santo                         0.111       0.137       0.301     0.137\n",
      "Guatemala_Huehuetenango                       0.042       0.039       0.000     0.039\n",
      "Guatemala_Antigua                             0.026       0.045       0.001     0.045\n",
      "Guatemala_AtitlÃ¡n                             0.033       0.047       0.000     0.047\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: CALCULATE CLIMATE STRESS INDICES (WITH HEAT AND FROST)\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_climate_stress(regional_climate, coffee_optimal):\n",
    "    \"\"\"\n",
    "    Calculate temperature and precipitation stress for each region\n",
    "    \n",
    "    Stress Index Scale (0-1):\n",
    "    - 0.0-0.2: Low stress (minimal yield impact)\n",
    "    - 0.2-0.4: Moderate stress (10-20% yield loss)\n",
    "    - 0.4-0.6: High stress (20-40% yield loss)\n",
    "    - 0.6-0.8: Severe stress (40-60% yield loss)\n",
    "    - 0.8-1.0: Critical stress (>60% yield loss, crop failure likely)\n",
    "    \n",
    "    Based on coffee physiology literature:\n",
    "    - Temperature: Optimal 18-21Â°C, tolerance 15-24Â°C\n",
    "    - Extreme heat: >26Â°C degrades quality, >28Â°C reduces yield, >32Â°C flower abortion\n",
    "    - Precipitation: Optimal 1500-1800mm, tolerance 1200-2000mm\n",
    "    \"\"\"\n",
    "    stress_results = {}\n",
    "    \n",
    "    print(\"\\nCalculating stress indices for regions:\")\n",
    "    for region, scenarios in regional_climate.items():\n",
    "        stress_results[region] = {}\n",
    "        \n",
    "        for scenario, data in scenarios.items():\n",
    "            # Skip metadata\n",
    "            if scenario == 'metadata':\n",
    "                continue\n",
    "                \n",
    "            for period in ['baseline', 'near_term', 'mid_term']:\n",
    "                temp_key = f'tas_{period}'\n",
    "                tasmax_key = f'tasmax_{period}'\n",
    "                tasmin_key = f'tasmin_{period}'\n",
    "                precip_key = f'pr_{period}'\n",
    "                \n",
    "                temp_stress = 0\n",
    "                heat_stress = 0\n",
    "                frost_stress = 0\n",
    "                precip_stress = 0\n",
    "                \n",
    "                # ============================================================\n",
    "                # TEMPERATURE STRESS (mean temperature)\n",
    "                # ============================================================\n",
    "                if temp_key in data:\n",
    "                    temp = data[temp_key]\n",
    "                    \n",
    "                    if temp < coffee_optimal['temp_min']:\n",
    "                        # Below minimum: Linear stress increase\n",
    "                        # Stress = 1.0 at 10Â°C (5Â° below minimum)\n",
    "                        temp_stress = min(1.0, (coffee_optimal['temp_min'] - temp) / 5.0)\n",
    "                        \n",
    "                    elif temp > coffee_optimal['temp_max']:\n",
    "                        # Above maximum: Linear stress increase\n",
    "                        # Stress = 1.0 at 30Â°C (6Â° above maximum)\n",
    "                        temp_stress = min(1.0, (temp - coffee_optimal['temp_max']) / 6.0)\n",
    "                        \n",
    "                    else:\n",
    "                        # Within tolerance range: minimal stress\n",
    "                        # Stress increases as we move away from optimal\n",
    "                        optimal = coffee_optimal['temp_optimal']\n",
    "                        tolerance_range = (coffee_optimal['temp_max'] - coffee_optimal['temp_min']) / 2\n",
    "                        temp_stress = abs(temp - optimal) / tolerance_range * 0.15\n",
    "                \n",
    "                # ============================================================\n",
    "                # EXTREME HEAT STRESS (tasmax - CRITICAL FOR COFFEE)\n",
    "                # ============================================================\n",
    "                # Coffee is very sensitive to extreme heat during flowering\n",
    "                # >26Â°C: quality degradation begins\n",
    "                # >28Â°C: significant yield loss\n",
    "                # >32Â°C: flower abortion (no beans form)\n",
    "                if tasmax_key in data:\n",
    "                    tasmax = data[tasmax_key]\n",
    "                    \n",
    "                    if tasmax > 32:\n",
    "                        # Critical heat: flower abortion likely\n",
    "                        # Stress = 1.0 at 38Â°C (6Â° above critical threshold)\n",
    "                        heat_stress = min(1.0, (tasmax - 32) / 6.0)\n",
    "                        \n",
    "                    elif tasmax > 28:\n",
    "                        # High heat: significant yield impact\n",
    "                        # Stress = 0.5 at 28Â°C, 1.0 at 34Â°C\n",
    "                        heat_stress = min(1.0, (tasmax - 28) / 6.0)\n",
    "                        \n",
    "                    elif tasmax > 26:\n",
    "                        # Moderate heat: quality degradation\n",
    "                        # Stress = 0.2 at 26Â°C, 0.5 at 28Â°C\n",
    "                        heat_stress = min(1.0, (tasmax - 26) / 4.0 * 0.5)\n",
    "                    else:\n",
    "                        heat_stress = 0\n",
    "                \n",
    "                # ============================================================\n",
    "                # FROST/CHILLING STRESS (tasmin)\n",
    "                # ============================================================\n",
    "                # Frost during growing season causes permanent damage\n",
    "                # Chilling hours <13Â°C reduce flowering intensity\n",
    "                if tasmin_key in data:\n",
    "                    tasmin = data[tasmin_key]\n",
    "                    \n",
    "                    if tasmin < 0:\n",
    "                        # Hard frost: permanent tree damage\n",
    "                        # Stress = 1.0 at -5Â°C\n",
    "                        frost_stress = min(1.0, (0 - tasmin) / 5.0)\n",
    "                        \n",
    "                    elif tasmin < 2:\n",
    "                        # Frost risk: some damage possible\n",
    "                        frost_stress = 0.3 + (2 - tasmin) / 2.0 * 0.3\n",
    "                        \n",
    "                    elif tasmin < 13:\n",
    "                        # Chilling stress: reduces flowering intensity\n",
    "                        # Stress increases as nights get colder\n",
    "                        frost_stress = (13 - tasmin) / 10.0 * 0.15\n",
    "                    else:\n",
    "                        frost_stress = 0\n",
    "                \n",
    "                # ============================================================\n",
    "                # PRECIPITATION STRESS\n",
    "                # ============================================================\n",
    "                if precip_key in data:\n",
    "                    precip = data[precip_key]\n",
    "                    \n",
    "                    if precip < coffee_optimal['precip_min']:\n",
    "                        # Drought stress: Linear increase\n",
    "                        # Stress = 1.0 at 600mm (50% of minimum)\n",
    "                        precip_stress = min(1.0, (coffee_optimal['precip_min'] - precip) / 600.0)\n",
    "                        \n",
    "                    elif precip > coffee_optimal['precip_max']:\n",
    "                        # Excess rainfall stress: Linear increase\n",
    "                        # Stress = 1.0 at 3000mm (50% above maximum)\n",
    "                        precip_stress = min(1.0, (precip - coffee_optimal['precip_max']) / 1000.0)\n",
    "                        \n",
    "                    else:\n",
    "                        # Within tolerance range: minimal stress\n",
    "                        optimal = coffee_optimal['precip_optimal']\n",
    "                        tolerance_range = (coffee_optimal['precip_max'] - coffee_optimal['precip_min']) / 2\n",
    "                        precip_stress = abs(precip - optimal) / tolerance_range * 0.10\n",
    "                \n",
    "                # ============================================================\n",
    "                # COMBINED STRESS\n",
    "                # ============================================================\n",
    "                # Temperature components: mean (40%) + heat extremes (50%) + frost (10%)\n",
    "                # Precipitation: 40%\n",
    "                combined_temp_stress = (\n",
    "                    temp_stress * 0.4 + \n",
    "                    heat_stress * 0.5 + \n",
    "                    frost_stress * 0.1\n",
    "                )\n",
    "                \n",
    "                total_stress = (combined_temp_stress * 0.6) + (precip_stress * 0.4)\n",
    "                \n",
    "                # Store results\n",
    "                stress_results[region][f'{scenario}_{period}_temp_stress'] = min(combined_temp_stress, 1.0)\n",
    "                stress_results[region][f'{scenario}_{period}_heat_stress'] = min(heat_stress, 1.0)\n",
    "                stress_results[region][f'{scenario}_{period}_frost_stress'] = min(frost_stress, 1.0)\n",
    "                stress_results[region][f'{scenario}_{period}_precip_stress'] = min(precip_stress, 1.0)\n",
    "                stress_results[region][f'{scenario}_{period}_total_stress'] = min(total_stress, 1.0)\n",
    "    \n",
    "    return stress_results\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: CALCULATING CLIMATE STRESS INDICES (WITH HEAT & FROST)\")\n",
    "print(\"=\"*80)\n",
    "stress_data = calculate_climate_stress(regional_climate, CONFIG['coffee_optimal'])\n",
    "print(\"âœ… Stress calculation complete\")\n",
    "\n",
    "# Show updated results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"UPDATED STRESS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Region':<40s} {'Baseline':<12s} {'2050':<12s} {'Heat Stress':<12s} {'Total':<10s}\")\n",
    "print(\"-\"*86)\n",
    "\n",
    "for region in list(regional_climate.keys())[:10]:\n",
    "    if region != 'nan_nan':\n",
    "        baseline_stress = stress_data[region]['ssp245_baseline_total_stress']\n",
    "        stress_2050 = stress_data[region]['ssp245_mid_term_total_stress']\n",
    "        heat_stress = stress_data[region]['ssp245_mid_term_heat_stress']\n",
    "        \n",
    "        print(f\"{region:<40s} {baseline_stress:>10.3f}  {stress_2050:>10.3f}  {heat_stress:>10.3f}  {stress_2050:>8.3f}\")\n",
    "\n",
    "print(\"=\"*86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "587c58d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STRESS TO YIELD LOSS CONVERSION\n",
      "================================================================================\n",
      "Region                                   Stress 2050     Yield Loss     \n",
      "----------------------------------------------------------------------\n",
      "Colombia_Huila                                   0.027            1.4%\n",
      "Colombia_Antioquia                               0.134            6.7%\n",
      "Colombia_Tolima                                  0.044            2.2%\n",
      "Colombia_Cauca                                   0.063            3.2%\n",
      "Brazil_Minas Gerais Sul                          0.098            4.9%\n",
      "Brazil_SÃ£o Paulo                                 0.156            7.8%\n",
      "Brazil_EspÃ­rito Santo                            0.137            6.8%\n",
      "Guatemala_Huehuetenango                          0.039            1.9%\n",
      "Guatemala_Antigua                                0.045            2.3%\n",
      "Guatemala_AtitlÃ¡n                                0.047            2.4%\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STRESS TO YIELD LOSS CONVERSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def stress_to_yield_loss(stress):\n",
    "    \"\"\"Convert stress index to yield loss percentage\"\"\"\n",
    "    if stress < 0.2:\n",
    "        loss = stress * 0.5 * 100\n",
    "    elif stress < 0.4:\n",
    "        loss = (0.10 + (stress - 0.2) * 0.75) * 100\n",
    "    elif stress < 0.6:\n",
    "        loss = (0.25 + (stress - 0.4) * 1.25) * 100\n",
    "    elif stress < 0.8:\n",
    "        loss = (0.50 + (stress - 0.6) * 1.25) * 100\n",
    "    else:\n",
    "        loss = min(95, (0.75 + (stress - 0.8) * 1.0) * 100)\n",
    "    return loss\n",
    "\n",
    "print(f\"{'Region':<40s} {'Stress 2050':<15s} {'Yield Loss':<15s}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for region in list(regional_climate.keys())[:10]:\n",
    "    if region != 'nan_nan':\n",
    "        stress_2050 = stress_data[region]['ssp245_mid_term_total_stress']\n",
    "        yield_loss = stress_to_yield_loss(stress_2050)\n",
    "        print(f\"{region:<40s} {stress_2050:>13.3f}  {yield_loss:>13.1f}%\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34be8cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this at the top of Step 5, before the function\n",
    "import os\n",
    "os.makedirs(f\"{CONFIG['base_path']}/outputs/intermediate\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d18e56",
   "metadata": {},
   "source": [
    "below is the new code i am adding for step 5-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0c7db52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 5: Calculating coffee yield impacts (TCFD-ready)...\n",
      "----------------------------------------------------------------------\n",
      "âœ“ Calculated yield impacts for 168 region-scenario records.\n",
      "\n",
      "Most vulnerable regions (2050, Current Policies scenario):\n",
      "  â€¢ Sumatra Aceh, Indonesia: -23.5% loss (1625 MT)\n",
      "  â€¢ Central Highlands, Vietnam: -19.5% loss (508 MT)\n",
      "  â€¢ Java West, Indonesia: -14.8% loss (503 MT)\n",
      "  â€¢ Yunnan Pu er, China: -9.0% loss (307 MT)\n",
      "  â€¢ Antioquia, Colombia: -8.6% loss (809 MT)\n",
      "\n",
      "âœ“ Saved yield impacts to outputs/\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5 (UPGRADED): CALCULATE YIELD IMPACTS â€” TCFD-READY & PIPELINE-SAFE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nSTEP 5: Calculating coffee yield impacts (TCFD-ready)...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "def convert_stress_to_yield_loss(stress_value):\n",
    "    \"\"\"\n",
    "    Convert stress index (0â€“1) to yield loss fraction (0â€“0.95).\n",
    "    Piecewise response preserves your original assumptions.\n",
    "    \"\"\"\n",
    "    if stress_value < 0.2:\n",
    "        loss = stress_value * 0.5\n",
    "    elif stress_value < 0.4:\n",
    "        loss = 0.10 + (stress_value - 0.2) * 0.75\n",
    "    elif stress_value < 0.6:\n",
    "        loss = 0.25 + (stress_value - 0.4) * 1.25\n",
    "    elif stress_value < 0.8:\n",
    "        loss = 0.50 + (stress_value - 0.6) * 1.25\n",
    "    else:\n",
    "        loss = 0.75 + (stress_value - 0.8) * 1.0\n",
    "\n",
    "    # Hard cap at 95% to avoid unrealistic collapse\n",
    "    return min(loss, 0.95)\n",
    "\n",
    "\n",
    "yield_results = []\n",
    "\n",
    "# Helpful mappings for TCFD-style reporting\n",
    "scenario_names = {\n",
    "    \"ssp126\": \"Net-Zero 2050\",\n",
    "    \"ssp245\": \"Delayed Transition\",\n",
    "    \"ssp585\": \"Current Policies\"\n",
    "}\n",
    "period_to_year = {\n",
    "    \"near_term\": 2030,\n",
    "    \"mid_term\": 2050\n",
    "}\n",
    "\n",
    "# Loop through stress_data results (from your earlier modules)\n",
    "for region, stress_values in stress_data.items():\n",
    "\n",
    "    # Parse region id format \"Country_RegionName\"\n",
    "    region_parts = region.split('_', 1)\n",
    "    country = region_parts[0]\n",
    "    region_name = region_parts[1] if len(region_parts) > 1 else region_parts[0]\n",
    "\n",
    "    # Pull region volumes from regions_df safely\n",
    "    region_info = regions_df[\n",
    "        (regions_df['country'] == country) &\n",
    "        (regions_df['region_name'] == region_name)\n",
    "    ]\n",
    "\n",
    "    if region_info.empty:\n",
    "        continue\n",
    "\n",
    "    row0 = region_info.iloc[0]\n",
    "\n",
    "    # ---- PIPELINE-SAFE COLUMN FALLBACKS ----\n",
    "    # Your notebook sometimes uses midpoint columns. If absent, fall back cleanly.\n",
    "    if 'annual_mt_midpoint' in regions_df.columns:\n",
    "        annual_mt = row0['annual_mt_midpoint']\n",
    "    elif 'annual_mt' in regions_df.columns:\n",
    "        annual_mt = row0['annual_mt']\n",
    "    else:\n",
    "        # last-ditch fallback\n",
    "        annual_mt = row0.get('annual_volume_mt', np.nan)\n",
    "\n",
    "    if 'sourcing_pct_midpoint' in regions_df.columns:\n",
    "        sourcing_pct = row0['sourcing_pct_midpoint']\n",
    "    elif 'sourcing_pct' in regions_df.columns:\n",
    "        sourcing_pct = row0['sourcing_pct']\n",
    "    else:\n",
    "        sourcing_pct = row0.get('sourcing_pct', np.nan)\n",
    "\n",
    "    # Process each scenario/period stress value\n",
    "    for key, stress_value in stress_values.items():\n",
    "\n",
    "        if 'total_stress' not in key:\n",
    "            continue\n",
    "\n",
    "        # Parse key like: \"ssp245_near_term_total_stress\"\n",
    "        parts = key.replace('_total_stress', '').split('_')\n",
    "        scenario = parts[0]\n",
    "        period = '_'.join(parts[1:])\n",
    "\n",
    "        if scenario == 'historical' or period == 'baseline':\n",
    "            continue\n",
    "\n",
    "        # Convert stress â†’ yield loss fraction\n",
    "        yield_loss_pct = convert_stress_to_yield_loss(stress_value)\n",
    "\n",
    "        # Volume at risk\n",
    "        volume_at_risk_mt = annual_mt * yield_loss_pct\n",
    "\n",
    "        # TCFD-friendly risk buckets (based on yield loss)\n",
    "        if yield_loss_pct >= 0.80:\n",
    "            risk_bucket = \"Extreme Risk (â‰¥80% loss)\"\n",
    "        elif yield_loss_pct >= 0.60:\n",
    "            risk_bucket = \"Very High Risk (60â€“80%)\"\n",
    "        elif yield_loss_pct >= 0.40:\n",
    "            risk_bucket = \"High Risk (40â€“60%)\"\n",
    "        elif yield_loss_pct >= 0.20:\n",
    "            risk_bucket = \"Moderate Risk (20â€“40%)\"\n",
    "        else:\n",
    "            risk_bucket = \"Low Risk (<20%)\"\n",
    "\n",
    "        yield_results.append({\n",
    "            # ---- DO NOT RENAME: used downstream ----\n",
    "            'country': country,\n",
    "            'region_name': region_name,\n",
    "            'scenario': scenario,\n",
    "            'period': period,\n",
    "            'stress_index': stress_value,\n",
    "            'yield_loss_pct': yield_loss_pct,\n",
    "            'volume_at_risk_mt': volume_at_risk_mt,\n",
    "            'annual_mt': annual_mt,\n",
    "            'sourcing_pct': sourcing_pct,\n",
    "\n",
    "            # ---- NEW (TCFD helpful, safe to add) ----\n",
    "            'scenario_name': scenario_names.get(scenario, scenario),\n",
    "            'year': period_to_year.get(period, np.nan),\n",
    "            'risk_bucket': risk_bucket\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "yield_df = pd.DataFrame(yield_results)\n",
    "\n",
    "print(f\"âœ“ Calculated yield impacts for {len(yield_df)} region-scenario records.\\n\")\n",
    "\n",
    "# Show most vulnerable regions (2050, SSP585)\n",
    "print(\"Most vulnerable regions (2050, Current Policies scenario):\")\n",
    "vulnerable = yield_df[\n",
    "    (yield_df['scenario'] == 'ssp585') &\n",
    "    (yield_df['period'] == 'mid_term')\n",
    "].nlargest(5, 'yield_loss_pct')\n",
    "\n",
    "for _, row in vulnerable.iterrows():\n",
    "    impact_pct = -row['yield_loss_pct'] * 100\n",
    "    print(f\"  â€¢ {row['region_name']}, {row['country']}: {impact_pct:.1f}% loss \"\n",
    "          f\"({row['volume_at_risk_mt']:.0f} MT)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Save results (same outputs as before)\n",
    "output_dir = f\"{CONFIG['base_path']}/outputs/intermediate\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(f\"{output_dir}/yield_impacts.pkl\", 'wb') as f:\n",
    "    pickle.dump(yield_df, f)\n",
    "\n",
    "yield_df.to_csv(f\"{CONFIG['base_path']}/outputs/yield_impacts_summary.csv\", index=False)\n",
    "\n",
    "print(f\"âœ“ Saved yield impacts to outputs/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0e6749",
   "metadata": {},
   "source": [
    "To check the code worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9a8a89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "YIELD LOSS VALIDATION\n",
      "================================================================================\n",
      "Checking if yield losses are reasonable after elevation correction:\n",
      "\n",
      "SSP2-4.5, 2050 - Yield Loss Distribution:\n",
      "  Average yield loss: 5.1%\n",
      "  Median yield loss:  3.4%\n",
      "  Max yield loss:     17.9%\n",
      "  Min yield loss:     0.7%\n",
      "\n",
      "Risk Bucket Distribution:\n",
      "risk_bucket\n",
      "Low Risk (<20%)    28\n",
      "\n",
      "================================================================================\n",
      "Expected after fix:\n",
      "  - Average: 15-25% (not 40-50%)\n",
      "  - Most regions: Low or Moderate Risk (not High/Extreme)\n",
      "  - Max: 50-70% for Guatemala (not 95%)\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"YIELD LOSS VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "print(\"Checking if yield losses are reasonable after elevation correction:\\n\")\n",
    "\n",
    "# Check 2050, SSP245 scenario (most likely)\n",
    "check_df = yield_df[(yield_df['scenario'] == 'ssp245') & (yield_df['period'] == 'mid_term')]\n",
    "\n",
    "print(f\"SSP2-4.5, 2050 - Yield Loss Distribution:\")\n",
    "print(f\"  Average yield loss: {check_df['yield_loss_pct'].mean()*100:.1f}%\")\n",
    "print(f\"  Median yield loss:  {check_df['yield_loss_pct'].median()*100:.1f}%\")\n",
    "print(f\"  Max yield loss:     {check_df['yield_loss_pct'].max()*100:.1f}%\")\n",
    "print(f\"  Min yield loss:     {check_df['yield_loss_pct'].min()*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nRisk Bucket Distribution:\")\n",
    "print(check_df['risk_bucket'].value_counts().to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Expected after fix:\")\n",
    "print(\"  - Average: 15-25% (not 40-50%)\")\n",
    "print(\"  - Most regions: Low or Moderate Risk (not High/Extreme)\")\n",
    "print(\"  - Max: 50-70% for Guatemala (not 95%)\")\n",
    "print(\"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54366bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 6: Calculating financial impacts (elasticity + gross margin)...\n",
      "----------------------------------------------------------------------\n",
      "âœ“ Baseline green coffee price: $3.50/kg\n",
      "âœ“ Revenue per kg: $73.66/kg\n",
      "âœ“ Gross margin per kg: $20.63/kg\n",
      "âœ“ Gross margin percent: 28.0%\n",
      "âœ“ Implied markup: 21.0x\n",
      "âœ“ Elasticity used: -0.8\n",
      "âœ“ Financial impacts calculated (baseline + elasticity + gross-margin profit)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 6 (UPGRADED): FINANCIAL IMPACTS (Elasticity + Gross Margin + TCFD Ready)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nSTEP 6: Calculating financial impacts (elasticity + gross margin)...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Load financial parameters\n",
    "# ---------------------------------------------------------------\n",
    "coffee_price_per_kg = CONFIG['financial_params']['coffee_price_baseline_usd_kg']\n",
    "coffee_revenue = CONFIG['financial_params']['coffee_revenue']\n",
    "total_volume_mt = CONFIG['financial_params']['starbucks_annual_coffee_mt']\n",
    "elasticity = CONFIG['financial_params']['price_elasticity']\n",
    "gross_margin_pct = CONFIG['financial_params']['gross_margin_pct']\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1. Baseline revenue & gross margin metrics\n",
    "# ---------------------------------------------------------------\n",
    "revenue_per_kg = coffee_revenue / (total_volume_mt * 1000)\n",
    "gross_margin_per_kg = revenue_per_kg * gross_margin_pct\n",
    "implied_markup = revenue_per_kg / coffee_price_per_kg\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2. Supply shock and elasticity adjustment\n",
    "# ---------------------------------------------------------------\n",
    "yield_df['supply_shock_pct'] = yield_df['volume_at_risk_mt'] / total_volume_mt\n",
    "\n",
    "# Elasticity formula: %Î”P = %Î”Q / elasticity\n",
    "# Using point elasticity: %Î”P = -(elasticity * supply_shock)\n",
    "yield_df['price_increase_pct'] = -elasticity * yield_df['supply_shock_pct']\n",
    "\n",
    "yield_df['elasticity_multiplier'] = 1 + yield_df['price_increase_pct']\n",
    "\n",
    "yield_df['adjusted_coffee_price_usd_kg'] = (\n",
    "    coffee_price_per_kg * yield_df['elasticity_multiplier']\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3. Cost impacts\n",
    "# ---------------------------------------------------------------\n",
    "yield_df['cost_green_coffee_usd'] = (\n",
    "    yield_df['volume_at_risk_mt'] * 1000 * coffee_price_per_kg\n",
    ")\n",
    "\n",
    "yield_df['cost_green_coffee_adjusted_usd'] = (\n",
    "    yield_df['volume_at_risk_mt'] * 1000 * yield_df['adjusted_coffee_price_usd_kg']\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 4. Profit impact (gross-margin method)\n",
    "# ---------------------------------------------------------------\n",
    "yield_df['profit_at_risk_usd'] = (\n",
    "    yield_df['volume_at_risk_mt'] * 1000 * gross_margin_per_kg\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5. Convert to millions for reporting\n",
    "# ---------------------------------------------------------------\n",
    "yield_df['cost_green_M'] = yield_df['cost_green_coffee_usd'] / 1_000_000\n",
    "yield_df['cost_green_adjusted_M'] = yield_df['cost_green_coffee_adjusted_usd'] / 1_000_000\n",
    "yield_df['profit_at_risk_M'] = yield_df['profit_at_risk_usd'] / 1_000_000\n",
    "\n",
    "yield_df['pct_of_total_volume'] = (\n",
    "    yield_df['volume_at_risk_mt'] / total_volume_mt * 100\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Diagnostics\n",
    "# ---------------------------------------------------------------\n",
    "print(f\"âœ“ Baseline green coffee price: ${coffee_price_per_kg:.2f}/kg\")\n",
    "print(f\"âœ“ Revenue per kg: ${revenue_per_kg:.2f}/kg\")\n",
    "print(f\"âœ“ Gross margin per kg: ${gross_margin_per_kg:.2f}/kg\")\n",
    "print(f\"âœ“ Gross margin percent: {gross_margin_pct*100:.1f}%\")\n",
    "print(f\"âœ“ Implied markup: {implied_markup:.1f}x\")\n",
    "print(f\"âœ“ Elasticity used: {elasticity}\")\n",
    "print(\"âœ“ Financial impacts calculated (baseline + elasticity + gross-margin profit)\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2edb9d",
   "metadata": {},
   "source": [
    "add validation to confirm financial impacts are reasonable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0b32d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINANCIAL IMPACT - TOP 10 MOST VULNERABLE (SSP245, 2050)\n",
      "================================================================================\n",
      "Region                                   Yield Loss   Profit Risk     Price Impact   \n",
      "----------------------------------------------------------------------------------\n",
      "Sumatra Aceh                                   17.9%            25M           0.6%\n",
      "TarrazÃº                                        13.1%            19M           0.4%\n",
      "Minas Gerais Sul                                4.9%            14M           0.3%\n",
      "Antioquia                                       6.7%            13M           0.3%\n",
      "SÃ£o Paulo                                       7.8%            11M           0.3%\n",
      "Central Highlands                              17.5%             9M           0.2%\n",
      "Java West                                      11.4%             8M           0.2%\n",
      "EspÃ­rito Santo                                  6.8%             7M           0.2%\n",
      "West Valley                                     4.8%             6M           0.1%\n",
      "Yunnan Pu er                                    8.0%             6M           0.1%\n",
      "\n",
      "================================================================================\n",
      "STARBUCKS vs COMPETITORS - FINANCIAL COMPARISON (SSP245, 2050)\n",
      "================================================================================\n",
      "\n",
      "Starbucks sources:\n",
      "  Huila                         :        3M profit at risk ( 1.4% loss)\n",
      "  Yirgacheffe                   :        1M profit at risk ( 0.8% loss)\n",
      "  Sidamo                        :        1M profit at risk ( 0.7% loss)\n",
      "  Central Highlands             :        3M profit at risk ( 2.4% loss)\n",
      "  Central Highlands             :        9M profit at risk (17.5% loss)\n",
      "  TOTAL                         :       16M\n",
      "\n",
      "Competitor sources:\n",
      "  Minas Gerais Sul              :       14M profit at risk ( 4.9% loss)\n",
      "  SÃ£o Paulo                     :       11M profit at risk ( 7.8% loss)\n",
      "  EspÃ­rito Santo                :        7M profit at risk ( 6.8% loss)\n",
      "  TOTAL                         :       32M\n",
      "\n",
      "Competitive advantage: 16M in protected profit\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FINANCIAL IMPACT - TOP 10 MOST VULNERABLE (SSP245, 2050)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Region':<40s} {'Yield Loss':<12s} {'Profit Risk':<15s} {'Price Impact':<15s}\")\n",
    "print(\"-\"*82)\n",
    "\n",
    "top_vulnerable = yield_df[\n",
    "    (yield_df['scenario'] == 'ssp245') &\n",
    "    (yield_df['period'] == 'mid_term')\n",
    "].nlargest(10, 'profit_at_risk_M')\n",
    "\n",
    "for _, row in top_vulnerable.iterrows():\n",
    "    print(f\"{row['region_name']:<40s} {row['yield_loss_pct']*100:>10.1f}% {row['profit_at_risk_M']:>13.0f}M {row['price_increase_pct']*100:>13.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARBUCKS vs COMPETITORS - FINANCIAL COMPARISON (SSP245, 2050)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "starbucks_regions = ['Huila', 'Yirgacheffe', 'Sidamo', 'Central Highlands']\n",
    "competitor_regions = ['Minas Gerais Sul', 'SÃ£o Paulo', 'EspÃ­rito Santo']\n",
    "\n",
    "ssp245_2050 = yield_df[\n",
    "    (yield_df['scenario'] == 'ssp245') &\n",
    "    (yield_df['period'] == 'mid_term')\n",
    "]\n",
    "\n",
    "print(\"\\nStarbucks sources:\")\n",
    "sbux_data = ssp245_2050[ssp245_2050['region_name'].isin(starbucks_regions)]\n",
    "for _, row in sbux_data.iterrows():\n",
    "    print(f\"  {row['region_name']:<30s}: {row['profit_at_risk_M']:>8.0f}M profit at risk ({row['yield_loss_pct']*100:>4.1f}% loss)\")\n",
    "\n",
    "sbux_total = sbux_data['profit_at_risk_M'].sum()\n",
    "print(f\"  {'TOTAL':<30s}: {sbux_total:>8.0f}M\")\n",
    "\n",
    "print(\"\\nCompetitor sources:\")\n",
    "comp_data = ssp245_2050[ssp245_2050['region_name'].isin(competitor_regions)]\n",
    "for _, row in comp_data.iterrows():\n",
    "    print(f\"  {row['region_name']:<30s}: {row['profit_at_risk_M']:>8.0f}M profit at risk ({row['yield_loss_pct']*100:>4.1f}% loss)\")\n",
    "\n",
    "comp_total = comp_data['profit_at_risk_M'].sum()\n",
    "print(f\"  {'TOTAL':<30s}: {comp_total:>8.0f}M\")\n",
    "\n",
    "print(f\"\\nCompetitive advantage: {comp_total - sbux_total:.0f}M in protected profit\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5ce3844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Baseline green coffee price: $3.50/kg\n",
      "âœ“ Revenue per kg: $73.66/kg\n",
      "âœ“ Gross margin per kg: $20.63/kg\n",
      "âœ“ Gross margin percent: 28.0%\n",
      "âœ“ Implied markup: 21.0x\n",
      "âœ“ Elasticity used: -0.8\n",
      "âœ“ Financial impacts calculated (baseline + elasticity + gross-margin profit)\n",
      "\n",
      "================================================================================\n",
      "FINANCIAL IMPACT VALIDATION (SSP2-4.5, 2050)\n",
      "================================================================================\n",
      "\n",
      "Total Volume at Risk: 7,701 MT (4.5% of supply)\n",
      "Total Profit at Risk: $159M\n",
      "As % of Coffee Revenue: 1.3%\n",
      "As % of Total Assets: 0.45%\n",
      "\n",
      "Top 5 Regions by Profit at Risk:\n",
      "  Indonesia_Sumatra Aceh             : $  25.4M ( 1,232 MT, 17.9% loss)\n",
      "  Costa Rica_TarrazÃº                  : $  18.6M (   902 MT, 13.1% loss)\n",
      "  Brazil_Minas Gerais Sul         : $  13.9M (   675 MT,  4.9% loss)\n",
      "  Colombia_Antioquia                : $  13.0M (   631 MT,  6.7% loss)\n",
      "  Brazil_SÃ£o Paulo                : $  11.1M (   538 MT,  7.8% loss)\n",
      "\n",
      "================================================================================\n",
      "EXPECTED AFTER ELEVATION FIX:\n",
      "  Total profit at risk: $500-600M (not $1,100M+)\n",
      "  Volume at risk: 14-16% of supply (not 30%+)\n",
      "  Top regions: $50-100M each (not $100-200M)\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Diagnostics\n",
    "# ---------------------------------------------------------------\n",
    "print(f\"âœ“ Baseline green coffee price: ${coffee_price_per_kg:.2f}/kg\")\n",
    "print(f\"âœ“ Revenue per kg: ${revenue_per_kg:.2f}/kg\")\n",
    "print(f\"âœ“ Gross margin per kg: ${gross_margin_per_kg:.2f}/kg\")\n",
    "print(f\"âœ“ Gross margin percent: {gross_margin_pct*100:.1f}%\")\n",
    "print(f\"âœ“ Implied markup: {implied_markup:.1f}x\")\n",
    "print(f\"âœ“ Elasticity used: {elasticity}\")\n",
    "print(\"âœ“ Financial impacts calculated (baseline + elasticity + gross-margin profit)\\n\")\n",
    "\n",
    "# â­ ADD THIS VALIDATION:\n",
    "print(\"=\"*80)\n",
    "print(\"FINANCIAL IMPACT VALIDATION (SSP2-4.5, 2050)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "ssp245_2050 = yield_df[(yield_df['scenario'] == 'ssp245') & (yield_df['period'] == 'mid_term')]\n",
    "\n",
    "total_volume_at_risk = ssp245_2050['volume_at_risk_mt'].sum()\n",
    "total_profit_at_risk = ssp245_2050['profit_at_risk_M'].sum()\n",
    "pct_volume = (total_volume_at_risk / total_volume_mt) * 100\n",
    "\n",
    "print(f\"\\nTotal Volume at Risk: {total_volume_at_risk:,.0f} MT ({pct_volume:.1f}% of supply)\")\n",
    "print(f\"Total Profit at Risk: ${total_profit_at_risk:,.0f}M\")\n",
    "print(f\"As % of Coffee Revenue: {(total_profit_at_risk*1e6 / coffee_revenue)*100:.1f}%\")\n",
    "print(f\"As % of Total Assets: {(total_profit_at_risk*1e6 / CONFIG['financial_params']['total_assets'])*100:.2f}%\")\n",
    "\n",
    "# Top 5 regions by profit at risk\n",
    "print(f\"\\nTop 5 Regions by Profit at Risk:\")\n",
    "top5 = ssp245_2050.nlargest(5, 'profit_at_risk_M')\n",
    "for _, row in top5.iterrows():\n",
    "    print(f\"  {row['country']}_{row['region_name']:25s}: ${row['profit_at_risk_M']:6.1f}M \" +\n",
    "          f\"({row['volume_at_risk_mt']:6,.0f} MT, {row['yield_loss_pct']*100:4.1f}% loss)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPECTED AFTER ELEVATION FIX:\")\n",
    "print(\"  Total profit at risk: $500-600M (not $1,100M+)\")\n",
    "print(\"  Volume at risk: 14-16% of supply (not 30%+)\")\n",
    "print(\"  Top regions: $50-100M each (not $100-200M)\")\n",
    "print(\"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8f5c39",
   "metadata": {},
   "source": [
    "Just adding this below to see the pickel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e770e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 7: Aggregating results by scenario...\n",
      "----------------------------------------------------------------------\n",
      "âœ“ Aggregation complete\n",
      "\n",
      "======================================================================\n",
      "KEY RESULTS: COFFEE SUPPLY AT RISK & FINANCIAL IMPACT\n",
      "======================================================================\n",
      "\n",
      "Net Zero 2050\n",
      "  2050:\n",
      "      Volume at risk:            5,733 MT\n",
      "      % of total supply:         3.33%\n",
      "      Baseline procurement cost: $20.1M\n",
      "      Elasticity-adjusted cost:  $20.1M\n",
      "      Profit at risk:            $118.2M\n",
      "  2030:\n",
      "      Volume at risk:            5,564 MT\n",
      "      % of total supply:         3.23%\n",
      "      Baseline procurement cost: $19.5M\n",
      "      Elasticity-adjusted cost:  $19.5M\n",
      "      Profit at risk:            $114.8M\n",
      "\n",
      "Delayed Transition\n",
      "  2050:\n",
      "      Volume at risk:            7,701 MT\n",
      "      % of total supply:         4.48%\n",
      "      Baseline procurement cost: $27.0M\n",
      "      Elasticity-adjusted cost:  $27.0M\n",
      "      Profit at risk:            $158.8M\n",
      "  2030:\n",
      "      Volume at risk:            7,200 MT\n",
      "      % of total supply:         4.19%\n",
      "      Baseline procurement cost: $25.2M\n",
      "      Elasticity-adjusted cost:  $25.3M\n",
      "      Profit at risk:            $148.5M\n",
      "\n",
      "Current Policies\n",
      "  2050:\n",
      "      Volume at risk:            8,503 MT\n",
      "      % of total supply:         4.94%\n",
      "      Baseline procurement cost: $29.8M\n",
      "      Elasticity-adjusted cost:  $29.9M\n",
      "      Profit at risk:            $175.4M\n",
      "  2030:\n",
      "      Volume at risk:            7,172 MT\n",
      "      % of total supply:         4.17%\n",
      "      Baseline procurement cost: $25.1M\n",
      "      Elasticity-adjusted cost:  $25.2M\n",
      "      Profit at risk:            $147.9M\n",
      "\n",
      "======================================================================\n",
      "\n",
      "âœ“ Saved financial impact results to outputs/\n",
      "  - yield_financial_impacts.csv (detailed)\n",
      "  - scenario_summary.csv (aggregated)\n",
      "  - financial_impacts.pkl (for next modules)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 7: AGGREGATE BY SCENARIO AND TIME PERIOD (TCFD-COMPLIANT)\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "print(\"STEP 7: Aggregating results by scenario...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. AGGREGATE ALL FINANCIAL + VOLUME METRICS\n",
    "# ============================================================================\n",
    "\n",
    "scenario_summary = (\n",
    "    yield_df.groupby([\"scenario\", \"period\"])\n",
    "    .agg({\n",
    "        \"volume_at_risk_mt\": \"sum\",\n",
    "        \"cost_green_M\": \"sum\",\n",
    "        \"cost_green_adjusted_M\": \"sum\",\n",
    "        \"profit_at_risk_M\": \"sum\",\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. CORRECT % OF TOTAL SUPPLY AT RISK\n",
    "# ============================================================================\n",
    "\n",
    "scenario_summary[\"pct_at_risk\"] = (\n",
    "    scenario_summary[\"volume_at_risk_mt\"] / total_volume_mt * 100\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. ADD HUMAN-READABLE SCENARIO / YEAR LABELS\n",
    "# ============================================================================\n",
    "\n",
    "scenario_names = {\n",
    "    \"ssp126\": \"Net Zero 2050\",\n",
    "    \"ssp245\": \"Delayed Transition\",\n",
    "    \"ssp585\": \"Current Policies\",\n",
    "}\n",
    "\n",
    "period_names = {\n",
    "    \"near_term\": \"2030\",\n",
    "    \"mid_term\": \"2050\",\n",
    "}\n",
    "\n",
    "scenario_summary[\"scenario_name\"] = scenario_summary[\"scenario\"].map(scenario_names)\n",
    "scenario_summary[\"year\"] = scenario_summary[\"period\"].map(period_names)\n",
    "\n",
    "print(\"âœ“ Aggregation complete\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# DISPLAY RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"KEY RESULTS: COFFEE SUPPLY AT RISK & FINANCIAL IMPACT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for scenario in [\"ssp126\", \"ssp245\", \"ssp585\"]:\n",
    "\n",
    "    data = scenario_summary[scenario_summary[\"scenario\"] == scenario]\n",
    "    if len(data) == 0:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n{scenario_names[scenario]}\")\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        print(f\"  {row['year']}:\")\n",
    "        print(f\"      Volume at risk:            {row['volume_at_risk_mt']:,.0f} MT\")\n",
    "        print(f\"      % of total supply:         {row['pct_at_risk']:.2f}%\")\n",
    "        print(f\"      Baseline procurement cost: ${row['cost_green_M']:.1f}M\")\n",
    "        print(f\"      Elasticity-adjusted cost:  ${row['cost_green_adjusted_M']:.1f}M\")\n",
    "        print(f\"      Profit at risk:            ${row['profit_at_risk_M']:.1f}M\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE OUTPUTS\n",
    "# ============================================================================\n",
    "\n",
    "yield_df.to_csv(f\"{CONFIG['base_path']}/outputs/yield_financial_impacts.csv\", index=False)\n",
    "scenario_summary.to_csv(f\"{CONFIG['base_path']}/outputs/scenario_summary.csv\", index=False)\n",
    "\n",
    "output_dir = f\"{CONFIG['base_path']}/outputs/intermediate\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(f\"{output_dir}/financial_impacts.pkl\", \"wb\") as f:\n",
    "    pickle.dump(\n",
    "        {\n",
    "            \"detailed\": yield_df,\n",
    "            \"summary\": scenario_summary,\n",
    "            \"parameters\": {\n",
    "                \"coffee_price_per_kg\": coffee_price_per_kg,\n",
    "                \"revenue_per_kg\": revenue_per_kg,\n",
    "                \"implied_markup\": implied_markup,\n",
    "                \"total_volume_mt\": total_volume_mt,\n",
    "            },\n",
    "        },\n",
    "        f,\n",
    "    )\n",
    "\n",
    "print(\"âœ“ Saved financial impact results to outputs/\")\n",
    "print(\"  - yield_financial_impacts.csv (detailed)\")\n",
    "print(\"  - scenario_summary.csv (aggregated)\")\n",
    "print(\"  - financial_impacts.pkl (for next modules)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ce487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 7: Aggregating results by scenario...\n",
      "----------------------------------------------------------------------\n",
      "âœ“ Aggregation complete\n",
      "\n",
      "======================================================================\n",
      "KEY RESULTS: COFFEE SUPPLY AT RISK & FINANCIAL IMPACT\n",
      "======================================================================\n",
      "\n",
      "Net Zero 2050\n",
      "  2050:\n",
      "      Volume at risk:            5,733 MT\n",
      "      % of total supply:         3.33%\n",
      "      Baseline procurement cost: $20.1M\n",
      "      Elasticity-adjusted cost:  $20.1M\n",
      "      Profit at risk:            $118.2M\n",
      "  2030:\n",
      "      Volume at risk:            5,564 MT\n",
      "      % of total supply:         3.23%\n",
      "      Baseline procurement cost: $19.5M\n",
      "      Elasticity-adjusted cost:  $19.5M\n",
      "      Profit at risk:            $114.8M\n",
      "\n",
      "Delayed Transition\n",
      "  2050:\n",
      "      Volume at risk:            7,701 MT\n",
      "      % of total supply:         4.48%\n",
      "      Baseline procurement cost: $27.0M\n",
      "      Elasticity-adjusted cost:  $27.0M\n",
      "      Profit at risk:            $158.8M\n",
      "  2030:\n",
      "      Volume at risk:            7,200 MT\n",
      "      % of total supply:         4.19%\n",
      "      Baseline procurement cost: $25.2M\n",
      "      Elasticity-adjusted cost:  $25.3M\n",
      "      Profit at risk:            $148.5M\n",
      "\n",
      "Current Policies\n",
      "  2050:\n",
      "      Volume at risk:            8,503 MT\n",
      "      % of total supply:         4.94%\n",
      "      Baseline procurement cost: $29.8M\n",
      "      Elasticity-adjusted cost:  $29.9M\n",
      "      Profit at risk:            $175.4M\n",
      "  2030:\n",
      "      Volume at risk:            7,172 MT\n",
      "      % of total supply:         4.17%\n",
      "      Baseline procurement cost: $25.1M\n",
      "      Elasticity-adjusted cost:  $25.2M\n",
      "      Profit at risk:            $147.9M\n",
      "\n",
      "======================================================================\n",
      "\n",
      "âœ“ Saved financial impact results to outputs/\n",
      "  - yield_financial_impacts.csv (detailed)\n",
      "  - scenario_summary.csv (aggregated)\n",
      "  - financial_impacts.pkl (for next modules)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 7: AGGREGATE BY SCENARIO AND TIME PERIOD (TCFD-COMPLIANT)\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "print(\"STEP 7: Aggregating results by scenario...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. AGGREGATE ALL FINANCIAL + VOLUME METRICS\n",
    "# ============================================================================\n",
    "\n",
    "scenario_summary = (\n",
    "    yield_df.groupby([\"scenario\", \"period\"])\n",
    "    .agg({\n",
    "        \"volume_at_risk_mt\": \"sum\",\n",
    "        \"cost_green_M\": \"sum\",\n",
    "        \"cost_green_adjusted_M\": \"sum\",\n",
    "        \"profit_at_risk_M\": \"sum\",\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. CORRECT % OF TOTAL SUPPLY AT RISK\n",
    "# ============================================================================\n",
    "\n",
    "scenario_summary[\"pct_at_risk\"] = (\n",
    "    scenario_summary[\"volume_at_risk_mt\"] / total_volume_mt * 100\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. ADD HUMAN-READABLE SCENARIO / YEAR LABELS\n",
    "# ============================================================================\n",
    "\n",
    "scenario_names = {\n",
    "    \"ssp126\": \"Net Zero 2050\",\n",
    "    \"ssp245\": \"Delayed Transition\",\n",
    "    \"ssp585\": \"Current Policies\",\n",
    "}\n",
    "\n",
    "period_names = {\n",
    "    \"near_term\": \"2030\",\n",
    "    \"mid_term\": \"2050\",\n",
    "}\n",
    "\n",
    "scenario_summary[\"scenario_name\"] = scenario_summary[\"scenario\"].map(scenario_names)\n",
    "scenario_summary[\"year\"] = scenario_summary[\"period\"].map(period_names)\n",
    "\n",
    "print(\"âœ“ Aggregation complete\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# DISPLAY RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"KEY RESULTS: COFFEE SUPPLY AT RISK & FINANCIAL IMPACT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for scenario in [\"ssp126\", \"ssp245\", \"ssp585\"]:\n",
    "\n",
    "    data = scenario_summary[scenario_summary[\"scenario\"] == scenario]\n",
    "    if len(data) == 0:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n{scenario_names[scenario]}\")\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        print(f\"  {row['year']}:\")\n",
    "        print(f\"      Volume at risk:            {row['volume_at_risk_mt']:,.0f} MT\")\n",
    "        print(f\"      % of total supply:         {row['pct_at_risk']:.2f}%\")\n",
    "        print(f\"      Baseline procurement cost: ${row['cost_green_M']:.1f}M\")\n",
    "        print(f\"      Elasticity-adjusted cost:  ${row['cost_green_adjusted_M']:.1f}M\")\n",
    "        print(f\"      Profit at risk:            ${row['profit_at_risk_M']:.1f}M\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE OUTPUTS\n",
    "# ============================================================================\n",
    "\n",
    "yield_df.to_csv(f\"{CONFIG['base_path']}/outputs/yield_financial_impacts.csv\", index=False)\n",
    "scenario_summary.to_csv(f\"{CONFIG['base_path']}/outputs/scenario_summary.csv\", index=False)\n",
    "\n",
    "output_dir = f\"{CONFIG['base_path']}/outputs/intermediate\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(f\"{output_dir}/financial_impacts.pkl\", \"wb\") as f:\n",
    "    pickle.dump(\n",
    "        {\n",
    "            \"detailed\": yield_df,\n",
    "            \"summary\": scenario_summary,\n",
    "            \"parameters\": {\n",
    "                \"coffee_price_per_kg\": coffee_price_per_kg,\n",
    "                \"revenue_per_kg\": revenue_per_kg,\n",
    "                \"implied_markup\": implied_markup,\n",
    "                \"total_volume_mt\": total_volume_mt,\n",
    "            },\n",
    "        },\n",
    "        f,\n",
    "    )\n",
    "\n",
    "print(\"âœ“ Saved financial impact results to outputs/\")\n",
    "print(\"  - yield_financial_impacts.csv (detailed)\")\n",
    "print(\"  - scenario_summary.csv (aggregated)\")\n",
    "print(\"  - financial_impacts.pkl (for next modules)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bab7b8",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# STEP 7: AGGREGATE BY SCENARIO AND TIME PERIOD (TCFD-COMPLIANT)\n",
    "# ============================================================================\n",
    "import os\n",
    "import pickle\n",
    "print(\"STEP 7: Aggregating results by scenario...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "scenario_summary = (\n",
    "    yield_df.groupby([\"scenario\", \"period\"])\n",
    "    .agg({\n",
    "        \"volume_at_risk_mt\": \"sum\",\n",
    "        \"cost_green_M\": \"sum\",\n",
    "        \"cost_green_adjusted_M\": \"sum\",\n",
    "        \"profit_at_risk_M\": \"sum\",\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "scenario_summary[\"pct_at_risk\"] = (\n",
    "    scenario_summary[\"volume_at_risk_mt\"] / total_volume_mt * 100\n",
    ")\n",
    "\n",
    "scenario_names = {\n",
    "    \"ssp126\": \"Net Zero 2050\",\n",
    "    \"ssp245\": \"Delayed Transition\",\n",
    "    \"ssp585\": \"Current Policies\",\n",
    "}\n",
    "period_names = {\n",
    "    \"near_term\": \"2030\",\n",
    "    \"mid_term\": \"2050\",\n",
    "}\n",
    "scenario_summary[\"scenario_name\"] = scenario_summary[\"scenario\"].map(scenario_names)\n",
    "scenario_summary[\"year\"] = scenario_summary[\"period\"].map(period_names)\n",
    "print(\"âœ“ Aggregation complete\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"KEY RESULTS: COFFEE SUPPLY AT RISK & FINANCIAL IMPACT\")\n",
    "print(\"=\"*70)\n",
    "for scenario in [\"ssp126\", \"ssp245\", \"ssp585\"]:\n",
    "    data = scenario_summary[scenario_summary[\"scenario\"] == scenario]\n",
    "    if len(data) == 0:\n",
    "        continue\n",
    "    print(f\"\\n{scenario_names[scenario]}\")\n",
    "    for _, row in data.iterrows():\n",
    "        print(f\"  {row['year']}:\")\n",
    "        print(f\"      Volume at risk:            {row['volume_at_risk_mt']:,.0f} MT\")\n",
    "        print(f\"      % of total supply:         {row['pct_at_risk']:.2f}%\")\n",
    "        print(f\"      Baseline procurement cost: ${row['cost_green_M']:.1f}M\")\n",
    "        print(f\"      Elasticity-adjusted cost:  ${row['cost_green_adjusted_M']:.1f}M\")\n",
    "        print(f\"      Profit at risk:            ${row['profit_at_risk_M']:.1f}M\")\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83100c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "NET PRESENT VALUE CALCULATION (30-YEAR HORIZON)\n",
      "================================================================================\n",
      "\n",
      "Net Zero 2050:\n",
      "  Annual profit at risk (2050): $118.2M\n",
      "  NPV (30-year, 8% discount):  $1331.2M\n",
      "\n",
      "Delayed Transition:\n",
      "  Annual profit at risk (2050): $158.8M\n",
      "  NPV (30-year, 8% discount):  $1788.1M\n",
      "\n",
      "Current Policies:\n",
      "  Annual profit at risk (2050): $175.4M\n",
      "  NPV (30-year, 8% discount):  $1974.5M\n",
      "\n",
      "================================================================================\n",
      "NPV SUMMARY\n",
      "================================================================================\n",
      "Scenario                       Annual          30-Yr NPV      \n",
      "------------------------------------------------------------\n",
      "Net Zero 2050                  $       118.2M $      1331.2M\n",
      "Delayed Transition             $       158.8M $      1788.1M\n",
      "Current Policies               $       175.4M $      1974.5M\n",
      "================================================================================\n",
      "\n",
      "âœ“ Saved NPV results to: C:/Users/ibeha/OneDrive/Desktop/Climate/outputs/npv_summary.csv\n"
     ]
    }
   ],
   "source": [
    "#Now we need to convert these annual impacts into Net Present Value (NPV) over 30 years. That's the total financial exposure figure.\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NET PRESENT VALUE CALCULATION (30-YEAR HORIZON)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "discount_rate = CONFIG['financial_params']['discount_rate']\n",
    "\n",
    "# Calculate NPV for each scenario/period\n",
    "npv_results = []\n",
    "\n",
    "for scenario in [\"ssp126\", \"ssp245\", \"ssp585\"]:\n",
    "    scenario_data = scenario_summary[scenario_summary[\"scenario\"] == scenario]\n",
    "    \n",
    "    # Mid-term (2050) represents 2041-2060, use as proxy for 2030-2060\n",
    "    mid_term_data = scenario_data[scenario_data[\"period\"] == \"mid_term\"]\n",
    "    \n",
    "    if len(mid_term_data) > 0:\n",
    "        annual_profit_risk = mid_term_data.iloc[0][\"profit_at_risk_M\"]\n",
    "        \n",
    "        # NPV: PV = FV / (1 + r)^t summed over 30 years\n",
    "        npv = sum([annual_profit_risk / ((1 + discount_rate) ** t) for t in range(1, 31)])\n",
    "        \n",
    "        scenario_name = scenario_names[scenario]\n",
    "        print(f\"\\n{scenario_name}:\")\n",
    "        print(f\"  Annual profit at risk (2050): ${annual_profit_risk:.1f}M\")\n",
    "        print(f\"  NPV (30-year, 8% discount):  ${npv:.1f}M\")\n",
    "        \n",
    "        npv_results.append({\n",
    "            \"scenario\": scenario,\n",
    "            \"scenario_name\": scenario_name,\n",
    "            \"annual_impact\": annual_profit_risk,\n",
    "            \"npv_30yr\": npv\n",
    "        })\n",
    "\n",
    "npv_df = pd.DataFrame(npv_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NPV SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Scenario':<30s} {'Annual':<15s} {'30-Yr NPV':<15s}\")\n",
    "print(\"-\"*60)\n",
    "for _, row in npv_df.iterrows():\n",
    "    print(f\"{row['scenario_name']:<30s} ${row['annual_impact']:>12.1f}M ${row['npv_30yr']:>12.1f}M\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "# Save NPV results\n",
    "npv_df.to_csv(f\"{CONFIG['base_path']}/outputs/npv_summary.csv\", index=False)\n",
    "\n",
    "print(f\"\\nâœ“ Saved NPV results to: {CONFIG['base_path']}/outputs/npv_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "740733d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved scenario summary with NPV to: C:/Users/ibeha/OneDrive/Desktop/Climate/outputs/scenario_summary_with_npv.csv\n"
     ]
    }
   ],
   "source": [
    "# Add NPV to scenario_summary\n",
    "scenario_summary_with_npv = scenario_summary.copy()\n",
    "\n",
    "for idx, row in scenario_summary_with_npv.iterrows():\n",
    "    if row['period'] == 'mid_term':\n",
    "        scenario = row['scenario']\n",
    "        npv_value = npv_df[npv_df['scenario'] == scenario]['npv_30yr'].values[0]\n",
    "        scenario_summary_with_npv.loc[idx, 'npv_30yr_M'] = npv_value\n",
    "    else:\n",
    "        scenario_summary_with_npv.loc[idx, 'npv_30yr_M'] = np.nan\n",
    "\n",
    "# Save updated summary\n",
    "scenario_summary_with_npv.to_csv(f\"{CONFIG['base_path']}/outputs/scenario_summary_with_npv.csv\", index=False)\n",
    "\n",
    "print(f\"âœ“ Saved scenario summary with NPV to: {CONFIG['base_path']}/outputs/scenario_summary_with_npv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3db7228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 8: Calculating carbon pricing & transition costs...\n",
      "----------------------------------------------------------------------\n",
      "Starbucks Emissions Baseline:\n",
      "  Scope 1+2: 1.50M MT\n",
      "  Scope 3 Total: 15.00M MT\n",
      "  Agriculture portion: 6.00M MT\n",
      "  Relevant emissions: 7.50M MT\n",
      "\n",
      "âœ“ Carbon costs calculated successfully\n",
      "\n",
      "======================================================================\n",
      "CARBON PRICING IMPACT BY SCENARIO\n",
      "======================================================================\n",
      "\n",
      "Net Zero 2050 (ssp126)\n",
      "  2025:\n",
      "      Carbon price: $40/tCO2\n",
      "      Annual carbon cost: $42.0M (0.12% of revenue)\n",
      "      Scope 1+2 cost:  $21.0M\n",
      "      Scope 3 cost:    $21.0M\n",
      "  2030:\n",
      "      Carbon price: $100/tCO2\n",
      "      Annual carbon cost: $216.0M (0.60% of revenue)\n",
      "      Scope 1+2 cost:  $90.0M\n",
      "      Scope 3 cost:    $126.0M\n",
      "  2035:\n",
      "      Carbon price: $150/tCO2\n",
      "      Annual carbon cost: $438.8M (1.21% of revenue)\n",
      "      Scope 1+2 cost:  $168.8M\n",
      "      Scope 3 cost:    $270.0M\n",
      "  2040:\n",
      "      Carbon price: $200/tCO2\n",
      "      Annual carbon cost: $663.0M (1.83% of revenue)\n",
      "      Scope 1+2 cost:  $255.0M\n",
      "      Scope 3 cost:    $408.0M\n",
      "  2045:\n",
      "      Carbon price: $225/tCO2\n",
      "      Annual carbon cost: $772.2M (2.13% of revenue)\n",
      "      Scope 1+2 cost:  $297.0M\n",
      "      Scope 3 cost:    $475.2M\n",
      "  2050:\n",
      "      Carbon price: $250/tCO2\n",
      "      Annual carbon cost: $877.5M (2.42% of revenue)\n",
      "      Scope 1+2 cost:  $337.5M\n",
      "      Scope 3 cost:    $540.0M\n",
      "\n",
      "Delayed Transition (ssp245)\n",
      "  2025:\n",
      "      Carbon price: $20/tCO2\n",
      "      Annual carbon cost: $13.5M (0.04% of revenue)\n",
      "      Scope 1+2 cost:  $7.5M\n",
      "      Scope 3 cost:    $6.0M\n",
      "  2030:\n",
      "      Carbon price: $75/tCO2\n",
      "      Annual carbon cost: $126.0M (0.35% of revenue)\n",
      "      Scope 1+2 cost:  $45.0M\n",
      "      Scope 3 cost:    $81.0M\n",
      "  2035:\n",
      "      Carbon price: $450/tCO2\n",
      "      Annual carbon cost: $1701.0M (4.70% of revenue)\n",
      "      Scope 1+2 cost:  $472.5M\n",
      "      Scope 3 cost:    $1228.5M\n",
      "  2040:\n",
      "      Carbon price: $700/tCO2\n",
      "      Annual carbon cost: $3391.5M (9.37% of revenue)\n",
      "      Scope 1+2 cost:  $892.5M\n",
      "      Scope 3 cost:    $2499.0M\n",
      "  2045:\n",
      "      Carbon price: $600/tCO2\n",
      "      Annual carbon cost: $2851.2M (7.88% of revenue)\n",
      "      Scope 1+2 cost:  $792.0M\n",
      "      Scope 3 cost:    $2059.2M\n",
      "  2050:\n",
      "      Carbon price: $500/tCO2\n",
      "      Annual carbon cost: $2295.0M (6.34% of revenue)\n",
      "      Scope 1+2 cost:  $675.0M\n",
      "      Scope 3 cost:    $1620.0M\n",
      "\n",
      "Current Policies (ssp585)\n",
      "  2025:\n",
      "      Carbon price: $15/tCO2\n",
      "      Annual carbon cost: $7.2M (0.02% of revenue)\n",
      "      Scope 1+2 cost:  $4.5M\n",
      "      Scope 3 cost:    $2.7M\n",
      "  2030:\n",
      "      Carbon price: $20/tCO2\n",
      "      Annual carbon cost: $10.6M (0.03% of revenue)\n",
      "      Scope 1+2 cost:  $6.6M\n",
      "      Scope 3 cost:    $4.0M\n",
      "  2035:\n",
      "      Carbon price: $25/tCO2\n",
      "      Annual carbon cost: $15.0M (0.04% of revenue)\n",
      "      Scope 1+2 cost:  $9.4M\n",
      "      Scope 3 cost:    $5.6M\n",
      "  2040:\n",
      "      Carbon price: $30/tCO2\n",
      "      Annual carbon cost: $20.2M (0.06% of revenue)\n",
      "      Scope 1+2 cost:  $12.6M\n",
      "      Scope 3 cost:    $7.6M\n",
      "  2045:\n",
      "      Carbon price: $35/tCO2\n",
      "      Annual carbon cost: $26.2M (0.07% of revenue)\n",
      "      Scope 1+2 cost:  $15.2M\n",
      "      Scope 3 cost:    $11.0M\n",
      "  2050:\n",
      "      Carbon price: $40/tCO2\n",
      "      Annual carbon cost: $32.4M (0.09% of revenue)\n",
      "      Scope 1+2 cost:  $18.0M\n",
      "      Scope 3 cost:    $14.4M\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 8: CARBON PRICING & TRANSITION COSTS (FIXED - ADD CODE COLUMN)\n",
    "# ============================================================================\n",
    "print(\"\\nSTEP 8: Calculating carbon pricing & transition costs...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Emissions parameters\n",
    "scope_1_2_emissions = CONFIG['financial_params']['scope_1_2_emissions']\n",
    "scope_3_emissions = CONFIG['financial_params']['scope_3_emissions']\n",
    "scope_3_agriculture = scope_3_emissions * 0.40\n",
    "\n",
    "print(\"Starbucks Emissions Baseline:\")\n",
    "print(f\"  Scope 1+2: {scope_1_2_emissions/1e6:.2f}M MT\")\n",
    "print(f\"  Scope 3 Total: {scope_3_emissions/1e6:.2f}M MT\")\n",
    "print(f\"  Agriculture portion: {scope_3_agriculture/1e6:.2f}M MT\")\n",
    "print(f\"  Relevant emissions: {(scope_1_2_emissions+scope_3_agriculture)/1e6:.2f}M MT\\n\")\n",
    "\n",
    "# â­ MAPPING: Excel names â†’ scenario codes\n",
    "scenario_name_to_code = {\n",
    "    \"Net Zero 2050\": \"ssp126\",\n",
    "    \"Net-Zero 2050\": \"ssp126\",\n",
    "    \"Delayed Transition\": \"ssp245\",\n",
    "    \"Current Policies\": \"ssp585\"\n",
    "}\n",
    "\n",
    "carbon_cost_rows = []\n",
    "\n",
    "for _, row in carbon_prices.iterrows():\n",
    "    scenario_name = row[\"scenario\"]  # From Excel (e.g., \"Net Zero 2050\")\n",
    "    year = row[\"year\"]\n",
    "    carbon_price = row[\"carbon_price_usd_per_tco2\"]\n",
    "    \n",
    "    # â­ MAP NAME TO CODE\n",
    "    scenario_code = scenario_name_to_code.get(scenario_name, scenario_name)\n",
    "    \n",
    "    coverage = row.get(\"policy_coverage_pct\", 100) / 100\n",
    "    passthrough = row.get(\"supplier_passthrough_rate\", 0)\n",
    "    \n",
    "    scope12_cost = scope_1_2_emissions * carbon_price * coverage\n",
    "    scope3_cost = scope_3_agriculture * carbon_price * coverage * passthrough\n",
    "    total_cost = scope12_cost + scope3_cost\n",
    "    \n",
    "    carbon_cost_rows.append({\n",
    "        \"scenario\": scenario_code,  # â­ NOW STORES CODE (ssp126, etc.)\n",
    "        \"scenario_name\": scenario_name,  # Keep original name for display\n",
    "        \"year\": year,\n",
    "        \"carbon_price_usd\": carbon_price,\n",
    "        \"coverage_pct\": coverage * 100,\n",
    "        \"passthrough_rate\": passthrough,\n",
    "        \"scope_1_2_cost_M\": scope12_cost / 1e6,\n",
    "        \"scope_3_cost_M\": scope3_cost / 1e6,\n",
    "        \"total_carbon_cost_M\": total_cost / 1e6,\n",
    "        \"pct_of_revenue\": total_cost / CONFIG[\"financial_params\"][\"total_revenue\"] * 100\n",
    "    })\n",
    "\n",
    "carbon_costs_df = pd.DataFrame(carbon_cost_rows)\n",
    "print(\"âœ“ Carbon costs calculated successfully\\n\")\n",
    "\n",
    "# Display results\n",
    "scenario_display_map = {\n",
    "    \"ssp126\": \"Net Zero 2050\",\n",
    "    \"ssp245\": \"Delayed Transition\",\n",
    "    \"ssp585\": \"Current Policies\"\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CARBON PRICING IMPACT BY SCENARIO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for scenario_code, scenario_name in scenario_display_map.items():\n",
    "    subset = carbon_costs_df[carbon_costs_df[\"scenario\"] == scenario_code]\n",
    "    if subset.empty:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{scenario_name} ({scenario_code})\")\n",
    "    for _, r in subset.iterrows():\n",
    "        print(f\"  {int(r['year'])}:\")\n",
    "        print(f\"      Carbon price: ${r['carbon_price_usd']:.0f}/tCO2\")\n",
    "        print(f\"      Annual carbon cost: ${r['total_carbon_cost_M']:.1f}M \"\n",
    "              f\"({r['pct_of_revenue']:.2f}% of revenue)\")\n",
    "        print(f\"      Scope 1+2 cost:  ${r['scope_1_2_cost_M']:.1f}M\")\n",
    "        print(f\"      Scope 3 cost:    ${r['scope_3_cost_M']:.1f}M\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54f90b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Saved carbon pricing results to: C:/Users/ibeha/OneDrive/Desktop/Climate/outputs/carbon_pricing_costs.csv\n",
      "\n",
      "================================================================================\n",
      "CARBON COST SUMMARY - 2050\n",
      "================================================================================\n",
      "Net Zero 2050                 : $     877.5M ( 2.42% of revenue)\n",
      "Delayed Transition            : $    2295.0M ( 6.34% of revenue)\n",
      "Current Policies              : $      32.4M ( 0.09% of revenue)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Save carbon costs\n",
    "carbon_costs_df.to_csv(f\"{CONFIG['base_path']}/outputs/carbon_pricing_costs.csv\", index=False)\n",
    "\n",
    "print(f\"\\nâœ“ Saved carbon pricing results to: {CONFIG['base_path']}/outputs/carbon_pricing_costs.csv\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CARBON COST SUMMARY - 2050\")\n",
    "print(\"=\"*80)\n",
    "for scenario_code in ['ssp126', 'ssp245', 'ssp585']:\n",
    "    subset = carbon_costs_df[(carbon_costs_df['scenario'] == scenario_code) & (carbon_costs_df['year'] == 2050)]\n",
    "    if not subset.empty:\n",
    "        cost = subset.iloc[0]['total_carbon_cost_M']\n",
    "        pct_rev = subset.iloc[0]['pct_of_revenue']\n",
    "        scenario_name = scenario_display_map[scenario_code]\n",
    "        print(f\"{scenario_name:<30s}: ${cost:>10.1f}M ({pct_rev:>5.2f}% of revenue)\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ecef0372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DIAGNOSTIC: CHECKING DATA AVAILABILITY\n",
      "================================================================================\n",
      "\n",
      "1. PHYSICAL RISKS (scenario_summary):\n",
      "  scenario  year  profit_at_risk_M\n",
      "0   ssp126  2050        118.247340\n",
      "1   ssp126  2030        114.763369\n",
      "2   ssp245  2050        158.833810\n",
      "3   ssp245  2030        148.496078\n",
      "4   ssp585  2050        175.388033\n",
      "5   ssp585  2030        147.921496\n",
      "\n",
      "2. CARBON COSTS (carbon_costs_df):\n",
      "   scenario  year  total_carbon_cost_M\n",
      "0    ssp126  2025               42.000\n",
      "1    ssp126  2030              216.000\n",
      "2    ssp126  2035              438.750\n",
      "3    ssp126  2040              663.000\n",
      "4    ssp126  2045              772.200\n",
      "5    ssp126  2050              877.500\n",
      "6    ssp245  2025               13.500\n",
      "7    ssp245  2030              126.000\n",
      "8    ssp245  2035             1701.000\n",
      "9    ssp245  2040             3391.500\n",
      "10   ssp245  2045             2851.200\n",
      "11   ssp245  2050             2295.000\n",
      "12   ssp585  2025                7.200\n",
      "13   ssp585  2030               10.560\n",
      "14   ssp585  2035               15.000\n",
      "15   ssp585  2040               20.160\n",
      "16   ssp585  2045               26.187\n",
      "17   ssp585  2050               32.400\n",
      "\n",
      "3. CHECKING MATCHES:\n",
      "\n",
      "ssp126:\n",
      "  Physical 2030: MISSING\n",
      "  Physical 2050: MISSING\n",
      "  Carbon 2030: Found\n",
      "  Carbon 2050: Found\n",
      "\n",
      "ssp245:\n",
      "  Physical 2030: MISSING\n",
      "  Physical 2050: MISSING\n",
      "  Carbon 2030: Found\n",
      "  Carbon 2050: Found\n",
      "\n",
      "ssp585:\n",
      "  Physical 2030: MISSING\n",
      "  Physical 2050: MISSING\n",
      "  Carbon 2030: Found\n",
      "  Carbon 2050: Found\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DIAGNOSTIC: CHECKING DATA AVAILABILITY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. PHYSICAL RISKS (scenario_summary):\")\n",
    "print(scenario_summary[['scenario', 'year', 'profit_at_risk_M']])\n",
    "\n",
    "print(\"\\n2. CARBON COSTS (carbon_costs_df):\")\n",
    "print(carbon_costs_df[['scenario', 'year', 'total_carbon_cost_M']])\n",
    "\n",
    "print(\"\\n3. CHECKING MATCHES:\")\n",
    "for code in ['ssp126', 'ssp245', 'ssp585']:\n",
    "    print(f\"\\n{code}:\")\n",
    "    \n",
    "    phys_2030 = scenario_summary[(scenario_summary['scenario'] == code) & (scenario_summary['year'] == 2030)]\n",
    "    phys_2050 = scenario_summary[(scenario_summary['scenario'] == code) & (scenario_summary['year'] == 2050)]\n",
    "    carb_2030 = carbon_costs_df[(carbon_costs_df['scenario'] == code) & (carbon_costs_df['year'] == 2030)]\n",
    "    carb_2050 = carbon_costs_df[(carbon_costs_df['scenario'] == code) & (carbon_costs_df['year'] == 2050)]\n",
    "    \n",
    "    print(f\"  Physical 2030: {'Found' if not phys_2030.empty else 'MISSING'}\")\n",
    "    print(f\"  Physical 2050: {'Found' if not phys_2050.empty else 'MISSING'}\")\n",
    "    print(f\"  Carbon 2030: {'Found' if not carb_2030.empty else 'MISSING'}\")\n",
    "    print(f\"  Carbon 2050: {'Found' if not carb_2050.empty else 'MISSING'}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7605e3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 9: Combining physical and transition risks...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "âœ“ Combined physical + transition risks\n",
      "\n",
      "================================================================================\n",
      "TOTAL CLIMATE RISK: PHYSICAL + TRANSITION (ANNUAL COSTS)\n",
      "================================================================================\n",
      "\n",
      "Net Zero 2050 (ssp126)\n",
      "  2030:\n",
      "      Physical risks (supply):  $114.8M\n",
      "      Transition risks (carbon): $216.0M\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "      TOTAL CLIMATE COST:       $330.8M\n",
      "      Volume at risk:           5,564 MT (3.2%)\n",
      "  2050:\n",
      "      Physical risks (supply):  $118.2M\n",
      "      Transition risks (carbon): $877.5M\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "      TOTAL CLIMATE COST:       $995.7M\n",
      "      Volume at risk:           5,733 MT (3.3%)\n",
      "\n",
      "Delayed Transition (ssp245)\n",
      "  2030:\n",
      "      Physical risks (supply):  $148.5M\n",
      "      Transition risks (carbon): $126.0M\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "      TOTAL CLIMATE COST:       $274.5M\n",
      "      Volume at risk:           7,200 MT (4.2%)\n",
      "  2050:\n",
      "      Physical risks (supply):  $158.8M\n",
      "      Transition risks (carbon): $2295.0M\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "      TOTAL CLIMATE COST:       $2453.8M\n",
      "      Volume at risk:           7,701 MT (4.5%)\n",
      "\n",
      "Current Policies (ssp585)\n",
      "  2030:\n",
      "      Physical risks (supply):  $147.9M\n",
      "      Transition risks (carbon): $10.6M\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "      TOTAL CLIMATE COST:       $158.5M\n",
      "      Volume at risk:           7,172 MT (4.2%)\n",
      "  2050:\n",
      "      Physical risks (supply):  $175.4M\n",
      "      Transition risks (carbon): $32.4M\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "      TOTAL CLIMATE COST:       $207.8M\n",
      "      Volume at risk:           8,503 MT (4.9%)\n",
      "\n",
      "================================================================================\n",
      "âœ“ Saved combined results to outputs/total_climate_costs.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 9: COMBINE PHYSICAL + TRANSITION RISKS (FIXED)\n",
    "# ============================================================================\n",
    "print(\"\\nSTEP 9: Combining physical and transition risks...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "combined_impacts = []\n",
    "\n",
    "scenario_map = {\n",
    "    'ssp126': 'Net Zero 2050',\n",
    "    'ssp245': 'Delayed Transition',\n",
    "    'ssp585': 'Current Policies'\n",
    "}\n",
    "\n",
    "# Ensure year is int\n",
    "scenario_summary['year'] = scenario_summary['year'].astype(int)\n",
    "carbon_costs_df['year'] = carbon_costs_df['year'].astype(int)\n",
    "\n",
    "for code, name in scenario_map.items():\n",
    "    # Get physical risks (uses CODE)\n",
    "    phys_2030 = scenario_summary[\n",
    "        (scenario_summary['scenario'] == code) &\n",
    "        (scenario_summary['year'] == 2030)\n",
    "    ]\n",
    "    phys_2050 = scenario_summary[\n",
    "        (scenario_summary['scenario'] == code) &\n",
    "        (scenario_summary['year'] == 2050)\n",
    "    ]\n",
    "    \n",
    "    # Get carbon risks (ALSO uses CODE - THIS WAS THE BUG!)\n",
    "    carb_2030 = carbon_costs_df[\n",
    "        (carbon_costs_df['scenario'] == code) &  # â† CHANGED from 'name' to 'code'\n",
    "        (carbon_costs_df['year'] == 2030)\n",
    "    ]\n",
    "    carb_2050 = carbon_costs_df[\n",
    "        (carbon_costs_df['scenario'] == code) &  # â† CHANGED from 'name' to 'code'\n",
    "        (carbon_costs_df['year'] == 2050)\n",
    "    ]\n",
    "    \n",
    "    # Combine 2030\n",
    "    if not phys_2030.empty and not carb_2030.empty:\n",
    "        combined_impacts.append({\n",
    "            'scenario_code': code,\n",
    "            'scenario_name': name,\n",
    "            'year': 2030,\n",
    "            'physical_risk_M': phys_2030['profit_at_risk_M'].values[0],\n",
    "            'carbon_cost_M': carb_2030['total_carbon_cost_M'].values[0],\n",
    "            'total_climate_cost_M': (phys_2030['profit_at_risk_M'].values[0] +\n",
    "                                    carb_2030['total_carbon_cost_M'].values[0]),\n",
    "            'volume_at_risk_mt': phys_2030['volume_at_risk_mt'].values[0],\n",
    "            'pct_supply_at_risk': phys_2030['pct_at_risk'].values[0]\n",
    "        })\n",
    "    \n",
    "    # Combine 2050\n",
    "    if not phys_2050.empty and not carb_2050.empty:\n",
    "        combined_impacts.append({\n",
    "            'scenario_code': code,\n",
    "            'scenario_name': name,\n",
    "            'year': 2050,\n",
    "            'physical_risk_M': phys_2050['profit_at_risk_M'].values[0],\n",
    "            'carbon_cost_M': carb_2050['total_carbon_cost_M'].values[0],\n",
    "            'total_climate_cost_M': (phys_2050['profit_at_risk_M'].values[0] +\n",
    "                                    carb_2050['total_carbon_cost_M'].values[0]),\n",
    "            'volume_at_risk_mt': phys_2050['volume_at_risk_mt'].values[0],\n",
    "            'pct_supply_at_risk': phys_2050['pct_at_risk'].values[0]\n",
    "        })\n",
    "\n",
    "combined_df = pd.DataFrame(combined_impacts)\n",
    "\n",
    "print(\"\\nâœ“ Combined physical + transition risks\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOTAL CLIMATE RISK: PHYSICAL + TRANSITION (ANNUAL COSTS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for scenario_code in ['ssp126', 'ssp245', 'ssp585']:\n",
    "    subset = combined_df[combined_df['scenario_code'] == scenario_code]\n",
    "    if subset.empty:\n",
    "        continue\n",
    "    \n",
    "    scenario_name = scenario_map[scenario_code]\n",
    "    print(f\"\\n{scenario_name} ({scenario_code})\")\n",
    "    \n",
    "    for _, row in subset.iterrows():\n",
    "        print(f\"  {int(row['year'])}:\")\n",
    "        print(f\"      Physical risks (supply):  ${row['physical_risk_M']:.1f}M\")\n",
    "        print(f\"      Transition risks (carbon): ${row['carbon_cost_M']:.1f}M\")\n",
    "        print(f\"      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "        print(f\"      TOTAL CLIMATE COST:       ${row['total_climate_cost_M']:.1f}M\")\n",
    "        print(f\"      Volume at risk:           {row['volume_at_risk_mt']:,.0f} MT ({row['pct_supply_at_risk']:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Save outputs\n",
    "combined_df.to_csv(f\"{CONFIG['base_path']}/outputs/total_climate_costs.csv\", index=False)\n",
    "print(\"âœ“ Saved combined results to outputs/total_climate_costs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d45ee03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TOTAL CLIMATE RISK - 30-YEAR NET PRESENT VALUE\n",
      "================================================================================\n",
      "\n",
      "Scenario                       Annual 2050     30-Yr NPV       % Assets    \n",
      "------------------------------------------------------------------------\n",
      "Net Zero 2050                  $       995.7M $     11209.9M       0.00%\n",
      "Delayed Transition             $      2453.8M $     27624.7M       0.00%\n",
      "Current Policies               $       207.8M $      2339.2M       0.00%\n",
      "\n",
      "================================================================================\n",
      "MATERIALITY ASSESSMENT (TCFD)\n",
      "================================================================================\n",
      "\n",
      "Financial materiality threshold: 5% of total assets\n",
      "Net Zero 2050                 :   0.00% of assets - âœ— Not material\n",
      "Delayed Transition            :   0.00% of assets - âœ— Not material\n",
      "Current Policies              :   0.00% of assets - âœ— Not material\n",
      "================================================================================\n",
      "\n",
      "âœ“ Saved to outputs/total_climate_npv.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOTAL CLIMATE RISK - 30-YEAR NET PRESENT VALUE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "discount_rate = CONFIG['financial_params']['discount_rate']\n",
    "\n",
    "total_npv_results = []\n",
    "\n",
    "for scenario_code in ['ssp126', 'ssp245', 'ssp585']:\n",
    "    scenario_name = scenario_map[scenario_code]\n",
    "    \n",
    "    # Get 2050 data (represents mid-term onwards)\n",
    "    mid_term = combined_df[\n",
    "        (combined_df['scenario_code'] == scenario_code) &\n",
    "        (combined_df['year'] == 2050)\n",
    "    ]\n",
    "    \n",
    "    if not mid_term.empty:\n",
    "        annual_cost = mid_term.iloc[0]['total_climate_cost_M']\n",
    "        \n",
    "        # NPV over 30 years\n",
    "        npv = sum([annual_cost / ((1 + discount_rate) ** t) for t in range(1, 31)])\n",
    "        \n",
    "        total_npv_results.append({\n",
    "            'scenario': scenario_code,\n",
    "            'scenario_name': scenario_name,\n",
    "            'annual_cost_2050_M': annual_cost,\n",
    "            'npv_30yr_M': npv,\n",
    "            'pct_of_total_revenue': (npv / CONFIG['financial_params']['total_revenue']) * 100,\n",
    "            'pct_of_total_assets': (npv / CONFIG['financial_params']['total_assets']) * 100\n",
    "        })\n",
    "\n",
    "total_npv_df = pd.DataFrame(total_npv_results)\n",
    "\n",
    "print(f\"\\n{'Scenario':<30s} {'Annual 2050':<15s} {'30-Yr NPV':<15s} {'% Assets':<12s}\")\n",
    "print(\"-\"*72)\n",
    "\n",
    "for _, row in total_npv_df.iterrows():\n",
    "    print(f\"{row['scenario_name']:<30s} ${row['annual_cost_2050_M']:>12.1f}M ${row['npv_30yr_M']:>12.1f}M {row['pct_of_total_assets']:>10.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MATERIALITY ASSESSMENT (TCFD)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nFinancial materiality threshold: 5% of total assets\")\n",
    "\n",
    "for _, row in total_npv_df.iterrows():\n",
    "    material = \"âœ“ MATERIAL\" if row['pct_of_total_assets'] > 5 else \"âœ— Not material\"\n",
    "    print(f\"{row['scenario_name']:<30s}: {row['pct_of_total_assets']:>6.2f}% of assets - {material}\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save\n",
    "total_npv_df.to_csv(f\"{CONFIG['base_path']}/outputs/total_climate_npv.csv\", index=False)\n",
    "print(\"\\nâœ“ Saved to outputs/total_climate_npv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6cea96b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario_code</th>\n",
       "      <th>scenario_name</th>\n",
       "      <th>year</th>\n",
       "      <th>physical_risk_M</th>\n",
       "      <th>carbon_cost_M</th>\n",
       "      <th>total_climate_cost_M</th>\n",
       "      <th>volume_at_risk_mt</th>\n",
       "      <th>pct_supply_at_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ssp126</td>\n",
       "      <td>Net Zero 2050</td>\n",
       "      <td>2030</td>\n",
       "      <td>114.763369</td>\n",
       "      <td>216.00</td>\n",
       "      <td>330.763369</td>\n",
       "      <td>5564.127708</td>\n",
       "      <td>3.234958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ssp126</td>\n",
       "      <td>Net Zero 2050</td>\n",
       "      <td>2050</td>\n",
       "      <td>118.247340</td>\n",
       "      <td>877.50</td>\n",
       "      <td>995.747340</td>\n",
       "      <td>5733.042765</td>\n",
       "      <td>3.333164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ssp245</td>\n",
       "      <td>Delayed Transition</td>\n",
       "      <td>2030</td>\n",
       "      <td>148.496078</td>\n",
       "      <td>126.00</td>\n",
       "      <td>274.496078</td>\n",
       "      <td>7199.606913</td>\n",
       "      <td>4.185818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ssp245</td>\n",
       "      <td>Delayed Transition</td>\n",
       "      <td>2050</td>\n",
       "      <td>158.833810</td>\n",
       "      <td>2295.00</td>\n",
       "      <td>2453.833810</td>\n",
       "      <td>7700.816131</td>\n",
       "      <td>4.477219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ssp585</td>\n",
       "      <td>Current Policies</td>\n",
       "      <td>2030</td>\n",
       "      <td>147.921496</td>\n",
       "      <td>10.56</td>\n",
       "      <td>158.481496</td>\n",
       "      <td>7171.749175</td>\n",
       "      <td>4.169622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  scenario_code       scenario_name  year  physical_risk_M  carbon_cost_M  \\\n",
       "0        ssp126       Net Zero 2050  2030       114.763369         216.00   \n",
       "1        ssp126       Net Zero 2050  2050       118.247340         877.50   \n",
       "2        ssp245  Delayed Transition  2030       148.496078         126.00   \n",
       "3        ssp245  Delayed Transition  2050       158.833810        2295.00   \n",
       "4        ssp585    Current Policies  2030       147.921496          10.56   \n",
       "\n",
       "   total_climate_cost_M  volume_at_risk_mt  pct_supply_at_risk  \n",
       "0            330.763369        5564.127708            3.234958  \n",
       "1            995.747340        5733.042765            3.333164  \n",
       "2            274.496078        7199.606913            4.185818  \n",
       "3           2453.833810        7700.816131            4.477219  \n",
       "4            158.481496        7171.749175            4.169622  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1aa9cd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 10: REGIONAL RISK CONCENTRATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Top 10 Most Vulnerable Regions (2050, Current Policies):\n",
      "----------------------------------------------------------------------\n",
      "Sumatra Aceh, Indonesia\n",
      "  Annual Volume: 6,900 MT (4.0% of supply)\n",
      "  Yield Loss: 23.5%\n",
      "  Volume at Risk: 1,625 MT\n",
      "  Profit at Risk: $33.5M\n",
      "\n",
      "Antioquia, Colombia\n",
      "  Annual Volume: 9,400 MT (5.5% of supply)\n",
      "  Yield Loss: 8.6%\n",
      "  Volume at Risk: 809 MT\n",
      "  Profit at Risk: $16.7M\n",
      "\n",
      "Minas Gerais Sul, Brazil\n",
      "  Annual Volume: 13,700 MT (8.0% of supply)\n",
      "  Yield Loss: 5.3%\n",
      "  Volume at Risk: 729 MT\n",
      "  Profit at Risk: $15.0M\n",
      "\n",
      "SÃ£o Paulo, Brazil\n",
      "  Annual Volume: 6,900 MT (4.0% of supply)\n",
      "  Yield Loss: 8.2%\n",
      "  Volume at Risk: 565 MT\n",
      "  Profit at Risk: $11.7M\n",
      "\n",
      "Central Highlands, Vietnam\n",
      "  Annual Volume: 2,600 MT (1.5% of supply)\n",
      "  Yield Loss: 19.5%\n",
      "  Volume at Risk: 508 MT\n",
      "  Profit at Risk: $10.5M\n",
      "\n",
      "Java West, Indonesia\n",
      "  Annual Volume: 3,400 MT (2.0% of supply)\n",
      "  Yield Loss: 14.8%\n",
      "  Volume at Risk: 503 MT\n",
      "  Profit at Risk: $10.4M\n",
      "\n",
      "Chiapas, Mexico\n",
      "  Annual Volume: 6,900 MT (4.0% of supply)\n",
      "  Yield Loss: 5.9%\n",
      "  Volume at Risk: 408 MT\n",
      "  Profit at Risk: $8.4M\n",
      "\n",
      "EspÃ­rito Santo, Brazil\n",
      "  Annual Volume: 5,200 MT (3.0% of supply)\n",
      "  Yield Loss: 7.2%\n",
      "  Volume at Risk: 377 MT\n",
      "  Profit at Risk: $7.8M\n",
      "\n",
      "West Valley, Costa Rica\n",
      "  Annual Volume: 6,000 MT (3.5% of supply)\n",
      "  Yield Loss: 5.6%\n",
      "  Volume at Risk: 335 MT\n",
      "  Profit at Risk: $6.9M\n",
      "\n",
      "Yunnan Pu er, China\n",
      "  Annual Volume: 3,400 MT (2.0% of supply)\n",
      "  Yield Loss: 9.0%\n",
      "  Volume at Risk: 307 MT\n",
      "  Profit at Risk: $6.3M\n",
      "\n",
      "CONCENTRATION RISK METRICS (2050, Current Policies):\n",
      "----------------------------------------------------------------------\n",
      "  Top 3 regions: $65.2M (37.2% of total risk)\n",
      "                 17.5% of total supply volume\n",
      "  Top 5 regions: $87.4M (49.8% of total risk)\n",
      "                 23.0% of total supply volume\n",
      "  Top 10 regions: $127.2M (72.5% of total risk)\n",
      "\n",
      "  Geographic concentration risk: MODERATE\n",
      "  Recommendation: Monitor and plan diversification\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 10: REGIONAL RISK CONCENTRATION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 10: REGIONAL RISK CONCENTRATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Worst case: SSP585, 2050\n",
    "regional_risk = yield_df[\n",
    "    (yield_df['scenario'] == 'ssp585') & \n",
    "    (yield_df['period'] == 'mid_term')\n",
    "].copy()\n",
    "\n",
    "# Sort by financial impact (profit at risk)\n",
    "regional_risk = regional_risk.sort_values('profit_at_risk_M', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Vulnerable Regions (2050, Current Policies):\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for idx, row in regional_risk.head(10).iterrows():\n",
    "    print(f\"{row['region_name']}, {row['country']}\")\n",
    "    print(f\"  Annual Volume: {row['annual_mt']:,.0f} MT ({row['sourcing_pct']:.1f}% of supply)\")\n",
    "    print(f\"  Yield Loss: {row['yield_loss_pct']*100:.1f}%\")\n",
    "    print(f\"  Volume at Risk: {row['volume_at_risk_mt']:,.0f} MT\")\n",
    "    print(f\"  Profit at Risk: ${row['profit_at_risk_M']:.1f}M\")\n",
    "    print()\n",
    "\n",
    "# Concentration metrics\n",
    "regional_risk['cumulative_cost'] = regional_risk['profit_at_risk_M'].cumsum()\n",
    "regional_risk['cumulative_pct'] = (\n",
    "    regional_risk['cumulative_cost'] / regional_risk['profit_at_risk_M'].sum() * 100\n",
    ")\n",
    "\n",
    "top_3_cost = regional_risk['profit_at_risk_M'].head(3).sum()\n",
    "top_5_cost = regional_risk['profit_at_risk_M'].head(5).sum()\n",
    "top_10_cost = regional_risk['profit_at_risk_M'].head(10).sum()\n",
    "total_cost = regional_risk['profit_at_risk_M'].sum()\n",
    "\n",
    "top_3_volume = regional_risk['sourcing_pct'].head(3).sum()\n",
    "top_5_volume = regional_risk['sourcing_pct'].head(5).sum()\n",
    "\n",
    "print(f\"CONCENTRATION RISK METRICS (2050, Current Policies):\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  Top 3 regions: ${top_3_cost:.1f}M ({top_3_cost/total_cost*100:.1f}% of total risk)\")\n",
    "print(f\"                 {top_3_volume:.1f}% of total supply volume\")\n",
    "print(f\"  Top 5 regions: ${top_5_cost:.1f}M ({top_5_cost/total_cost*100:.1f}% of total risk)\")\n",
    "print(f\"                 {top_5_volume:.1f}% of total supply volume\")\n",
    "print(f\"  Top 10 regions: ${top_10_cost:.1f}M ({top_10_cost/total_cost*100:.1f}% of total risk)\")\n",
    "print()\n",
    "\n",
    "# Risk classification\n",
    "concentration_risk_level = (\n",
    "    'CRITICAL' if top_3_cost/total_cost > 0.5 else\n",
    "    'HIGH' if top_3_cost/total_cost > 0.4 else\n",
    "    'MODERATE' if top_3_cost/total_cost > 0.25 else \n",
    "    'LOW'\n",
    ")\n",
    "\n",
    "print(f\"  Geographic concentration risk: {concentration_risk_level}\")\n",
    "print(f\"  Recommendation: {'URGENT diversification needed' if concentration_risk_level in ['CRITICAL', 'HIGH'] else 'Monitor and plan diversification'}\")\n",
    "print()\n",
    "\n",
    "# Save results\n",
    "regional_risk.to_csv(f\"{CONFIG['base_path']}/outputs/10_regional_risk_concentration.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a2349d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 11: SUPPLY CHAIN RESILIENCE & DIVERSIFICATION\n",
      "================================================================================\n",
      "\n",
      "Sourcing Distribution by Risk Level (2050, Current Policies):\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Low Risk (<20% loss):\n",
      "  Sourcing: 84.8% (145,560 MT)\n",
      "  Volume at risk: 6,879 MT\n",
      "  Profit at risk: $141.9M\n",
      "\n",
      "Medium Risk (20-40%):\n",
      "  Sourcing: 4.0% (6,900 MT)\n",
      "  Volume at risk: 1,625 MT\n",
      "  Profit at risk: $33.5M\n",
      "\n",
      "High Risk (>40%):\n",
      "  Sourcing: 0.0% (0 MT)\n",
      "  Volume at risk: 0 MT\n",
      "  Profit at risk: $0.0M\n",
      "\n",
      "======================================================================\n",
      "DIVERSIFICATION STRATEGY RECOMMENDATIONS\n",
      "======================================================================\n",
      "\n",
      "HIGH-PRIORITY ACTIONS (High-risk regions to phase out):\n",
      "----------------------------------------------------------------------\n",
      "  âœ“ No regions in critical risk category\n",
      "\n",
      "\n",
      "EXPANSION OPPORTUNITIES (Low-risk regions to scale up):\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "â€¢ Minas Gerais Sul, Brazil\n",
      "  Current: 8.0% of supply (13,700 MT)\n",
      "  Risk: Only 5.3% yield loss expected\n",
      "  Opportunity: Expand by 6,850 MT\n",
      "  Investment needed: ~$13.7M for infrastructure\n",
      "\n",
      "â€¢ Huila, Colombia\n",
      "  Current: 6.0% of supply (10,300 MT)\n",
      "  Risk: Only 1.0% yield loss expected\n",
      "  Opportunity: Expand by 5,150 MT\n",
      "  Investment needed: ~$10.3M for infrastructure\n",
      "\n",
      "â€¢ Antioquia, Colombia\n",
      "  Current: 5.5% of supply (9,400 MT)\n",
      "  Risk: Only 8.6% yield loss expected\n",
      "  Opportunity: Expand by 4,700 MT\n",
      "  Investment needed: ~$9.4M for infrastructure\n",
      "\n",
      "â€¢ Huehuetenango, Guatemala\n",
      "  Current: 5.0% of supply (8,600 MT)\n",
      "  Risk: Only 2.5% yield loss expected\n",
      "  Opportunity: Expand by 4,300 MT\n",
      "  Investment needed: ~$8.6M for infrastructure\n",
      "\n",
      "â€¢ Antigua, Guatemala\n",
      "  Current: 4.0% of supply (6,900 MT)\n",
      "  Risk: Only 3.4% yield loss expected\n",
      "  Opportunity: Expand by 3,450 MT\n",
      "  Investment needed: ~$6.9M for infrastructure\n",
      "\n",
      "\n",
      "OPTIMAL PORTFOLIO REBALANCING:\n",
      "----------------------------------------------------------------------\n",
      "Current allocation:\n",
      "  High risk: 0.0% (0 MT)\n",
      "  Medium risk: 4.0%\n",
      "  Low risk: 84.8% (145,560 MT)\n",
      "\n",
      "Recommended target (by 2035):\n",
      "  High risk: <15% (reduce by -15.0 percentage points)\n",
      "  Medium risk: 35-45%\n",
      "  Low risk: >40% (increase by -44.8 percentage points)\n",
      "\n",
      "âœ“ Saved resilience and diversification analysis to outputs/\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 11: SUPPLY CHAIN RESILIENCE & DIVERSIFICATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 11: SUPPLY CHAIN RESILIENCE & DIVERSIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use SSP585 (worst case) to categorize regions by risk\n",
    "resilience_df = yield_df[\n",
    "    (yield_df['scenario'] == 'ssp585') & \n",
    "    (yield_df['period'] == 'mid_term')\n",
    "].copy()\n",
    "\n",
    "# Create vulnerability score (0-1 scale)\n",
    "resilience_df['vulnerability_score'] = resilience_df['yield_loss_pct']\n",
    "\n",
    "# Categorize risk levels\n",
    "resilience_df['risk_category'] = pd.cut(\n",
    "    resilience_df['vulnerability_score'], \n",
    "    bins=[0, 0.20, 0.40, 1.0],\n",
    "    labels=['Low Risk (<20% loss)', 'Medium Risk (20-40%)', 'High Risk (>40%)']\n",
    ")\n",
    "\n",
    "print(\"\\nSourcing Distribution by Risk Level (2050, Current Policies):\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "risk_summary = resilience_df.groupby('risk_category').agg({\n",
    "    'sourcing_pct': 'sum',\n",
    "    'annual_mt': 'sum',\n",
    "    'volume_at_risk_mt': 'sum',\n",
    "    'profit_at_risk_M': 'sum'\n",
    "\n",
    "}).reset_index()\n",
    "\n",
    "for _, row in risk_summary.iterrows():\n",
    "    print(f\"\\n{row['risk_category']}:\")\n",
    "    print(f\"  Sourcing: {row['sourcing_pct']:.1f}% ({row['annual_mt']:,.0f} MT)\")\n",
    "    print(f\"  Volume at risk: {row['volume_at_risk_mt']:,.0f} MT\")\n",
    "    print(f\"  Profit at risk: ${row['profit_at_risk_M']:.1f}M\")\n",
    "\n",
    "# Diversification strategy\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DIVERSIFICATION STRATEGY RECOMMENDATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "high_risk = resilience_df[resilience_df['risk_category'] == 'High Risk (>40%)'].sort_values(\n",
    "    'sourcing_pct', ascending=False\n",
    ")\n",
    "low_risk = resilience_df[resilience_df['risk_category'] == 'Low Risk (<20% loss)'].sort_values(\n",
    "    'annual_mt', ascending=False\n",
    ")\n",
    "\n",
    "print(\"\\nHIGH-PRIORITY ACTIONS (High-risk regions to phase out):\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "if len(high_risk) > 0:\n",
    "    for idx, row in high_risk.head(5).iterrows():\n",
    "        replacement_needed = row['annual_mt']\n",
    "        print(f\"\\nâ€¢ {row['region_name']}, {row['country']}\")\n",
    "        print(f\"  Current: {row['sourcing_pct']:.1f}% of supply ({row['annual_mt']:,.0f} MT)\")\n",
    "        print(f\"  Risk: {row['yield_loss_pct']*100:.1f}% yield loss expected\")\n",
    "        print(f\"  Action: Reduce sourcing by {replacement_needed * 0.5:,.0f} MT over 5 years\")\n",
    "        print(f\"  Timeline: Begin transition by 2026\")\n",
    "else:\n",
    "    print(\"  âœ“ No regions in critical risk category\")\n",
    "\n",
    "print(\"\\n\\nEXPANSION OPPORTUNITIES (Low-risk regions to scale up):\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "if len(low_risk) > 0:\n",
    "    for idx, row in low_risk.head(5).iterrows():\n",
    "        expansion_potential = row['annual_mt'] * 0.5  # Could expand 50%\n",
    "        print(f\"\\nâ€¢ {row['region_name']}, {row['country']}\")\n",
    "        print(f\"  Current: {row['sourcing_pct']:.1f}% of supply ({row['annual_mt']:,.0f} MT)\")\n",
    "        print(f\"  Risk: Only {row['yield_loss_pct']*100:.1f}% yield loss expected\")\n",
    "        print(f\"  Opportunity: Expand by {expansion_potential:,.0f} MT\")\n",
    "        print(f\"  Investment needed: ~$\" + f\"{expansion_potential * 2000 / 1e6:.1f}M for infrastructure\")\n",
    "else:\n",
    "    print(\"  âš  No low-risk regions available for expansion\")\n",
    "\n",
    "# Calculate optimal portfolio rebalancing\n",
    "print(\"\\n\\nOPTIMAL PORTFOLIO REBALANCING:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "total_volume = CONFIG['financial_params']['starbucks_annual_coffee_mt']\n",
    "high_risk_volume = high_risk['annual_mt'].sum()\n",
    "low_risk_volume = low_risk['annual_mt'].sum()\n",
    "\n",
    "print(f\"Current allocation:\")\n",
    "print(f\"  High risk: {high_risk['sourcing_pct'].sum():.1f}% ({high_risk_volume:,.0f} MT)\")\n",
    "print(f\"  Medium risk: {risk_summary[risk_summary['risk_category']=='Medium Risk (20-40%)']['sourcing_pct'].values[0]:.1f}%\")\n",
    "print(f\"  Low risk: {low_risk['sourcing_pct'].sum():.1f}% ({low_risk_volume:,.0f} MT)\")\n",
    "\n",
    "print(f\"\\nRecommended target (by 2035):\")\n",
    "print(f\"  High risk: <15% (reduce by {high_risk['sourcing_pct'].sum() - 15:.1f} percentage points)\")\n",
    "print(f\"  Medium risk: 35-45%\")\n",
    "print(f\"  Low risk: >40% (increase by {40 - low_risk['sourcing_pct'].sum():.1f} percentage points)\")\n",
    "\n",
    "# Save results\n",
    "resilience_df.to_csv(f\"{CONFIG['base_path']}/outputs/11_supply_chain_resilience.csv\", index=False)\n",
    "risk_summary.to_csv(f\"{CONFIG['base_path']}/outputs/11_risk_distribution_summary.csv\", index=False)\n",
    "\n",
    "print(\"\\nâœ“ Saved resilience and diversification analysis to outputs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "edea824a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TOTAL CLIMATE RISK - 30-YEAR NET PRESENT VALUE\n",
      "================================================================================\n",
      "\n",
      "Scenario                       Annual 2050     30-Yr NPV       % Assets    \n",
      "------------------------------------------------------------------------\n",
      "Net Zero 2050                  $       995.7M $     11209.9M       0.00%\n",
      "Delayed Transition             $      2453.8M $     27624.7M       0.00%\n",
      "Current Policies               $       207.8M $      2339.2M       0.00%\n",
      "================================================================================\n",
      "\n",
      "âœ“ Saved to outputs/total_climate_npv.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOTAL CLIMATE RISK - 30-YEAR NET PRESENT VALUE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "discount_rate = CONFIG['financial_params']['discount_rate']\n",
    "\n",
    "total_npv_results = []\n",
    "\n",
    "for scenario_code in ['ssp126', 'ssp245', 'ssp585']:\n",
    "    scenario_name = scenario_map[scenario_code]\n",
    "    \n",
    "    mid_term = combined_df[\n",
    "        (combined_df['scenario_code'] == scenario_code) &\n",
    "        (combined_df['year'] == 2050)\n",
    "    ]\n",
    "    \n",
    "    if not mid_term.empty:\n",
    "        annual_cost = mid_term.iloc[0]['total_climate_cost_M']\n",
    "        npv = sum([annual_cost / ((1 + discount_rate) ** t) for t in range(1, 31)])\n",
    "        \n",
    "        total_npv_results.append({\n",
    "            'scenario': scenario_code,\n",
    "            'scenario_name': scenario_name,\n",
    "            'annual_cost_2050_M': annual_cost,\n",
    "            'npv_30yr_M': npv,\n",
    "            'pct_of_total_revenue': (npv / CONFIG['financial_params']['total_revenue']) * 100,\n",
    "            'pct_of_total_assets': (npv / CONFIG['financial_params']['total_assets']) * 100\n",
    "        })\n",
    "\n",
    "total_npv_df = pd.DataFrame(total_npv_results)\n",
    "\n",
    "print(f\"\\n{'Scenario':<30s} {'Annual 2050':<15s} {'30-Yr NPV':<15s} {'% Assets':<12s}\")\n",
    "print(\"-\"*72)\n",
    "\n",
    "for _, row in total_npv_df.iterrows():\n",
    "    print(f\"{row['scenario_name']:<30s} ${row['annual_cost_2050_M']:>12.1f}M ${row['npv_30yr_M']:>12.1f}M {row['pct_of_total_assets']:>10.2f}%\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_npv_df.to_csv(f\"{CONFIG['base_path']}/outputs/total_climate_npv.csv\", index=False)\n",
    "print(\"\\nâœ“ Saved to outputs/total_climate_npv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4fc48154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 12: STRATEGIC PRICING ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Delayed Transition Scenario (2050):\n",
      "  Total climate cost: $2453.8M\n",
      "    Physical: $158.8M\n",
      "    Carbon: $2295.0M\n",
      "\n",
      "  Cost per kg: $14.27\n",
      "  As % of current price: 19.4%\n",
      "\n",
      "Pricing Strategy Options:\n",
      "  Option A - Full pass-through: +19.4% price increase\n",
      "  Option B - Absorb 50%: +9.7% price increase\n",
      "  Option C - Full absorption: Margin compression of 19.4%\n",
      "\n",
      "Recommendation: Gradual price increases starting 2030 to maintain margins\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 12: STRATEGIC PRICING RESPONSE (SIMPLIFIED)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 12: STRATEGIC PRICING ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Focus on most material scenario: Delayed Transition 2050\n",
    "ssp245_2050 = combined_df[\n",
    "    (combined_df['scenario_code'] == 'ssp245') & \n",
    "    (combined_df['year'] == 2050)\n",
    "].iloc[0]\n",
    "\n",
    "total_cost_M = ssp245_2050['total_climate_cost_M']\n",
    "physical_M = ssp245_2050['physical_risk_M']\n",
    "carbon_M = ssp245_2050['carbon_cost_M']\n",
    "\n",
    "# Calculate per-kg impact\n",
    "total_volume_kg = CONFIG['financial_params']['starbucks_annual_coffee_mt'] * 1000\n",
    "cost_per_kg = (total_cost_M * 1_000_000) / total_volume_kg\n",
    "current_revenue_per_kg = CONFIG['financial_params']['coffee_revenue'] / total_volume_kg\n",
    "\n",
    "print(f\"\\nDelayed Transition Scenario (2050):\")\n",
    "print(f\"  Total climate cost: ${total_cost_M:.1f}M\")\n",
    "print(f\"    Physical: ${physical_M:.1f}M\")\n",
    "print(f\"    Carbon: ${carbon_M:.1f}M\")\n",
    "print(f\"\\n  Cost per kg: ${cost_per_kg:.2f}\")\n",
    "print(f\"  As % of current price: {cost_per_kg/current_revenue_per_kg*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nPricing Strategy Options:\")\n",
    "print(f\"  Option A - Full pass-through: +{cost_per_kg/current_revenue_per_kg*100:.1f}% price increase\")\n",
    "print(f\"  Option B - Absorb 50%: +{cost_per_kg/current_revenue_per_kg*50:.1f}% price increase\")\n",
    "print(f\"  Option C - Full absorption: Margin compression of {cost_per_kg/current_revenue_per_kg*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nRecommendation: Gradual price increases starting 2030 to maintain margins\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5420dbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 14: COMPETITOR BENCHMARKING & MARKET POSITIONING\n",
      "================================================================================\n",
      "Starbucks Top-3 Concentration (from YOUR analysis): 17.5%\n",
      "\n",
      "\n",
      "VULNERABILITY RANKING (Most â†’ Least Vulnerable):\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ”´ illycaffÃ¨ â€” Vulnerability: 0.76\n",
      "   Volume: 8,000 MT\n",
      "   Regions: 12\n",
      "   Top-3 concentration: 60.0%\n",
      "   Diversification score: 0.32\n",
      "   Preparedness score: 0.12\n",
      "   Estimated 2050 climate cost: $41M\n",
      "   Cost as % of revenue: 11.4%\n",
      "   Disclosure: Sustainability report\n",
      "\n",
      "ğŸŸ¡ Lavazza â€” Vulnerability: 0.65\n",
      "   Volume: 60,000 MT\n",
      "   Regions: 25\n",
      "   Top-3 concentration: 45.0%\n",
      "   Diversification score: 0.53\n",
      "   Preparedness score: 0.09\n",
      "   Estimated 2050 climate cost: $263M\n",
      "   Cost as % of revenue: 9.8%\n",
      "   Disclosure: Basic ESG\n",
      "\n",
      "ğŸŸ¡ JDE Peets â€” Vulnerability: 0.53\n",
      "   Volume: 180,000 MT\n",
      "   Regions: 35\n",
      "   Top-3 concentration: 38.0%\n",
      "   Diversification score: 0.66\n",
      "   Preparedness score: 0.18\n",
      "   Estimated 2050 climate cost: $648M\n",
      "   Cost as % of revenue: 8.0%\n",
      "   Disclosure: Partial TCFD\n",
      "\n",
      "ğŸŸ¡ Starbucks â€” Vulnerability: 0.46\n",
      "   Volume: 172,000 MT\n",
      "   Regions: 29\n",
      "   Top-3 concentration: 17.5%\n",
      "   Diversification score: 0.70\n",
      "   Preparedness score: 0.30\n",
      "   Estimated 2050 climate cost: $208M\n",
      "   Cost as % of revenue: 2.7%\n",
      "   Disclosure: TCFD-aligned\n",
      "\n",
      "ğŸŸ¢ NestlÃ© (NescafÃ©) â€” Vulnerability: 0.41\n",
      "   Volume: 230,000 MT\n",
      "   Regions: 50\n",
      "   Top-3 concentration: 40.0%\n",
      "   Diversification score: 0.80\n",
      "   Preparedness score: 0.27\n",
      "   Estimated 2050 climate cost: $641M\n",
      "   Cost as % of revenue: 6.2%\n",
      "   Disclosure: TCFD-compliant\n",
      "\n",
      "======================================================================\n",
      "STARBUCKS COMPETITIVE POSITION\n",
      "======================================================================\n",
      "\n",
      "Starbucks ranks: #4 (1 = most vulnerable)\n",
      "  Diversification: 0.70\n",
      "  Preparedness: 0.30\n",
      "  Vulnerability: 0.46\n",
      "\n",
      "Potential improvement with adaptation:\n",
      "  Diversification: 0.70 â†’ 0.85\n",
      "  Preparedness: 0.30 â†’ 0.55\n",
      "\n",
      "âœ“ Saved competitor benchmarking analysis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 14: COMPETITOR BENCHMARKING & MARKET POSITIONING  (FULLY FIXED)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 14: COMPETITOR BENCHMARKING & MARKET POSITIONING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# COMPETITOR PROFILES (Based on public data & industry reports)\n",
    "# ============================================================================\n",
    "\n",
    "competitors = {\n",
    "    'Starbucks': {\n",
    "        'annual_volume_mt': CONFIG['financial_params']['starbucks_annual_coffee_mt'],\n",
    "        'sourcing_regions': len(regions_df),\n",
    "        'top3_concentration': None,   # Will be replaced with real calculated value\n",
    "        'climate_disclosure': 'TCFD-aligned',\n",
    "        'adaptation_investment_M': 0, # Will be updated from Step 13 if desired\n",
    "        'sustainability_commitment': 'Net-zero by 2050'\n",
    "    },\n",
    "    'NestlÃ© (NescafÃ©)': {\n",
    "        'annual_volume_mt': 230000,\n",
    "        'sourcing_regions': 50,\n",
    "        'top3_concentration': 0.40,\n",
    "        'climate_disclosure': 'TCFD-compliant',\n",
    "        'adaptation_investment_M': 300,\n",
    "        'sustainability_commitment': 'Net-zero by 2050'\n",
    "    },\n",
    "    'JDE Peets': {\n",
    "        'annual_volume_mt': 180000,\n",
    "        'sourcing_regions': 35,\n",
    "        'top3_concentration': 0.38,\n",
    "        'climate_disclosure': 'Partial TCFD',\n",
    "        'adaptation_investment_M': 150,\n",
    "        'sustainability_commitment': 'Carbon neutral by 2040'\n",
    "    },\n",
    "    'Lavazza': {\n",
    "        'annual_volume_mt': 60000,\n",
    "        'sourcing_regions': 25,\n",
    "        'top3_concentration': 0.45,\n",
    "        'climate_disclosure': 'Basic ESG',\n",
    "        'adaptation_investment_M': 80,\n",
    "        'sustainability_commitment': 'Sustainable sourcing 100% by 2030'\n",
    "    },\n",
    "    'illycaffÃ¨': {\n",
    "        'annual_volume_mt': 8000,\n",
    "        'sourcing_regions': 12,\n",
    "        'top3_concentration': 0.60,\n",
    "        'climate_disclosure': 'Sustainability report',\n",
    "        'adaptation_investment_M': 20,\n",
    "        'sustainability_commitment': 'Carbon neutral by 2033'\n",
    "    }\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# CALCULATE STARBUCKS TOP-3 CONCENTRATION FROM YOUR DATA\n",
    "# ============================================================================\n",
    "\n",
    "regional_risk_585_2050 = yield_df[\n",
    "    (yield_df['scenario'] == 'ssp585') &\n",
    "    (yield_df['period'] == 'mid_term')\n",
    "].sort_values('profit_at_risk_M', ascending=False)\n",
    "\n",
    "starbucks_top3_concentration = regional_risk_585_2050.head(3)['sourcing_pct'].sum() / 100\n",
    "competitors['Starbucks']['top3_concentration'] = starbucks_top3_concentration\n",
    "\n",
    "print(f\"Starbucks Top-3 Concentration (from YOUR analysis): {starbucks_top3_concentration:.1%}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# GET STARBUCKS BASELINE CLIMATE COST (FROM Step 9 COMBINED_DF)\n",
    "# ============================================================================\n",
    "\n",
    "sbux_cost_2050 = combined_df[\n",
    "    (combined_df['scenario_code'] == 'ssp585') &\n",
    "    (combined_df['year'] == 2050)\n",
    "]['total_climate_cost_M'].values[0]\n",
    "\n",
    "# ============================================================================\n",
    "# BUILD COMPETITOR COMPARISON TABLE\n",
    "# ============================================================================\n",
    "\n",
    "competitor_analysis = []\n",
    "\n",
    "# Starbucks' own diversification and preparedness for scaling comparisons\n",
    "sbux_regions = competitors['Starbucks']['sourcing_regions']\n",
    "sbux_top3 = competitors['Starbucks']['top3_concentration']\n",
    "\n",
    "# Diversification score for Starbucks\n",
    "sbux_region_div_score = min(sbux_regions / 50, 1.0)\n",
    "sbux_concentration_score = 1 - sbux_top3\n",
    "sbux_diversification = (sbux_region_div_score * 0.5) + (sbux_concentration_score * 0.5)\n",
    "\n",
    "sbux_preparedness = 1.0  # TCFD-aligned baseline\n",
    "sbux_vulnerability = 1 - ((sbux_diversification * 0.6) + (sbux_preparedness * 0.4))\n",
    "\n",
    "for company, profile in competitors.items():\n",
    "\n",
    "    # ---------- Diversification Score ----------\n",
    "    region_div = min(profile['sourcing_regions'] / 50, 1.0)\n",
    "    conc_score = 1 - profile['top3_concentration']\n",
    "    diversification_score = (region_div * 0.5) + (conc_score * 0.5)\n",
    "\n",
    "    # ---------- Preparedness Score ----------\n",
    "    disclosure_map = {\n",
    "        'TCFD-aligned': 1.0,\n",
    "        'TCFD-compliant': 0.9,\n",
    "        'Partial TCFD': 0.6,\n",
    "        'Sustainability report': 0.4,\n",
    "        'Basic ESG': 0.3\n",
    "    }\n",
    "    disclosure_score = disclosure_map.get(profile['climate_disclosure'], 0.2)\n",
    "\n",
    "    # Normalize investment\n",
    "    if profile['annual_volume_mt'] > 0:\n",
    "        invest_per_mt = profile['adaptation_investment_M'] / profile['annual_volume_mt']\n",
    "        investment_score = min(invest_per_mt / 2, 1.0)\n",
    "    else:\n",
    "        investment_score = 0\n",
    "\n",
    "    preparedness_score = (investment_score * 0.7) + (disclosure_score * 0.3)\n",
    "\n",
    "    # ---------- Vulnerability ----------\n",
    "    vulnerability_score = 1 - ((diversification_score * 0.6) + (preparedness_score * 0.4))\n",
    "\n",
    "    # ---------- Climate Cost ----------\n",
    "    if company == 'Starbucks':\n",
    "        estimated_cost = sbux_cost_2050\n",
    "    else:\n",
    "        volume_ratio = profile['annual_volume_mt'] / competitors['Starbucks']['annual_volume_mt']\n",
    "        vulnerability_adjustment = vulnerability_score / sbux_vulnerability\n",
    "        estimated_cost = sbux_cost_2050 * volume_ratio * vulnerability_adjustment\n",
    "\n",
    "    # Revenue baseline: assume $45/kg like Starbucks\n",
    "    annual_revenue = profile['annual_volume_mt'] * 1000 * 45\n",
    "    cost_pct_rev = (estimated_cost * 1e6 / annual_revenue) * 100 if annual_revenue > 0 else 0\n",
    "\n",
    "    competitor_analysis.append({\n",
    "        'company': company,\n",
    "        'annual_volume_mt': profile['annual_volume_mt'],\n",
    "        'sourcing_regions': profile['sourcing_regions'],\n",
    "        'top3_concentration': profile['top3_concentration'],\n",
    "        'diversification_score': diversification_score,\n",
    "        'preparedness_score': preparedness_score,\n",
    "        'vulnerability_score': vulnerability_score,\n",
    "        'estimated_climate_cost_2050_M': estimated_cost,\n",
    "        'cost_pct_revenue': cost_pct_rev,\n",
    "        'climate_disclosure': profile['climate_disclosure'],\n",
    "        'sustainability_commitment': profile['sustainability_commitment']\n",
    "    })\n",
    "\n",
    "competitor_df = pd.DataFrame(competitor_analysis)\n",
    "competitor_df = competitor_df.sort_values('vulnerability_score', ascending=False)\n",
    "\n",
    "# ============================================================================\n",
    "# DISPLAY RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nVULNERABILITY RANKING (Most â†’ Least Vulnerable):\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for idx, row in competitor_df.iterrows():\n",
    "    \n",
    "    vuln_color = \"ğŸ”´\" if row['vulnerability_score'] > 0.65 else \"ğŸŸ¡\" if row['vulnerability_score'] > 0.45 else \"ğŸŸ¢\"\n",
    "    \n",
    "    print(f\"\\n{vuln_color} {row['company']} â€” Vulnerability: {row['vulnerability_score']:.2f}\")\n",
    "    print(f\"   Volume: {row['annual_volume_mt']:,.0f} MT\")\n",
    "    print(f\"   Regions: {row['sourcing_regions']}\")\n",
    "    print(f\"   Top-3 concentration: {row['top3_concentration']:.1%}\")\n",
    "    print(f\"   Diversification score: {row['diversification_score']:.2f}\")\n",
    "    print(f\"   Preparedness score: {row['preparedness_score']:.2f}\")\n",
    "    print(f\"   Estimated 2050 climate cost: ${row['estimated_climate_cost_2050_M']:.0f}M\")\n",
    "    print(f\"   Cost as % of revenue: {row['cost_pct_revenue']:.1f}%\")\n",
    "    print(f\"   Disclosure: {row['climate_disclosure']}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STARBUCKS COMPETITIVE POSITIONING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARBUCKS COMPETITIVE POSITION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "sbux_row = competitor_df[competitor_df['company'] == 'Starbucks'].iloc[0]\n",
    "sbux_rank = competitor_df.index.get_loc(sbux_row.name) + 1\n",
    "\n",
    "print(f\"\\nStarbucks ranks: #{sbux_rank} (1 = most vulnerable)\")\n",
    "print(f\"  Diversification: {sbux_row['diversification_score']:.2f}\")\n",
    "print(f\"  Preparedness: {sbux_row['preparedness_score']:.2f}\")\n",
    "print(f\"  Vulnerability: {sbux_row['vulnerability_score']:.2f}\")\n",
    "\n",
    "print(\"\\nPotential improvement with adaptation:\")\n",
    "print(f\"  Diversification: {sbux_row['diversification_score']:.2f} â†’ {min(sbux_row['diversification_score']+0.15,1):.2f}\")\n",
    "print(f\"  Preparedness: {sbux_row['preparedness_score']:.2f} â†’ {min(sbux_row['preparedness_score']+0.25,1):.2f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE\n",
    "# ============================================================================\n",
    "\n",
    "competitor_df.to_csv(f\"{CONFIG['base_path']}/outputs/14_competitor_benchmarking.csv\", index=False)\n",
    "\n",
    "print(\"\\nâœ“ Saved competitor benchmarking analysis.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6105c9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 15: CARBON PRICE HEDGING STRATEGY\n",
      "================================================================================\n",
      "BASELINE CARBON EXPOSURE (Delayed Transition, 2050):\n",
      "  Annual carbon cost: $2295M\n",
      "  Price per ton: $306/tCO2\n",
      "\n",
      "\n",
      "No Hedge:\n",
      "  Hedged exposure: $0M\n",
      "  Annual cost: $0.0M\n",
      "  Savings if spike: $0M\n",
      "  Net benefit: $0M\n",
      "\n",
      "25% Carbon Swaps:\n",
      "  Hedged exposure: $574M\n",
      "  Annual cost: $17.2M\n",
      "  Savings if spike: $361M\n",
      "  Net benefit: $344M\n",
      "\n",
      "50% Carbon Futures:\n",
      "  Hedged exposure: $1148M\n",
      "  Annual cost: $57.4M\n",
      "  Savings if spike: $723M\n",
      "  Net benefit: $666M\n",
      "\n",
      "75% Collar Strategy:\n",
      "  Hedged exposure: $1721M\n",
      "  Annual cost: $120.5M\n",
      "  Savings if spike: $1084M\n",
      "  Net benefit: $964M\n",
      "\n",
      "Recommendation: 25-50% carbon price hedge to manage transition risk volatility\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 15: CARBON PRICE RISK HEDGING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 15: CARBON PRICE HEDGING STRATEGY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Focus on Delayed Transition scenario ($2,295M carbon cost)\n",
    "baseline_carbon_cost_M = 2295  # From Step 9\n",
    "\n",
    "print(f\"BASELINE CARBON EXPOSURE (Delayed Transition, 2050):\")\n",
    "print(f\"  Annual carbon cost: ${baseline_carbon_cost_M:.0f}M\")\n",
    "print(f\"  Price per ton: $306/tCO2\")\n",
    "print()\n",
    "\n",
    "# Carbon hedging strategies\n",
    "hedging_strategies = [\n",
    "    {'strategy': 'No Hedge', 'hedge_ratio': 0.0, 'cost_pct': 0},\n",
    "    {'strategy': '25% Carbon Swaps', 'hedge_ratio': 0.25, 'cost_pct': 3},\n",
    "    {'strategy': '50% Carbon Futures', 'hedge_ratio': 0.50, 'cost_pct': 5},\n",
    "    {'strategy': '75% Collar Strategy', 'hedge_ratio': 0.75, 'cost_pct': 7},\n",
    "]\n",
    "\n",
    "for strategy in hedging_strategies:\n",
    "    hedged_amount_M = baseline_carbon_cost_M * strategy['hedge_ratio']\n",
    "    hedge_cost_M = hedged_amount_M * strategy['cost_pct'] / 100\n",
    "    \n",
    "    # If carbon price spikes to $500/ton (from $306)\n",
    "    price_spike_pct = 0.63  # (500-306)/306\n",
    "    savings_if_spike_M = hedged_amount_M * price_spike_pct\n",
    "    net_benefit_M = savings_if_spike_M - hedge_cost_M\n",
    "    \n",
    "    print(f\"\\n{strategy['strategy']}:\")\n",
    "    print(f\"  Hedged exposure: ${hedged_amount_M:.0f}M\")\n",
    "    print(f\"  Annual cost: ${hedge_cost_M:.1f}M\")\n",
    "    print(f\"  Savings if spike: ${savings_if_spike_M:.0f}M\")\n",
    "    print(f\"  Net benefit: ${net_benefit_M:.0f}M\")\n",
    "\n",
    "print(\"\\nRecommendation: 25-50% carbon price hedge to manage transition risk volatility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa78f97",
   "metadata": {},
   "source": [
    "new visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53369df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 17A: NET-ZERO EMISSION TRAJECTORY (ORIGINAL FORMAT)\n",
      "======================================================================\n",
      "\n",
      "ACTUAL STARBUCKS BASELINE EMISSIONS (2023):\n",
      "  Scope 1: 0.3 M MT CO2e\n",
      "  Scope 2: 1.2 M MT CO2e\n",
      "  Scope 3: 13.8 M MT CO2e\n",
      "  TOTAL BASELINE: 15.3 M MT CO2e\n",
      "\n",
      "OFFICIAL STARBUCKS NET-ZERO TARGETS:\n",
      "  2030: 7.65 M MT CO2e (50% cut)\n",
      "  2050: 0.77 M MT CO2e (95% cut)\n",
      "\n",
      "Year     Business-as-Usual    Net-Zero Pathway     Reduction    Reduction %\n",
      "---------------------------------------------------------------------------\n",
      "2024     15.30                15.30                0.00               0.0%\n",
      "2030     17.23                7.65                 9.58              55.6%\n",
      "2035     19.02                6.43                 12.60             66.2%\n",
      "2040     21.00                2.75                 18.25             86.9%\n",
      "2045     23.19                1.53                 21.66             93.4%\n",
      "2050     25.60                0.77                 24.84             97.0%\n",
      "\n",
      "âœ“ Saved original emission trajectory to outputs/17a_emission_trajectory.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 17A: EMISSION TRAJECTORY (ORIGINAL OUTPUT)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 17A: NET-ZERO EMISSION TRAJECTORY (ORIGINAL FORMAT)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Baseline Starbucks emissions (2023 ESG Report)\n",
    "scope_1_baseline = 0.3\n",
    "scope_2_baseline = 1.2\n",
    "scope_3_baseline = 13.8\n",
    "total_baseline = scope_1_baseline + scope_2_baseline + scope_3_baseline\n",
    "\n",
    "print(f\"\\nACTUAL STARBUCKS BASELINE EMISSIONS (2023):\")\n",
    "print(f\"  Scope 1: {scope_1_baseline:.1f} M MT CO2e\")\n",
    "print(f\"  Scope 2: {scope_2_baseline:.1f} M MT CO2e\")\n",
    "print(f\"  Scope 3: {scope_3_baseline:.1f} M MT CO2e\")\n",
    "print(f\"  TOTAL BASELINE: {total_baseline:.1f} M MT CO2e\")\n",
    "\n",
    "# Starbucks official targets\n",
    "target_2030_reduction = 0.50     # 50% by 2030\n",
    "target_2050_reduction = 0.95     # 95% by 2050 (net-zero with 5% offsets)\n",
    "\n",
    "target_2030 = total_baseline * (1 - target_2030_reduction)\n",
    "target_2050 = total_baseline * (1 - target_2050_reduction)\n",
    "\n",
    "print(f\"\\nOFFICIAL STARBUCKS NET-ZERO TARGETS:\")\n",
    "print(f\"  2030: {target_2030:.2f} M MT CO2e (50% cut)\")\n",
    "print(f\"  2050: {target_2050:.2f} M MT CO2e (95% cut)\")\n",
    "\n",
    "# Emission trajectory: BAU vs Net-Zero\n",
    "years = [2024, 2030, 2035, 2040, 2045, 2050]\n",
    "growth_rate = 1.02  # BAU = 2%/yr growth\n",
    "\n",
    "business_as_usual = [\n",
    "    total_baseline * (growth_rate ** (year - 2024)) \n",
    "    for year in years\n",
    "]\n",
    "\n",
    "net_zero_trajectory = [\n",
    "    total_baseline,         # 2024\n",
    "    target_2030,            # 2030: 50% reduction\n",
    "    total_baseline * 0.42,  # interpolated to 2035\n",
    "    total_baseline * 0.18,  # 2040\n",
    "    total_baseline * 0.10,  # 2045\n",
    "    target_2050             # 2050\n",
    "]\n",
    "\n",
    "print(\"\\nYear     Business-as-Usual    Net-Zero Pathway     Reduction    Reduction %\")\n",
    "print(\"-\" * 75)\n",
    "for i, year in enumerate(years):\n",
    "    bau = business_as_usual[i]\n",
    "    nz = net_zero_trajectory[i]\n",
    "    reduction = bau - nz\n",
    "    reduction_pct = (reduction / bau) * 100 if bau > 0 else 0\n",
    "    print(f\"{year:<8} {bau:<20.2f} {nz:<20.2f} {reduction:<12.2f} {reduction_pct:>9.1f}%\")\n",
    "\n",
    "# Save emissions trajectory\n",
    "trajectory_df = pd.DataFrame({\n",
    "    'year': years,\n",
    "    'business_as_usual_MT': business_as_usual,\n",
    "    'net_zero_MT': net_zero_trajectory,\n",
    "})\n",
    "trajectory_df.to_csv(f\"{CONFIG['base_path']}/outputs/17a_emission_trajectory.csv\", index=False)\n",
    "\n",
    "print(\"\\nâœ“ Saved original emission trajectory to outputs/17a_emission_trajectory.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bdcb2835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 17B: NET-ZERO FINANCIAL IMPACT USING REAL PHYSICAL + TRANSITION RISKS\n",
      "======================================================================\n",
      "\n",
      "REAL CLIMATE RISK METRICS (SSP585):\n",
      "  2030 total climate cost: $158.5M\n",
      "     - Physical: $147.9M\n",
      "     - Carbon:   $10.6M\n",
      "  2050 total climate cost: $207.8M\n",
      "     - Physical: $175.4M\n",
      "     - Carbon:   $32.4M\n",
      "\n",
      "FINANCIAL IMPACT:\n",
      "  Avoided cost (2030): $-722M\n",
      "  Avoided cost (2050): $-95M\n",
      "\n",
      "NET FINANCIAL BENEFIT OF NET-ZERO:\n",
      "  30-year avoided climate cost: $-10,615M\n",
      "  Net benefit after investment: $-12,315M\n",
      "  ROI: -724%\n",
      "\n",
      "âœ“ Saved net-zero financial analysis to outputs/17b_net_zero_financial_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 17B: NET-ZERO FINANCIAL IMPACT (PIPELINE-INTEGRATED)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 17B: NET-ZERO FINANCIAL IMPACT USING REAL PHYSICAL + TRANSITION RISKS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Pull climate risk values from your model (SSP585 worst case)\n",
    "phys_2030 = combined_df[(combined_df['scenario_code']=='ssp585') & (combined_df['year']==2030)]\n",
    "phys_2050 = combined_df[(combined_df['scenario_code']=='ssp585') & (combined_df['year']==2050)]\n",
    "\n",
    "physical_2030_M = float(phys_2030['physical_risk_M'])\n",
    "physical_2050_M = float(phys_2050['physical_risk_M'])\n",
    "carbon_2030_M   = float(phys_2030['carbon_cost_M'])\n",
    "carbon_2050_M   = float(phys_2050['carbon_cost_M'])\n",
    "total_2030_M    = float(phys_2030['total_climate_cost_M'])\n",
    "total_2050_M    = float(phys_2050['total_climate_cost_M'])\n",
    "\n",
    "print(\"\\nREAL CLIMATE RISK METRICS (SSP585):\")\n",
    "print(f\"  2030 total climate cost: ${total_2030_M:,.1f}M\")\n",
    "print(f\"     - Physical: ${physical_2030_M:,.1f}M\")\n",
    "print(f\"     - Carbon:   ${carbon_2030_M:,.1f}M\")\n",
    "print(f\"  2050 total climate cost: ${total_2050_M:,.1f}M\")\n",
    "print(f\"     - Physical: ${physical_2050_M:,.1f}M\")\n",
    "print(f\"     - Carbon:   ${carbon_2050_M:,.1f}M\")\n",
    "\n",
    "# Cost of inaction = total climate cost\n",
    "cost_of_inaction_2030 = total_2030_M\n",
    "cost_of_inaction_2050 = total_2050_M\n",
    "\n",
    "# Cost of net-zero (decarbonization investment + reduced risk exposure)\n",
    "total_investment = 1700  # $M through 2050\n",
    "\n",
    "carbon_cost_2030_nz = target_2030 * 75\n",
    "carbon_cost_2050_nz = target_2050 * 150\n",
    "\n",
    "supply_2030_nz = physical_2030_M * 0.35\n",
    "supply_2050_nz = physical_2050_M * 0.10\n",
    "\n",
    "cost_of_nz_2030 = carbon_cost_2030_nz + supply_2030_nz + (total_investment * 0.15)\n",
    "cost_of_nz_2050 = carbon_cost_2050_nz + supply_2050_nz + (total_investment * 0.10)\n",
    "\n",
    "avoided_cost_2030 = cost_of_inaction_2030 - cost_of_nz_2030\n",
    "avoided_cost_2050 = cost_of_inaction_2050 - cost_of_nz_2050\n",
    "\n",
    "print(\"\\nFINANCIAL IMPACT:\")\n",
    "print(f\"  Avoided cost (2030): ${avoided_cost_2030:,.0f}M\")\n",
    "print(f\"  Avoided cost (2050): ${avoided_cost_2050:,.0f}M\")\n",
    "\n",
    "avg_annual_benefit = (avoided_cost_2030 + avoided_cost_2050) / 2\n",
    "net_benefit = avg_annual_benefit * 26 - total_investment\n",
    "\n",
    "print(\"\\nNET FINANCIAL BENEFIT OF NET-ZERO:\")\n",
    "print(f\"  30-year avoided climate cost: ${avg_annual_benefit*26:,.0f}M\")\n",
    "print(f\"  Net benefit after investment: ${net_benefit:,.0f}M\")\n",
    "print(f\"  ROI: {net_benefit / total_investment * 100:.0f}%\")\n",
    "\n",
    "# Save results\n",
    "nz_df = pd.DataFrame({\n",
    "    'year': [2030, 2050],\n",
    "    'cost_of_inaction_M': [cost_of_inaction_2030, cost_of_inaction_2050],\n",
    "    'cost_of_net_zero_M': [cost_of_nz_2030, cost_of_nz_2050],\n",
    "    'avoided_cost_M': [avoided_cost_2030, avoided_cost_2050],\n",
    "})\n",
    "nz_df.to_csv(f\"{CONFIG['base_path']}/outputs/17b_net_zero_financial_analysis.csv\", index=False)\n",
    "\n",
    "print(\"\\nâœ“ Saved net-zero financial analysis to outputs/17b_net_zero_financial_analysis.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b41e5f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CREATING PORTFOLIO VISUALIZATIONS\n",
      "================================================================================\n",
      "\n",
      "1. Creating Executive Dashboard...\n",
      "   âœ“ Saved: 01_Executive_Dashboard.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VIZ 1: EXECUTIVE DASHBOARD - COMPLETE STORY\n",
    "# ============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING PORTFOLIO VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Setup\n",
    "output_dir = f\"{CONFIG['base_path']}/outputs/visualizations\"\n",
    "import os\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "print(\"\\n1. Creating Executive Dashboard...\")\n",
    "\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.3)\n",
    "\n",
    "fig.suptitle('STARBUCKS CLIMATE RISK ASSESSMENT - EXECUTIVE DASHBOARD\\nTCFD-Aligned Analysis (2025-2050)', \n",
    "             fontsize=18, fontweight='bold', y=0.98)\n",
    "\n",
    "# ============================================================================\n",
    "# PANEL 1 (Top): TOTAL CLIMATE COST BY SCENARIO - 2050\n",
    "# ============================================================================\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "\n",
    "scenarios_2050 = combined_df[combined_df['year'] == 2050].copy()\n",
    "scenario_order = ['ssp126', 'ssp245', 'ssp585']\n",
    "scenario_names = ['Net-Zero 2050', 'Delayed Transition', 'Current Policies']\n",
    "\n",
    "totals = [scenarios_2050[scenarios_2050['scenario_code'] == s]['total_climate_cost_M'].values[0] \n",
    "          for s in scenario_order]\n",
    "physical = [scenarios_2050[scenarios_2050['scenario_code'] == s]['physical_risk_M'].values[0] \n",
    "            for s in scenario_order]\n",
    "carbon = [scenarios_2050[scenarios_2050['scenario_code'] == s]['carbon_cost_M'].values[0] \n",
    "          for s in scenario_order]\n",
    "\n",
    "colors = ['#2ecc71', '#f39c12', '#e74c3c']\n",
    "bars = ax1.bar(scenario_names, totals, color=colors, edgecolor='black', linewidth=2, alpha=0.85)\n",
    "\n",
    "for bar, total, phys, carb in zip(bars, totals, physical, carbon):\n",
    "    height = bar.get_height()\n",
    "    # Total on top\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + max(totals)*0.02,\n",
    "            f'${total:,.0f}M', ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "    \n",
    "    # Components inside\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height*0.5,\n",
    "            f'Physical: ${phys:.0f}M\\nCarbon: ${carb:.0f}M', \n",
    "            ha='center', va='center', fontsize=9, color='white', fontweight='bold')\n",
    "\n",
    "ax1.set_ylabel('Total Annual Climate Cost ($M)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Total Climate Risk by Scenario (2050)', fontsize=14, fontweight='bold', pad=15)\n",
    "ax1.yaxis.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, max(totals) * 1.15)\n",
    "\n",
    "# Add key insight\n",
    "insight_text = f\"Transition risks (carbon) are {carbon[1]/physical[1]:.0f}x larger than physical risks\"\n",
    "ax1.text(0.98, 0.95, insight_text, transform=ax1.transAxes,\n",
    "         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7),\n",
    "         fontsize=10, fontweight='bold', ha='right', va='top')\n",
    "\n",
    "# ============================================================================\n",
    "# PANEL 2 (Middle-Left): REGIONAL RISK DISTRIBUTION PIE\n",
    "# ============================================================================\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "\n",
    "regional_2050 = yield_df[\n",
    "    (yield_df['scenario'] == 'ssp585') &\n",
    "    (yield_df['period'] == 'mid_term')\n",
    "].copy()\n",
    "\n",
    "# Risk categories based on yield loss\n",
    "low_risk = (regional_2050['yield_loss_pct'] < 0.20).sum()\n",
    "med_risk = ((regional_2050['yield_loss_pct'] >= 0.20) & \n",
    "            (regional_2050['yield_loss_pct'] < 0.40)).sum()\n",
    "high_risk = (regional_2050['yield_loss_pct'] >= 0.40).sum()\n",
    "\n",
    "sizes = [low_risk, med_risk, high_risk]\n",
    "labels = [f'Low Risk\\n(<20% loss)\\n{low_risk} regions', \n",
    "          f'Medium Risk\\n(20-40% loss)\\n{med_risk} regions',\n",
    "          f'High Risk\\n(>40% loss)\\n{high_risk} regions']\n",
    "colors_pie = ['#2ecc71', '#f39c12', '#e74c3c']\n",
    "\n",
    "wedges, texts, autotexts = ax2.pie(sizes, labels=labels, autopct='%1.1f%%',\n",
    "                                     colors=colors_pie, startangle=90,\n",
    "                                     textprops={'fontsize': 9, 'fontweight': 'bold'})\n",
    "\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontsize(11)\n",
    "\n",
    "ax2.set_title('Regional Vulnerability Distribution\\n(SSP5-8.5, 2050)', \n",
    "              fontsize=11, fontweight='bold', pad=10)\n",
    "\n",
    "# ============================================================================\n",
    "# PANEL 3 (Middle-Center): PHYSICAL VS TRANSITION RISK\n",
    "# ============================================================================\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "x = np.arange(len(scenario_names))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax3.bar(x - width/2, physical, width, label='Physical Risk',\n",
    "                color='#e74c3c', edgecolor='black', linewidth=1.5, alpha=0.85)\n",
    "bars2 = ax3.bar(x + width/2, carbon, width, label='Transition Risk (Carbon)',\n",
    "                color='#3498db', edgecolor='black', linewidth=1.5, alpha=0.85)\n",
    "\n",
    "ax3.set_ylabel('Annual Cost ($M)', fontsize=10, fontweight='bold')\n",
    "ax3.set_title('Physical vs Transition Risk\\nBreakdown by Scenario', \n",
    "              fontsize=11, fontweight='bold', pad=10)\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(scenario_names, fontsize=8, rotation=15, ha='right')\n",
    "ax3.legend(fontsize=9, loc='upper left')\n",
    "ax3.yaxis.grid(True, alpha=0.3)\n",
    "\n",
    "# ============================================================================\n",
    "# PANEL 4 (Middle-Right): KEY METRICS BOX\n",
    "# ============================================================================\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "ax4.axis('off')\n",
    "\n",
    "# Calculate key metrics\n",
    "most_likely_total = totals[1]  # SSP245\n",
    "most_likely_physical = physical[1]\n",
    "most_likely_carbon = carbon[1]\n",
    "total_regions = len(regional_2050)\n",
    "low_risk_pct = (low_risk / total_regions) * 100\n",
    "\n",
    "metrics_text = f\"\"\"\n",
    "KEY FINDINGS\n",
    "\n",
    "ğŸ“Š Total Exposure\n",
    "   ${most_likely_total:,.0f}M\n",
    "   (Delayed Transition, 2050)\n",
    "\n",
    "ğŸŒ± Physical Risk\n",
    "   ${most_likely_physical:.0f}M/year\n",
    "   (Coffee supply impacts)\n",
    "\n",
    "ğŸ’¨ Transition Risk\n",
    "   ${most_likely_carbon:,.0f}M/year\n",
    "   (Carbon pricing)\n",
    "\n",
    "ğŸ—ºï¸ Portfolio Resilience\n",
    "   {low_risk_pct:.0f}% Low Risk\n",
    "   ({low_risk}/{total_regions} regions)\n",
    "\n",
    "âš ï¸ High-Risk Regions\n",
    "   {high_risk} regions\n",
    "   ({(high_risk/total_regions)*100:.0f}% of portfolio)\n",
    "\"\"\"\n",
    "\n",
    "ax4.text(0.05, 0.95, metrics_text, transform=ax4.transAxes,\n",
    "         fontsize=10, fontweight='bold', verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3),\n",
    "         family='monospace')\n",
    "\n",
    "# ============================================================================\n",
    "# PANEL 5 (Bottom): TOP 10 VULNERABLE REGIONS BAR CHART\n",
    "# ============================================================================\n",
    "ax5 = fig.add_subplot(gs[2, :])\n",
    "\n",
    "top10 = regional_2050.nlargest(10, 'yield_loss_pct')[['region_name', 'country', 'yield_loss_pct', 'sourcing_pct']].copy()\n",
    "top10['label'] = top10['region_name'] + ', ' + top10['country']\n",
    "\n",
    "y_pos = np.arange(len(top10))\n",
    "colors_bar = ['#e74c3c' if x >= 0.40 else '#f39c12' if x >= 0.20 else '#2ecc71' \n",
    "              for x in top10['yield_loss_pct']]\n",
    "\n",
    "bars = ax5.barh(y_pos, top10['yield_loss_pct'] * 100, color=colors_bar, \n",
    "                edgecolor='black', linewidth=1.5, alpha=0.85)\n",
    "\n",
    "ax5.set_yticks(y_pos)\n",
    "ax5.set_yticklabels(top10['label'], fontsize=9)\n",
    "ax5.invert_yaxis()\n",
    "ax5.set_xlabel('Expected Yield Loss (%)', fontsize=11, fontweight='bold')\n",
    "ax5.set_title('Top 10 Most Vulnerable Regions (SSP5-8.5, 2050)', \n",
    "              fontsize=12, fontweight='bold', pad=15)\n",
    "ax5.xaxis.grid(True, alpha=0.3)\n",
    "\n",
    "# Add sourcing % labels\n",
    "for i, (bar, loss, pct) in enumerate(zip(bars, top10['yield_loss_pct'], top10['sourcing_pct'])):\n",
    "    ax5.text(loss * 100 + 0.5, i, f'{loss*100:.1f}% loss | {pct:.1f}% sourcing',\n",
    "             va='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{output_dir}/01_Executive_Dashboard.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"   âœ“ Saved: 01_Executive_Dashboard.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c376b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Creating Scenario Comparison Timeline...\n",
      "   âœ“ Saved: 02_Scenario_Timeline.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2. Creating Scenario Comparison Timeline...\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "fig.suptitle('Climate Risk Evolution: 2030 vs 2050 Comparison', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "# Get 2030 and 2050 data\n",
    "years_data = combined_df[combined_df['year'].isin([2030, 2050])].copy()\n",
    "\n",
    "for scenario_code, scenario_name in zip(['ssp126', 'ssp245', 'ssp585'], \n",
    "                                         ['Net-Zero 2050', 'Delayed Transition', 'Current Policies']):\n",
    "    scenario_data = years_data[years_data['scenario_code'] == scenario_code]\n",
    "    \n",
    "    years = scenario_data['year'].values\n",
    "    physical_vals = scenario_data['physical_risk_M'].values\n",
    "    carbon_vals = scenario_data['carbon_cost_M'].values\n",
    "    total_vals = scenario_data['total_climate_cost_M'].values\n",
    "    \n",
    "    # Plot 1: Total cost evolution\n",
    "    ax1.plot(years, total_vals, marker='o', linewidth=3, markersize=10, \n",
    "             label=scenario_name, alpha=0.8)\n",
    "    \n",
    "    # Add value labels\n",
    "    for year, val in zip(years, total_vals):\n",
    "        ax1.text(year, val + max(total_vals)*0.02, f'${val:,.0f}M',\n",
    "                ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "ax1.set_xlabel('Year', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Total Climate Cost ($M)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Total Climate Risk Trajectory by Scenario', fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=11, loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xticks([2030, 2050])\n",
    "\n",
    "# Plot 2: Physical vs Carbon breakdown for 2050\n",
    "scenarios_2050_sorted = scenarios_2050.sort_values('scenario_code')\n",
    "x = np.arange(len(scenario_names))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax2.bar(x - width/2, physical, width, label='Physical Risk',\n",
    "                color='#e74c3c', edgecolor='black', linewidth=1.5, alpha=0.85)\n",
    "bars2 = ax2.bar(x + width/2, carbon, width, label='Carbon Cost',\n",
    "                color='#3498db', edgecolor='black', linewidth=1.5, alpha=0.85)\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + max(carbon)*0.02,\n",
    "                f'${height:,.0f}M', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax2.set_ylabel('Annual Cost ($M)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Physical vs Transition Risk Comparison (2050)', fontsize=13, fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(scenario_names, fontsize=11)\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.yaxis.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{output_dir}/02_Scenario_Timeline.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"   âœ“ Saved: 02_Scenario_Timeline.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a0bd9e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Creating Geographic Vulnerability Visualization...\n",
      "   âœ“ Saved: 03_Geographic_Vulnerability.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n3. Creating Geographic Vulnerability Visualization...\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "fig.suptitle('Geographic Climate Risk Assessment', fontsize=16, fontweight='bold')\n",
    "\n",
    "# LEFT: Bubble chart - Stress vs Sourcing %\n",
    "regional_sorted = regional_2050.sort_values('yield_loss_pct', ascending=False).head(20)\n",
    "\n",
    "scatter = ax1.scatter(regional_sorted['sourcing_pct'], \n",
    "                      regional_sorted['yield_loss_pct'] * 100,\n",
    "                      s=regional_sorted['profit_at_risk_M'] * 10,  # Size by financial impact\n",
    "                      c=regional_sorted['stress_index'],\n",
    "                      cmap='RdYlGn_r', alpha=0.7, edgecolors='black', linewidth=1.5)\n",
    "\n",
    "# Add region labels for top 10\n",
    "for idx, row in regional_sorted.head(10).iterrows():\n",
    "    ax1.annotate(row['region_name'], \n",
    "                (row['sourcing_pct'], row['yield_loss_pct'] * 100),\n",
    "                xytext=(5, 5), textcoords='offset points',\n",
    "                fontsize=8, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.5))\n",
    "\n",
    "ax1.set_xlabel('% of Total Sourcing', fontsize=11, fontweight='bold')\n",
    "ax1.set_ylabel('Expected Yield Loss (%)', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Climate Risk vs Portfolio Concentration\\n(Bubble size = Profit at risk)', \n",
    "              fontsize=12, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add risk zones\n",
    "ax1.axhline(y=20, color='orange', linestyle='--', linewidth=2, alpha=0.5, label='Medium risk threshold')\n",
    "ax1.axhline(y=40, color='red', linestyle='--', linewidth=2, alpha=0.5, label='High risk threshold')\n",
    "ax1.legend(fontsize=9)\n",
    "\n",
    "cbar = plt.colorbar(scatter, ax=ax1)\n",
    "cbar.set_label('Climate Stress Index', fontweight='bold')\n",
    "\n",
    "# RIGHT: Regional concentration bar chart\n",
    "top_regions = regional_2050.nlargest(15, 'sourcing_pct')[['region_name', 'country', 'sourcing_pct', 'yield_loss_pct']].copy()\n",
    "top_regions['label'] = top_regions['region_name'] + ', ' + top_regions['country']\n",
    "\n",
    "y_pos = np.arange(len(top_regions))\n",
    "colors_conc = ['#e74c3c' if x >= 0.40 else '#f39c12' if x >= 0.20 else '#2ecc71' \n",
    "               for x in top_regions['yield_loss_pct']]\n",
    "\n",
    "bars = ax2.barh(y_pos, top_regions['sourcing_pct'], color=colors_conc,\n",
    "                edgecolor='black', linewidth=1.5, alpha=0.85)\n",
    "\n",
    "ax2.set_yticks(y_pos)\n",
    "ax2.set_yticklabels(top_regions['label'], fontsize=9)\n",
    "ax2.invert_yaxis()\n",
    "ax2.set_xlabel('% of Total Sourcing', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Top 15 Sourcing Regions\\n(Color = Risk Level)', fontsize=12, fontweight='bold')\n",
    "ax2.xaxis.grid(True, alpha=0.3)\n",
    "\n",
    "# Add sourcing % labels\n",
    "for i, (bar, pct, loss) in enumerate(zip(bars, top_regions['sourcing_pct'], top_regions['yield_loss_pct'])):\n",
    "    ax2.text(pct + 0.2, i, f'{pct:.1f}%', va='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{output_dir}/03_Geographic_Vulnerability.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"   âœ“ Saved: 03_Geographic_Vulnerability.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "18ad1b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Creating Competitive Benchmarking Chart...\n",
      "   âœ“ Saved: 04_Competitive_Benchmarking.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VIZ 4: COMPETITIVE BENCHMARKING - INDUSTRY CLIMATE RESILIENCE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n4. Creating Competitive Benchmarking Chart...\")\n",
    "\n",
    "# Check if competitor_df exists\n",
    "if 'competitor_df' not in globals():\n",
    "    print(\"   âš ï¸ competitor_df not found - run Step 14 first\")\n",
    "else:\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    gs = fig.add_gridspec(3, 2, hspace=0.35, wspace=0.3)\n",
    "    \n",
    "    fig.suptitle('COMPETITIVE CLIMATE RISK BENCHMARKING\\nIndustry Vulnerability Assessment', \n",
    "                 fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Sort by vulnerability (best to worst)\n",
    "    comp_sorted = competitor_df.sort_values('vulnerability_score', ascending=True)\n",
    "    companies = comp_sorted['company'].tolist()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # PANEL 1 (Top-Left): OVERALL VULNERABILITY RANKING\n",
    "    # ========================================================================\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    \n",
    "    vulnerability = comp_sorted['vulnerability_score'].values\n",
    "    \n",
    "    # Color code: green = best, red = worst\n",
    "    colors_vuln = []\n",
    "    for v in vulnerability:\n",
    "        if v < 0.45:\n",
    "            colors_vuln.append('#2ecc71')  # Green - low vulnerability\n",
    "        elif v < 0.55:\n",
    "            colors_vuln.append('#f39c12')  # Orange - medium\n",
    "        else:\n",
    "            colors_vuln.append('#e74c3c')  # Red - high vulnerability\n",
    "    \n",
    "    bars = ax1.barh(companies, vulnerability, color=colors_vuln, \n",
    "                    edgecolor='black', linewidth=2, alpha=0.85)\n",
    "    \n",
    "    # Highlight Starbucks\n",
    "    starbucks_idx = companies.index('Starbucks')\n",
    "    bars[starbucks_idx].set_edgecolor('gold')\n",
    "    bars[starbucks_idx].set_linewidth(4)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, vuln) in enumerate(zip(bars, vulnerability)):\n",
    "        label_text = f'{vuln:.2f}'\n",
    "        if companies[i] == 'Starbucks':\n",
    "            label_text += ' â­'\n",
    "        ax1.text(vuln + 0.02, bar.get_y() + bar.get_height()/2,\n",
    "                label_text, va='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax1.set_xlabel('Vulnerability Score (Lower = Better)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Overall Climate Vulnerability Ranking', fontsize=14, fontweight='bold', pad=15)\n",
    "    ax1.set_xlim(0, 1.0)\n",
    "    ax1.xaxis.grid(True, alpha=0.3)\n",
    "    ax1.invert_yaxis()\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='#2ecc71', edgecolor='black', label='Low Vulnerability (<0.45)'),\n",
    "        Patch(facecolor='#f39c12', edgecolor='black', label='Medium Vulnerability (0.45-0.55)'),\n",
    "        Patch(facecolor='#e74c3c', edgecolor='black', label='High Vulnerability (>0.55)'),\n",
    "        Patch(facecolor='white', edgecolor='gold', linewidth=3, label='Starbucks')\n",
    "    ]\n",
    "    ax1.legend(handles=legend_elements, loc='lower right', fontsize=10)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # PANEL 2 (Middle-Left): DIVERSIFICATION SCORES\n",
    "    # ========================================================================\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    \n",
    "    diversification = comp_sorted['diversification_score'].values\n",
    "    preparedness = comp_sorted['preparedness_score'].values\n",
    "    \n",
    "    x_pos = np.arange(len(companies))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax2.barh(x_pos - width/2, diversification, width, \n",
    "                     label='Diversification', color='#3498db', \n",
    "                     edgecolor='black', linewidth=1.5, alpha=0.85)\n",
    "    bars2 = ax2.barh(x_pos + width/2, preparedness, width,\n",
    "                     label='Preparedness', color='#9b59b6',\n",
    "                     edgecolor='black', linewidth=1.5, alpha=0.85)\n",
    "    \n",
    "    ax2.set_yticks(x_pos)\n",
    "    ax2.set_yticklabels(companies, fontsize=10)\n",
    "    ax2.invert_yaxis()\n",
    "    ax2.set_xlabel('Score (0-1)', fontsize=11, fontweight='bold')\n",
    "    ax2.set_title('Diversification & Preparedness', fontsize=12, fontweight='bold', pad=10)\n",
    "    ax2.legend(fontsize=9, loc='lower right')\n",
    "    ax2.xaxis.grid(True, alpha=0.3)\n",
    "    ax2.set_xlim(0, 1.0)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # PANEL 3 (Middle-Right): TOP-3 CONCENTRATION RISK\n",
    "    # ========================================================================\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    \n",
    "    concentration = comp_sorted['top3_concentration'].values * 100\n",
    "    \n",
    "    # Color by risk level\n",
    "    colors_conc = ['#e74c3c' if c > 50 else '#f39c12' if c > 35 else '#2ecc71' \n",
    "                   for c in concentration]\n",
    "    \n",
    "    bars = ax3.barh(companies, concentration, color=colors_conc,\n",
    "                    edgecolor='black', linewidth=1.5, alpha=0.85)\n",
    "    \n",
    "    # Highlight Starbucks\n",
    "    bars[starbucks_idx].set_edgecolor('gold')\n",
    "    bars[starbucks_idx].set_linewidth(3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, conc in zip(bars, concentration):\n",
    "        ax3.text(conc + 1, bar.get_y() + bar.get_height()/2,\n",
    "                f'{conc:.1f}%', va='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    ax3.invert_yaxis()\n",
    "    ax3.set_xlabel('Top-3 Regional Concentration (%)', fontsize=11, fontweight='bold')\n",
    "    ax3.set_title('Geographic Concentration Risk\\n(Lower = Better Diversified)', \n",
    "                  fontsize=12, fontweight='bold', pad=10)\n",
    "    ax3.xaxis.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add risk zones\n",
    "    ax3.axvline(x=50, color='red', linestyle='--', linewidth=2, alpha=0.5)\n",
    "    ax3.axvline(x=35, color='orange', linestyle='--', linewidth=2, alpha=0.5)\n",
    "    ax3.text(50, len(companies)*0.9, 'High Risk', ha='center', fontsize=8, \n",
    "             bbox=dict(boxstyle='round', facecolor='red', alpha=0.3))\n",
    "    ax3.text(35, len(companies)*0.9, 'Medium', ha='center', fontsize=8,\n",
    "             bbox=dict(boxstyle='round', facecolor='orange', alpha=0.3))\n",
    "    \n",
    "    # ========================================================================\n",
    "    # PANEL 4 (Bottom-Left): ESTIMATED 2050 CLIMATE COST\n",
    "    # ========================================================================\n",
    "    ax4 = fig.add_subplot(gs[2, 0])\n",
    "    \n",
    "    climate_costs = comp_sorted['estimated_climate_cost_2050_M'].values\n",
    "    \n",
    "    bars = ax4.barh(companies, climate_costs, color='#e74c3c',\n",
    "                    edgecolor='black', linewidth=1.5, alpha=0.85)\n",
    "    \n",
    "    # Highlight Starbucks\n",
    "    bars[starbucks_idx].set_color('#f39c12')\n",
    "    bars[starbucks_idx].set_edgecolor('gold')\n",
    "    bars[starbucks_idx].set_linewidth(3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, cost in zip(bars, climate_costs):\n",
    "        ax4.text(cost + max(climate_costs)*0.02, bar.get_y() + bar.get_height()/2,\n",
    "                f'${cost:,.0f}M', va='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    ax4.invert_yaxis()\n",
    "    ax4.set_xlabel('Estimated Annual Climate Cost ($M)', fontsize=11, fontweight='bold')\n",
    "    ax4.set_title('2050 Financial Exposure\\n(SSP5-8.5 Scenario)', \n",
    "                  fontsize=12, fontweight='bold', pad=10)\n",
    "    ax4.xaxis.grid(True, alpha=0.3)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # PANEL 5 (Bottom-Right): COST AS % OF REVENUE\n",
    "    # ========================================================================\n",
    "    ax5 = fig.add_subplot(gs[2, 1])\n",
    "    \n",
    "    cost_pct = comp_sorted['cost_pct_revenue'].values\n",
    "    \n",
    "    bars = ax5.barh(companies, cost_pct, color='#9b59b6',\n",
    "                    edgecolor='black', linewidth=1.5, alpha=0.85)\n",
    "    \n",
    "    # Highlight Starbucks\n",
    "    bars[starbucks_idx].set_color('#3498db')\n",
    "    bars[starbucks_idx].set_edgecolor('gold')\n",
    "    bars[starbucks_idx].set_linewidth(3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, pct in zip(bars, cost_pct):\n",
    "        ax5.text(pct + 0.05, bar.get_y() + bar.get_height()/2,\n",
    "                f'{pct:.2f}%', va='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    ax5.invert_yaxis()\n",
    "    ax5.set_xlabel('Climate Cost as % of Revenue', fontsize=11, fontweight='bold')\n",
    "    ax5.set_title('Financial Materiality\\n(Relative Impact)', \n",
    "                  fontsize=12, fontweight='bold', pad=10)\n",
    "    ax5.xaxis.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add materiality threshold\n",
    "    ax5.axvline(x=5.0, color='red', linestyle='--', linewidth=2, alpha=0.5)\n",
    "    ax5.text(5.0, len(companies)*0.95, '5% Materiality\\nThreshold', ha='right', \n",
    "             fontsize=8, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/04_Competitive_Benchmarking.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"   âœ“ Saved: 04_Competitive_Benchmarking.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b0513193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Creating Emission Trajectory Visualization...\n",
      "   âœ“ Saved: 05_Emission_Trajectory.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VIZ 5: EMISSION TRAJECTORY & NET-ZERO PATHWAY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n5. Creating Emission Trajectory Visualization...\")\n",
    "\n",
    "# Check if trajectory_df exists from Step 17A\n",
    "if 'trajectory_df' not in globals():\n",
    "    print(\"   âš ï¸ trajectory_df not found - run Step 17A first\")\n",
    "else:\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "    fig.suptitle('STARBUCKS NET-ZERO EMISSION TRAJECTORY\\nPathway to 2050 Climate Commitments', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Get data\n",
    "    years = trajectory_df['year'].values\n",
    "    bau = trajectory_df['business_as_usual_MT'].values\n",
    "    net_zero = trajectory_df['net_zero_MT'].values\n",
    "    \n",
    "    # ========================================================================\n",
    "    # TOP CHART: EMISSION TRAJECTORY\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Plot trajectories\n",
    "    ax1.plot(years, bau, marker='o', linewidth=3, markersize=10, \n",
    "             label='Business as Usual (+2%/year)', color='#e74c3c', linestyle='--', alpha=0.8)\n",
    "    ax1.plot(years, net_zero, marker='s', linewidth=3, markersize=10,\n",
    "             label='Net-Zero Pathway (Official Target)', color='#2ecc71', alpha=0.8)\n",
    "    \n",
    "    # Fill area between trajectories (emissions avoided)\n",
    "    ax1.fill_between(years, bau, net_zero, alpha=0.2, color='green', \n",
    "                     label='Emissions Avoided')\n",
    "    \n",
    "    # Add milestone annotations\n",
    "    ax1.annotate('2030 Target\\n50% Reduction\\n7.65 MT', \n",
    "                xy=(2030, net_zero[1]), xytext=(2028, net_zero[1] + 3),\n",
    "                arrowprops=dict(arrowstyle='->', color='green', lw=2),\n",
    "                fontsize=10, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
    "    \n",
    "    ax1.annotate('2050 Net-Zero\\n95% Reduction\\n0.77 MT', \n",
    "                xy=(2050, net_zero[-1]), xytext=(2047, net_zero[-1] + 3),\n",
    "                arrowprops=dict(arrowstyle='->', color='darkgreen', lw=2),\n",
    "                fontsize=10, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
    "    \n",
    "    # Add baseline\n",
    "    ax1.axhline(y=15.3, color='gray', linestyle=':', linewidth=2, alpha=0.5)\n",
    "    ax1.text(2024.5, 15.3 + 0.5, '2023 Baseline: 15.3 MT', \n",
    "             fontsize=9, style='italic', color='gray')\n",
    "    \n",
    "    # Formatting\n",
    "    ax1.set_xlabel('Year', fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel('Total Emissions (Million MT COâ‚‚e)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Emission Reduction Pathway', fontsize=13, fontweight='bold', pad=10)\n",
    "    ax1.legend(fontsize=11, loc='upper right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0, max(bau) * 1.1)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # BOTTOM CHART: EMISSIONS BY SCOPE (2024 vs 2030 vs 2050)\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Data for stacked bar chart\n",
    "    milestone_years = [2024, 2030, 2050]\n",
    "    scope_1 = [0.3, 0.15, 0.015]  # 50% reduction by 2030, 95% by 2050\n",
    "    scope_2 = [1.2, 0.6, 0.06]\n",
    "    scope_3 = [13.8, 6.9, 0.69]\n",
    "    \n",
    "    x_pos = np.arange(len(milestone_years))\n",
    "    width = 0.5\n",
    "    \n",
    "    # Stacked bars\n",
    "    p1 = ax2.bar(x_pos, scope_1, width, label='Scope 1 (Direct operations)', \n",
    "                 color='#e74c3c', edgecolor='black', linewidth=1.5)\n",
    "    p2 = ax2.bar(x_pos, scope_2, width, bottom=scope_1,\n",
    "                 label='Scope 2 (Purchased energy)', \n",
    "                 color='#f39c12', edgecolor='black', linewidth=1.5)\n",
    "    p3 = ax2.bar(x_pos, scope_3, width, \n",
    "                 bottom=np.array(scope_1) + np.array(scope_2),\n",
    "                 label='Scope 3 (Supply chain)', \n",
    "                 color='#3498db', edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # Add total labels on top\n",
    "    totals = [s1 + s2 + s3 for s1, s2, s3 in zip(scope_1, scope_2, scope_3)]\n",
    "    for i, (x, total) in enumerate(zip(x_pos, totals)):\n",
    "        ax2.text(x, total + 0.5, f'{total:.2f} MT', \n",
    "                ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Add reduction percentage labels\n",
    "    reductions = ['Baseline', '-50%', '-95%']\n",
    "    for i, (x, red) in enumerate(zip(x_pos, reductions)):\n",
    "        ax2.text(x, -1.5, red, ha='center', va='top', fontsize=10, \n",
    "                fontweight='bold', color='green' if i > 0 else 'black')\n",
    "    \n",
    "    # Formatting\n",
    "    ax2.set_ylabel('Emissions (Million MT COâ‚‚e)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Emission Reduction by Scope', fontsize=13, fontweight='bold', pad=10)\n",
    "    ax2.set_xticks(x_pos)\n",
    "    ax2.set_xticklabels(milestone_years, fontsize=11)\n",
    "    ax2.legend(fontsize=10, loc='upper right')\n",
    "    ax2.yaxis.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(-2, max(totals) * 1.15)\n",
    "    \n",
    "    # Add key insight box\n",
    "    insight = \"Scope 3 (supply chain) represents\\n90% of emissions - requires\\nsupplier engagement & regenerative\\nagriculture investment\"\n",
    "    ax2.text(0.02, 0.98, insight, transform=ax2.transAxes,\n",
    "             bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8),\n",
    "             fontsize=9, verticalalignment='top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/05_Emission_Trajectory.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"   âœ“ Saved: 05_Emission_Trajectory.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0631aab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CONSOLIDATING ALL RESULTS INTO MASTER EXCEL FILE\n",
      "================================================================================\n",
      "\n",
      "âœ“ Master Excel file created: C:/Users/ibeha/OneDrive/Desktop/Climate/outputs/STARBUCKS_CLIMATE_RISK_ANALYSIS_MASTER.xlsx\n",
      "\n",
      "Sheets included:\n",
      "  1. Executive Summary (Key metrics)\n",
      "  2. NPV Summary (Total climate NPV by scenario)\n",
      "  3. Scenario Summary (Physical + transition impacts)\n",
      "  4. Combined Risks (Physical + transition by year)\n",
      "  5. Carbon Costs (Carbon pricing trajectory)\n",
      "  6. Regional Yields (Detailed regional analysis)\n",
      "  7. Regional Concentration (Top vulnerable regions)\n",
      "  8. Competitor Analysis (Benchmarking vs peers)\n",
      "  9. Emissions Trajectory (Net-zero pathway)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "from openpyxl.styles import Font, PatternFill, Alignment, Border, Side\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONSOLIDATING ALL RESULTS INTO MASTER EXCEL FILE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Output file\n",
    "output_file = f\"{CONFIG['base_path']}/outputs/STARBUCKS_CLIMATE_RISK_ANALYSIS_MASTER.xlsx\"\n",
    "\n",
    "# Create Excel writer\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SHEET 1: EXECUTIVE SUMMARY\n",
    "    # ========================================================================\n",
    "    \n",
    "    summary_data = {\n",
    "        'Metric': [\n",
    "            'Analysis Period',\n",
    "            'Scenarios Modeled',\n",
    "            'Regions Analyzed',\n",
    "            'Annual Coffee Volume (MT)',\n",
    "            '',\n",
    "            'PHYSICAL RISK (2050, Most Likely)',\n",
    "            'Annual Profit at Risk',\n",
    "            'Supply at Risk (%)',\n",
    "            '',\n",
    "            'TRANSITION RISK (2050, Most Likely)',\n",
    "            'Annual Carbon Cost',\n",
    "            'Carbon Price ($/tCO2)',\n",
    "            '',\n",
    "            'TOTAL CLIMATE COST (2050)',\n",
    "            'Annual Exposure',\n",
    "            '30-Year NPV',\n",
    "            '% of Total Assets',\n",
    "            '% of Total Revenue',\n",
    "            '',\n",
    "            'COMPETITIVE POSITION',\n",
    "            'Vulnerability Score',\n",
    "            'Rank vs Competitors',\n",
    "            'Top-3 Concentration',\n",
    "            'Diversification Score',\n",
    "            '',\n",
    "            'GEOGRAPHIC RESILIENCE',\n",
    "            'Low-Risk Regions (%)',\n",
    "            'Medium-Risk Regions (%)',\n",
    "            'High-Risk Regions (%)',\n",
    "        ],\n",
    "        'Value': [\n",
    "            '2024-2050',\n",
    "            'SSP1-2.6, SSP2-4.5, SSP5-8.5',\n",
    "            '29',\n",
    "            f\"{CONFIG['financial_params']['starbucks_annual_coffee_mt']:,.0f}\",\n",
    "            '',\n",
    "            '',\n",
    "            f\"${combined_df[(combined_df['scenario_code']=='ssp245') & (combined_df['year']==2050)]['physical_risk_M'].values[0]:.1f}M\",\n",
    "            f\"{combined_df[(combined_df['scenario_code']=='ssp245') & (combined_df['year']==2050)]['pct_supply_at_risk'].values[0]:.1f}%\",\n",
    "            '',\n",
    "            '',\n",
    "            f\"${combined_df[(combined_df['scenario_code']=='ssp245') & (combined_df['year']==2050)]['carbon_cost_M'].values[0]:.1f}M\",\n",
    "            '$306/tCO2',\n",
    "            '',\n",
    "            '',\n",
    "            f\"${combined_df[(combined_df['scenario_code']=='ssp245') & (combined_df['year']==2050)]['total_climate_cost_M'].values[0]:.1f}M\",\n",
    "            f\"${total_npv_df[total_npv_df['scenario']=='ssp245']['npv_30yr_M'].values[0]:.1f}M\",\n",
    "            f\"{total_npv_df[total_npv_df['scenario']=='ssp245']['pct_of_total_assets'].values[0]:.2f}%\",\n",
    "            f\"{total_npv_df[total_npv_df['scenario']=='ssp245']['pct_of_total_revenue'].values[0]:.2f}%\",\n",
    "            '',\n",
    "            '',\n",
    "            f\"{competitor_df[competitor_df['company']=='Starbucks']['vulnerability_score'].values[0]:.2f}\",\n",
    "            '4 of 5 (Second-Best)',\n",
    "            '17.5%',\n",
    "            f\"{competitor_df[competitor_df['company']=='Starbucks']['diversification_score'].values[0]:.2f}\",\n",
    "            '',\n",
    "            '',\n",
    "            '84.8%',\n",
    "            '4.0%',\n",
    "            '0.0%',\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df.to_excel(writer, sheet_name='Executive Summary', index=False)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SHEET 2: KEY METRICS BY SCENARIO\n",
    "    # ========================================================================\n",
    "    \n",
    "    total_npv_df.to_excel(writer, sheet_name='NPV Summary', index=False)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SHEET 3: SCENARIO FINANCIAL IMPACTS\n",
    "    # ========================================================================\n",
    "    \n",
    "    scenario_summary.to_excel(writer, sheet_name='Scenario Summary', index=False)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SHEET 4: PHYSICAL + TRANSITION COMBINED\n",
    "    # ========================================================================\n",
    "    \n",
    "    combined_df.to_excel(writer, sheet_name='Combined Risks', index=False)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SHEET 5: CARBON PRICING TRAJECTORY\n",
    "    # ========================================================================\n",
    "    \n",
    "    carbon_costs_df.to_excel(writer, sheet_name='Carbon Costs', index=False)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SHEET 6: REGIONAL DETAILED ANALYSIS\n",
    "    # ========================================================================\n",
    "    \n",
    "    yield_df.to_excel(writer, sheet_name='Regional Yields', index=False)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SHEET 7: REGIONAL RISK CONCENTRATION\n",
    "    # ========================================================================\n",
    "    \n",
    "    regional_risk_sorted = yield_df[\n",
    "        (yield_df['scenario'] == 'ssp585') & \n",
    "        (yield_df['period'] == 'mid_term')\n",
    "    ].sort_values('profit_at_risk_M', ascending=False)\n",
    "    \n",
    "    regional_risk_sorted.to_excel(writer, sheet_name='Regional Concentration', index=False)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SHEET 8: COMPETITOR BENCHMARKING\n",
    "    # ========================================================================\n",
    "    \n",
    "    competitor_df.to_excel(writer, sheet_name='Competitor Analysis', index=False)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SHEET 9: EMISSION TRAJECTORY\n",
    "    # ========================================================================\n",
    "    \n",
    "    trajectory_df.to_excel(writer, sheet_name='Emissions Trajectory', index=False)\n",
    "\n",
    "print(f\"\\nâœ“ Master Excel file created: {output_file}\")\n",
    "print(\"\\nSheets included:\")\n",
    "print(\"  1. Executive Summary (Key metrics)\")\n",
    "print(\"  2. NPV Summary (Total climate NPV by scenario)\")\n",
    "print(\"  3. Scenario Summary (Physical + transition impacts)\")\n",
    "print(\"  4. Combined Risks (Physical + transition by year)\")\n",
    "print(\"  5. Carbon Costs (Carbon pricing trajectory)\")\n",
    "print(\"  6. Regional Yields (Detailed regional analysis)\")\n",
    "print(\"  7. Regional Concentration (Top vulnerable regions)\")\n",
    "print(\"  8. Competitor Analysis (Benchmarking vs peers)\")\n",
    "print(\"  9. Emissions Trajectory (Net-zero pathway)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9897acae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SENSITIVITY ANALYSIS: VALIDATING KEY ASSUMPTIONS\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1. STRESS-TO-YIELD CONVERSION SENSITIVITY\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "BASELINE YIELDS vs ADJUSTED SCENARIOS:\n",
      "Region                              Base       -20% Loss  +20% Loss  Range          \n",
      "----------------------------------------------------------------------\n",
      "Colombia Huila (high-elev)               1.4%      1.1%      1.6% Â±0.3%\n",
      "Brazil SÃ£o Paulo (low-elev)              7.8%      6.2%      9.4% Â±1.6%\n",
      "Sumatra Aceh (extreme)                  12.6%     10.1%     15.1% Â±2.5%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2. FINANCIAL IMPACT SENSITIVITY (Most Likely Scenario - 2050)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "BASE CASE (Delayed Transition, 2050):\n",
      "  Physical risk: $158.8M\n",
      "  Carbon cost: $2295.0M\n",
      "  Total annual: $2453.8M\n",
      "  30-year NPV (8%): $27624.7M\n",
      "\n",
      "Parameter                                Scenario             Annual Impact   NPV 30yr        vs Base        \n",
      "-------------------------------------------------------------------------------------\n",
      "Physical Risk Adjustment                 -30% (High adaptation) $      2406.2M $     27088.0M          -1.9%\n",
      "Physical Risk Adjustment                 Baseline             $      2453.8M $     27624.3M          -0.0%\n",
      "Physical Risk Adjustment                 +30% (Low adaptation) $      2501.4M $     28160.7M           1.9%\n",
      "\n",
      "Carbon Cost Adjustment                   -25% (Slower transition) $      1880.0M $     21165.2M         -23.4%\n",
      "Carbon Cost Adjustment                   Baseline             $      2453.8M $     27624.3M          -0.0%\n",
      "Carbon Cost Adjustment                   +25% (Faster transition) $      3027.6M $     34083.5M          23.4%\n",
      "\n",
      "Discount Rate                            6% (Lower opportunity cost) $      2453.8M $     33776.1M          22.3%\n",
      "Discount Rate                            8% (Baseline)        $      2453.8M $     27624.3M          -0.0%\n",
      "Discount Rate                            10% (Higher opportunity cost) $      2453.8M $     23131.8M         -16.3%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3. COMPETITIVE ADVANTAGE HOLDS ACROSS SCENARIOS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "COMPETITIVE ADVANTAGE: Starbucks vs Low-Elevation Competitors\n",
      "  Baseline Starbucks profit at risk: $32M\n",
      "  Baseline Competitors profit at risk: $65M\n",
      "  Advantage: $33M\n",
      "\n",
      "Scenario                                 Starbucks       Competitors     Advantage      \n",
      "-------------------------------------------------------------------------------------\n",
      "-30% Stress (High adaptation)            $         22.4M $         45.5M $         23.1M\n",
      "Baseline                                 $         32.0M $         65.0M $         33.0M\n",
      "+30% Stress (Low adaptation)             $         41.6M $         84.5M $         42.9M\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4. PRICE ELASTICITY SENSITIVITY\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Supply shock: 4.48% of total volume (7,701 MT)\n",
      "Revenue per kg: $73.66\n",
      "\n",
      "Elasticity                Label                     Price Increase     Demand Loss    \n",
      "-----------------------------------------------------------------------------------\n",
      "Very Inelastic            Very Inelastic                        8.95%          4.48%\n",
      "Baseline (Literature)     Baseline (Literature)                 5.60%          4.48%\n",
      "Elastic                   Elastic                               3.73%          4.48%\n",
      "\n",
      "Interpretation:\n",
      "  â€¢ Very Inelastic (-0.5): Coffee is essential â†’ small demand loss (3%)\n",
      "  â€¢ Baseline (-0.8): 4.5% supply reduction requires 5.6% price increase\n",
      "  â€¢ Elastic (-1.2): Consumers very price-sensitive â†’ 3.8% demand loss\n",
      "\n",
      "================================================================================\n",
      "MATERIALITY ASSESSMENT ACROSS SENSITIVITY SCENARIOS\n",
      "================================================================================\n",
      "\n",
      "Total Assets: $35.0B\n",
      "Materiality Threshold (5%): $1.8B\n",
      "\n",
      "Scenario                                 30-Yr NPV       % of Assets     Material?   \n",
      "----------------------------------------------------------------------------------\n",
      "Conservative (-30% scenario)             $     19337.3M         55.25% YES âœ“       \n",
      "Baseline                                 $     27624.7M         78.93% YES âœ“       \n",
      "Aggressive (+30% scenario)               $     35912.1M        102.61% YES âœ“       \n",
      "\n",
      "================================================================================\n",
      "KEY INSIGHT: Climate risk remains MATERIAL across all reasonable scenarios\n",
      "================================================================================\n",
      "\n",
      "âœ“ Saved sensitivity analysis to outputs/sensitivity_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SENSITIVITY ANALYSIS: KEY ASSUMPTIONS IMPACT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SENSITIVITY ANALYSIS: VALIDATING KEY ASSUMPTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. STRESS-TO-YIELD CONVERSION SENSITIVITY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"1. STRESS-TO-YIELD CONVERSION SENSITIVITY\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "def convert_stress_to_yield_loss(stress_value, adjustment_factor=1.0):\n",
    "    \"\"\"\n",
    "    Adjustable stress-to-yield conversion\n",
    "    adjustment_factor: 0.8 = more conservative (lower losses)\n",
    "                      1.0 = baseline\n",
    "                      1.2 = more aggressive (higher losses)\n",
    "    \"\"\"\n",
    "    if stress_value < 0.2:\n",
    "        loss = stress_value * 0.5\n",
    "    elif stress_value < 0.4:\n",
    "        loss = 0.10 + (stress_value - 0.2) * 0.75\n",
    "    elif stress_value < 0.6:\n",
    "        loss = 0.25 + (stress_value - 0.4) * 1.25\n",
    "    elif stress_value < 0.8:\n",
    "        loss = 0.50 + (stress_value - 0.6) * 1.25\n",
    "    else:\n",
    "        loss = 0.75 + (stress_value - 0.8) * 1.0\n",
    "    \n",
    "    # Apply adjustment factor\n",
    "    adjusted_loss = loss * adjustment_factor\n",
    "    return min(adjusted_loss, 0.95)\n",
    "\n",
    "# Test with key regions\n",
    "test_regions = {\n",
    "    'Colombia Huila (high-elev)': 0.027,\n",
    "    'Brazil SÃ£o Paulo (low-elev)': 0.156,\n",
    "    'Sumatra Aceh (extreme)': 0.235\n",
    "}\n",
    "\n",
    "print(\"\\nBASELINE YIELDS vs ADJUSTED SCENARIOS:\")\n",
    "print(f\"{'Region':<35s} {'Base':<10s} {'-20% Loss':<10s} {'+20% Loss':<10s} {'Range':<15s}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "baseline_yields = {}\n",
    "for region, stress in test_regions.items():\n",
    "    base_yield = convert_stress_to_yield_loss(stress, 1.0) * 100\n",
    "    conservative_yield = convert_stress_to_yield_loss(stress, 0.8) * 100\n",
    "    aggressive_yield = convert_stress_to_yield_loss(stress, 1.2) * 100\n",
    "    baseline_yields[region] = base_yield\n",
    "    \n",
    "    range_pct = aggressive_yield - conservative_yield\n",
    "    print(f\"{region:<35s} {base_yield:>8.1f}% {conservative_yield:>8.1f}% {aggressive_yield:>8.1f}% Â±{range_pct/2:.1f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. FINANCIAL IMPACT SENSITIVITY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"2. FINANCIAL IMPACT SENSITIVITY (Most Likely Scenario - 2050)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Base case from your analysis\n",
    "base_physical_risk = 158.8\n",
    "base_carbon_cost = 2295.0\n",
    "base_total = base_physical_risk + base_carbon_cost\n",
    "base_npv = 27624.7\n",
    "\n",
    "discount_rate = 0.08\n",
    "\n",
    "print(f\"\\nBASE CASE (Delayed Transition, 2050):\")\n",
    "print(f\"  Physical risk: ${base_physical_risk:.1f}M\")\n",
    "print(f\"  Carbon cost: ${base_carbon_cost:.1f}M\")\n",
    "print(f\"  Total annual: ${base_total:.1f}M\")\n",
    "print(f\"  30-year NPV (8%): ${base_npv:.1f}M\")\n",
    "\n",
    "print(f\"\\n{'Parameter':<40s} {'Scenario':<20s} {'Annual Impact':<15s} {'NPV 30yr':<15s} {'vs Base':<15s}\")\n",
    "print(\"-\"*85)\n",
    "\n",
    "# Scenario 1: Physical risk varies by Â±30%\n",
    "for adj, label in [(0.7, '-30% (High adaptation)'), (1.0, 'Baseline'), (1.3, '+30% (Low adaptation)')]:\n",
    "    adj_phys = base_physical_risk * adj\n",
    "    adj_total = adj_phys + base_carbon_cost\n",
    "    adj_npv = sum([adj_total / ((1 + discount_rate) ** t) for t in range(1, 31)])\n",
    "    diff = adj_npv - base_npv\n",
    "    diff_pct = (diff / base_npv) * 100\n",
    "    print(f\"{'Physical Risk Adjustment':<40s} {label:<20s} ${adj_total:>12.1f}M ${adj_npv:>12.1f}M {diff_pct:>13.1f}%\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Scenario 2: Carbon price varies by Â±25%\n",
    "for adj, label in [(0.75, '-25% (Slower transition)'), (1.0, 'Baseline'), (1.25, '+25% (Faster transition)')]:\n",
    "    adj_carbon = base_carbon_cost * adj\n",
    "    adj_total = base_physical_risk + adj_carbon\n",
    "    adj_npv = sum([adj_total / ((1 + discount_rate) ** t) for t in range(1, 31)])\n",
    "    diff = adj_npv - base_npv\n",
    "    diff_pct = (diff / base_npv) * 100\n",
    "    print(f\"{'Carbon Cost Adjustment':<40s} {label:<20s} ${adj_total:>12.1f}M ${adj_npv:>12.1f}M {diff_pct:>13.1f}%\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Scenario 3: Discount rate varies\n",
    "for rate, label in [(0.06, '6% (Lower opportunity cost)'), (0.08, '8% (Baseline)'), (0.10, '10% (Higher opportunity cost)')]:\n",
    "    adj_npv = sum([base_total / ((1 + rate) ** t) for t in range(1, 31)])\n",
    "    diff = adj_npv - base_npv\n",
    "    diff_pct = (diff / base_npv) * 100\n",
    "    print(f\"{'Discount Rate':<40s} {label:<20s} ${base_total:>12.1f}M ${adj_npv:>12.1f}M {diff_pct:>13.1f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. COMPETITIVE ADVANTAGE SENSITIVITY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"3. COMPETITIVE ADVANTAGE HOLDS ACROSS SCENARIOS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "starbucks_profit_risk = 32  # From earlier analysis (top 5 regions)\n",
    "competitors_profit_risk = 65  # From earlier analysis\n",
    "\n",
    "print(f\"\\nCOMPETITIVE ADVANTAGE: Starbucks vs Low-Elevation Competitors\")\n",
    "print(f\"  Baseline Starbucks profit at risk: ${starbucks_profit_risk:.0f}M\")\n",
    "print(f\"  Baseline Competitors profit at risk: ${competitors_profit_risk:.0f}M\")\n",
    "print(f\"  Advantage: ${competitors_profit_risk - starbucks_profit_risk:.0f}M\\n\")\n",
    "\n",
    "print(f\"{'Scenario':<40s} {'Starbucks':<15s} {'Competitors':<15s} {'Advantage':<15s}\")\n",
    "print(\"-\"*85)\n",
    "\n",
    "scenarios = [\n",
    "    (0.7, '-30% Stress (High adaptation)'),\n",
    "    (1.0, 'Baseline'),\n",
    "    (1.3, '+30% Stress (Low adaptation)')\n",
    "]\n",
    "\n",
    "for adj, label in scenarios:\n",
    "    sbux_adj = starbucks_profit_risk * adj\n",
    "    comp_adj = competitors_profit_risk * adj\n",
    "    advantage = comp_adj - sbux_adj\n",
    "    print(f\"{label:<40s} ${sbux_adj:>13.1f}M ${comp_adj:>13.1f}M ${advantage:>13.1f}M\")\n",
    "\n",
    "# ============================================================================\n",
    "# ============================================================================\n",
    "# 4. PRICE ELASTICITY SENSITIVITY (CORRECTED)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"4. PRICE ELASTICITY SENSITIVITY\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Use actual supply shock from yield impact\n",
    "base_volume_at_risk = 7701  # MT (from your 2050 data)\n",
    "total_volume = CONFIG['financial_params']['starbucks_annual_coffee_mt']\n",
    "supply_shock_pct = (base_volume_at_risk / total_volume)  # This is the % supply lost\n",
    "\n",
    "current_revenue_per_kg = (CONFIG['financial_params']['coffee_revenue'] / \n",
    "                          (CONFIG['financial_params']['starbucks_annual_coffee_mt'] * 1000))\n",
    "\n",
    "print(f\"\\nSupply shock: {supply_shock_pct*100:.2f}% of total volume ({base_volume_at_risk:,} MT)\")\n",
    "print(f\"Revenue per kg: ${current_revenue_per_kg:.2f}\\n\")\n",
    "\n",
    "print(f\"{'Elasticity':<25s} {'Label':<25s} {'Price Increase':<18s} {'Demand Loss':<15s}\")\n",
    "print(\"-\"*83)\n",
    "\n",
    "elasticities = [(-0.5, 'Very Inelastic'), (-0.8, 'Baseline (Literature)'), (-1.2, 'Elastic')]\n",
    "\n",
    "for elast, label in elasticities:\n",
    "    # Price elasticity formula: %Î”P = -%Î”Q / elasticity\n",
    "    price_increase_pct = (-supply_shock_pct * 100) / elast\n",
    "    # Demand loss: %Î”Q = elasticity Ã— %Î”P\n",
    "    demand_loss_pct = abs(elast * (price_increase_pct / 100)) * 100\n",
    "    \n",
    "    print(f\"{label:<25s} {label:<25s} {price_increase_pct:>16.2f}% {demand_loss_pct:>13.2f}%\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  â€¢ Very Inelastic (-0.5): Coffee is essential â†’ small demand loss (3%)\")\n",
    "print(\"  â€¢ Baseline (-0.8): 4.5% supply reduction requires 5.6% price increase\")\n",
    "print(\"  â€¢ Elastic (-1.2): Consumers very price-sensitive â†’ 3.8% demand loss\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. SUMMARY: MATERIALITY ACROSS ALL SCENARIOS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MATERIALITY ASSESSMENT ACROSS SENSITIVITY SCENARIOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nTotal Assets: ${CONFIG['financial_params']['total_assets']/1e9:.1f}B\")\n",
    "print(f\"Materiality Threshold (5%): ${CONFIG['financial_params']['total_assets'] * 0.05 / 1e9:.1f}B\\n\")\n",
    "\n",
    "print(f\"{'Scenario':<40s} {'30-Yr NPV':<15s} {'% of Assets':<15s} {'Material?':<12s}\")\n",
    "print(\"-\"*82)\n",
    "\n",
    "scenarios_materiality = [\n",
    "    (base_npv * 0.7, 'Conservative (-30% scenario)'),\n",
    "    (base_npv * 1.0, 'Baseline'),\n",
    "    (base_npv * 1.3, 'Aggressive (+30% scenario)')\n",
    "]\n",
    "\n",
    "for npv, label in scenarios_materiality:\n",
    "    pct_assets = (npv * 1e6 / CONFIG['financial_params']['total_assets']) * 100\n",
    "    material = \"YES âœ“\" if pct_assets > 5 else \"NO\"\n",
    "    print(f\"{label:<40s} ${npv:>12.1f}M {pct_assets:>13.2f}% {material:<12s}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY INSIGHT: Climate risk remains MATERIAL across all reasonable scenarios\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# 6. EXPORT SENSITIVITY RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "sensitivity_summary = pd.DataFrame({\n",
    "    'Assumption': [\n",
    "        'Physical Risk -30% (High Adaptation)',\n",
    "        'Physical Risk Baseline',\n",
    "        'Physical Risk +30% (Low Adaptation)',\n",
    "        'Carbon Cost -25% (Slower Transition)',\n",
    "        'Carbon Cost Baseline',\n",
    "        'Carbon Cost +25% (Faster Transition)',\n",
    "        'Discount Rate 6%',\n",
    "        'Discount Rate 8% (Baseline)',\n",
    "        'Discount Rate 10%'\n",
    "    ],\n",
    "    'Annual_Impact_M': [\n",
    "        base_physical_risk*0.7 + base_carbon_cost,\n",
    "        base_total,\n",
    "        base_physical_risk*1.3 + base_carbon_cost,\n",
    "        base_physical_risk + base_carbon_cost*0.75,\n",
    "        base_total,\n",
    "        base_physical_risk + base_carbon_cost*1.25,\n",
    "        base_total,\n",
    "        base_total,\n",
    "        base_total\n",
    "    ],\n",
    "    'NPV_30yr_M': [\n",
    "        sum([((base_physical_risk*0.7 + base_carbon_cost) / ((1 + 0.08) ** t)) for t in range(1, 31)]),\n",
    "        base_npv,\n",
    "        sum([((base_physical_risk*1.3 + base_carbon_cost) / ((1 + 0.08) ** t)) for t in range(1, 31)]),\n",
    "        sum([((base_physical_risk + base_carbon_cost*0.75) / ((1 + 0.08) ** t)) for t in range(1, 31)]),\n",
    "        base_npv,\n",
    "        sum([((base_physical_risk + base_carbon_cost*1.25) / ((1 + 0.08) ** t)) for t in range(1, 31)]),\n",
    "        sum([(base_total / ((1 + 0.06) ** t)) for t in range(1, 31)]),\n",
    "        base_npv,\n",
    "        sum([(base_total / ((1 + 0.10) ** t)) for t in range(1, 31)])\n",
    "    ]\n",
    "})\n",
    "\n",
    "sensitivity_summary.to_csv(f\"{CONFIG['base_path']}/outputs/sensitivity_analysis.csv\", index=False)\n",
    "\n",
    "print(\"\\nâœ“ Saved sensitivity analysis to outputs/sensitivity_analysis.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
